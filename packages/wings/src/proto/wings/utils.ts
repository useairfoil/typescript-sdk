// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v1.176.0
//   protoc               unknown
// source: wings/utils.proto

/* eslint-disable */
import Long from "long";
import _m0 from "protobufjs/minimal.js";
import { Timestamp } from "../google/protobuf/timestamp.js";
import { CommittedBatch, PartitionValue } from "./log_metadata.js";

export const protobufPackage = "wings.v1.utils";

/** Represents metadata sent with an ingestion request. */
export interface IngestionRequestMetadata {
  /** A unique identifier for this ingestion request. */
  readonly requestId: bigint;
  /** The partition value associated with this ingestion. */
  readonly partitionValue?:
    | PartitionValue
    | undefined;
  /** Timestamp of when this ingestion was initiated. */
  readonly timestamp?: Date | undefined;
}

/** Represents metadata about a successfully accepted batch of messages. */
export interface AcceptedBatchInfo {
  /** The offset of the first message in the batch. */
  readonly startOffset: bigint;
  /** The offset of the last message in the batch. */
  readonly endOffset: bigint;
  /** The timestamp of the batch. */
  readonly timestamp: Date | undefined;
}

/** Represents metadata about a batch that was rejected. */
export interface RejectedBatchInfo {
  /** The number of messages in the rejected batch. */
  readonly numMessages: number;
}

/** Represents metadata for an ingestion response. */
export interface IngestionResponseMetadata {
  /** Unique identifier for the ingestion request this response refers to. */
  readonly requestId: bigint;
  /** The result of the ingestion request, which may be accepted or rejected. */
  readonly result: CommittedBatch | undefined;
}

export interface FetchTicket {
  readonly topicName: string;
  readonly partitionValue?: PartitionValue | undefined;
  readonly offset: bigint;
}

export interface Any {
  readonly typeUrl: string;
  readonly value: Uint8Array;
}

function createBaseIngestionRequestMetadata(): IngestionRequestMetadata {
  return { requestId: BigInt("0"), partitionValue: undefined, timestamp: undefined };
}

export const IngestionRequestMetadata = {
  encode(message: IngestionRequestMetadata, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.requestId !== BigInt("0")) {
      if (BigInt.asUintN(64, message.requestId) !== message.requestId) {
        throw new globalThis.Error("value provided for field message.requestId of type uint64 too large");
      }
      writer.uint32(8).uint64(message.requestId.toString());
    }
    if (message.partitionValue !== undefined) {
      PartitionValue.encode(message.partitionValue, writer.uint32(18).fork()).ldelim();
    }
    if (message.timestamp !== undefined) {
      Timestamp.encode(toTimestamp(message.timestamp), writer.uint32(26).fork()).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): IngestionRequestMetadata {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIngestionRequestMetadata() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.requestId = longToBigint(reader.uint64() as Long);
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.partitionValue = PartitionValue.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.timestamp = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IngestionRequestMetadata {
    return {
      requestId: isSet(object.requestId) ? BigInt(object.requestId) : BigInt("0"),
      partitionValue: isSet(object.partitionValue) ? PartitionValue.fromJSON(object.partitionValue) : undefined,
      timestamp: isSet(object.timestamp) ? fromJsonTimestamp(object.timestamp) : undefined,
    };
  },

  toJSON(message: IngestionRequestMetadata): unknown {
    const obj: any = {};
    if (message.requestId !== BigInt("0")) {
      obj.requestId = message.requestId.toString();
    }
    if (message.partitionValue !== undefined) {
      obj.partitionValue = PartitionValue.toJSON(message.partitionValue);
    }
    if (message.timestamp !== undefined) {
      obj.timestamp = message.timestamp.toISOString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<IngestionRequestMetadata>, I>>(base?: I): IngestionRequestMetadata {
    return IngestionRequestMetadata.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<IngestionRequestMetadata>, I>>(object: I): IngestionRequestMetadata {
    const message = createBaseIngestionRequestMetadata() as any;
    message.requestId = object.requestId ?? BigInt("0");
    message.partitionValue = (object.partitionValue !== undefined && object.partitionValue !== null)
      ? PartitionValue.fromPartial(object.partitionValue)
      : undefined;
    message.timestamp = object.timestamp ?? undefined;
    return message;
  },
};

function createBaseAcceptedBatchInfo(): AcceptedBatchInfo {
  return { startOffset: BigInt("0"), endOffset: BigInt("0"), timestamp: undefined };
}

export const AcceptedBatchInfo = {
  encode(message: AcceptedBatchInfo, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.startOffset !== BigInt("0")) {
      if (BigInt.asUintN(64, message.startOffset) !== message.startOffset) {
        throw new globalThis.Error("value provided for field message.startOffset of type uint64 too large");
      }
      writer.uint32(8).uint64(message.startOffset.toString());
    }
    if (message.endOffset !== BigInt("0")) {
      if (BigInt.asUintN(64, message.endOffset) !== message.endOffset) {
        throw new globalThis.Error("value provided for field message.endOffset of type uint64 too large");
      }
      writer.uint32(16).uint64(message.endOffset.toString());
    }
    if (message.timestamp !== undefined) {
      Timestamp.encode(toTimestamp(message.timestamp), writer.uint32(26).fork()).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): AcceptedBatchInfo {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAcceptedBatchInfo() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.startOffset = longToBigint(reader.uint64() as Long);
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.endOffset = longToBigint(reader.uint64() as Long);
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.timestamp = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AcceptedBatchInfo {
    return {
      startOffset: isSet(object.startOffset) ? BigInt(object.startOffset) : BigInt("0"),
      endOffset: isSet(object.endOffset) ? BigInt(object.endOffset) : BigInt("0"),
      timestamp: isSet(object.timestamp) ? fromJsonTimestamp(object.timestamp) : undefined,
    };
  },

  toJSON(message: AcceptedBatchInfo): unknown {
    const obj: any = {};
    if (message.startOffset !== BigInt("0")) {
      obj.startOffset = message.startOffset.toString();
    }
    if (message.endOffset !== BigInt("0")) {
      obj.endOffset = message.endOffset.toString();
    }
    if (message.timestamp !== undefined) {
      obj.timestamp = message.timestamp.toISOString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AcceptedBatchInfo>, I>>(base?: I): AcceptedBatchInfo {
    return AcceptedBatchInfo.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AcceptedBatchInfo>, I>>(object: I): AcceptedBatchInfo {
    const message = createBaseAcceptedBatchInfo() as any;
    message.startOffset = object.startOffset ?? BigInt("0");
    message.endOffset = object.endOffset ?? BigInt("0");
    message.timestamp = object.timestamp ?? undefined;
    return message;
  },
};

function createBaseRejectedBatchInfo(): RejectedBatchInfo {
  return { numMessages: 0 };
}

export const RejectedBatchInfo = {
  encode(message: RejectedBatchInfo, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.numMessages !== 0) {
      writer.uint32(8).uint32(message.numMessages);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): RejectedBatchInfo {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRejectedBatchInfo() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.numMessages = reader.uint32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RejectedBatchInfo {
    return { numMessages: isSet(object.numMessages) ? globalThis.Number(object.numMessages) : 0 };
  },

  toJSON(message: RejectedBatchInfo): unknown {
    const obj: any = {};
    if (message.numMessages !== 0) {
      obj.numMessages = Math.round(message.numMessages);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RejectedBatchInfo>, I>>(base?: I): RejectedBatchInfo {
    return RejectedBatchInfo.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RejectedBatchInfo>, I>>(object: I): RejectedBatchInfo {
    const message = createBaseRejectedBatchInfo() as any;
    message.numMessages = object.numMessages ?? 0;
    return message;
  },
};

function createBaseIngestionResponseMetadata(): IngestionResponseMetadata {
  return { requestId: BigInt("0"), result: undefined };
}

export const IngestionResponseMetadata = {
  encode(message: IngestionResponseMetadata, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.requestId !== BigInt("0")) {
      if (BigInt.asUintN(64, message.requestId) !== message.requestId) {
        throw new globalThis.Error("value provided for field message.requestId of type uint64 too large");
      }
      writer.uint32(8).uint64(message.requestId.toString());
    }
    if (message.result !== undefined) {
      CommittedBatch.encode(message.result, writer.uint32(18).fork()).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): IngestionResponseMetadata {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIngestionResponseMetadata() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.requestId = longToBigint(reader.uint64() as Long);
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.result = CommittedBatch.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IngestionResponseMetadata {
    return {
      requestId: isSet(object.requestId) ? BigInt(object.requestId) : BigInt("0"),
      result: isSet(object.result) ? CommittedBatch.fromJSON(object.result) : undefined,
    };
  },

  toJSON(message: IngestionResponseMetadata): unknown {
    const obj: any = {};
    if (message.requestId !== BigInt("0")) {
      obj.requestId = message.requestId.toString();
    }
    if (message.result !== undefined) {
      obj.result = CommittedBatch.toJSON(message.result);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<IngestionResponseMetadata>, I>>(base?: I): IngestionResponseMetadata {
    return IngestionResponseMetadata.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<IngestionResponseMetadata>, I>>(object: I): IngestionResponseMetadata {
    const message = createBaseIngestionResponseMetadata() as any;
    message.requestId = object.requestId ?? BigInt("0");
    message.result = (object.result !== undefined && object.result !== null)
      ? CommittedBatch.fromPartial(object.result)
      : undefined;
    return message;
  },
};

function createBaseFetchTicket(): FetchTicket {
  return { topicName: "", partitionValue: undefined, offset: BigInt("0") };
}

export const FetchTicket = {
  encode(message: FetchTicket, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.topicName !== "") {
      writer.uint32(10).string(message.topicName);
    }
    if (message.partitionValue !== undefined) {
      PartitionValue.encode(message.partitionValue, writer.uint32(18).fork()).ldelim();
    }
    if (message.offset !== BigInt("0")) {
      if (BigInt.asUintN(64, message.offset) !== message.offset) {
        throw new globalThis.Error("value provided for field message.offset of type uint64 too large");
      }
      writer.uint32(24).uint64(message.offset.toString());
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): FetchTicket {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFetchTicket() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.topicName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.partitionValue = PartitionValue.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.offset = longToBigint(reader.uint64() as Long);
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FetchTicket {
    return {
      topicName: isSet(object.topicName) ? globalThis.String(object.topicName) : "",
      partitionValue: isSet(object.partitionValue) ? PartitionValue.fromJSON(object.partitionValue) : undefined,
      offset: isSet(object.offset) ? BigInt(object.offset) : BigInt("0"),
    };
  },

  toJSON(message: FetchTicket): unknown {
    const obj: any = {};
    if (message.topicName !== "") {
      obj.topicName = message.topicName;
    }
    if (message.partitionValue !== undefined) {
      obj.partitionValue = PartitionValue.toJSON(message.partitionValue);
    }
    if (message.offset !== BigInt("0")) {
      obj.offset = message.offset.toString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<FetchTicket>, I>>(base?: I): FetchTicket {
    return FetchTicket.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<FetchTicket>, I>>(object: I): FetchTicket {
    const message = createBaseFetchTicket() as any;
    message.topicName = object.topicName ?? "";
    message.partitionValue = (object.partitionValue !== undefined && object.partitionValue !== null)
      ? PartitionValue.fromPartial(object.partitionValue)
      : undefined;
    message.offset = object.offset ?? BigInt("0");
    return message;
  },
};

function createBaseAny(): Any {
  return { typeUrl: "", value: new Uint8Array(0) };
}

export const Any = {
  encode(message: Any, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.typeUrl !== "") {
      writer.uint32(10).string(message.typeUrl);
    }
    if (message.value.length !== 0) {
      writer.uint32(18).bytes(message.value);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): Any {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAny() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.typeUrl = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.bytes();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Any {
    return {
      typeUrl: isSet(object.typeUrl) ? globalThis.String(object.typeUrl) : "",
      value: isSet(object.value) ? bytesFromBase64(object.value) : new Uint8Array(0),
    };
  },

  toJSON(message: Any): unknown {
    const obj: any = {};
    if (message.typeUrl !== "") {
      obj.typeUrl = message.typeUrl;
    }
    if (message.value.length !== 0) {
      obj.value = base64FromBytes(message.value);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Any>, I>>(base?: I): Any {
    return Any.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Any>, I>>(object: I): Any {
    const message = createBaseAny() as any;
    message.typeUrl = object.typeUrl ?? "";
    message.value = object.value ?? new Uint8Array(0);
    return message;
  },
};

function bytesFromBase64(b64: string): Uint8Array {
  if ((globalThis as any).Buffer) {
    return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
  } else {
    const bin = globalThis.atob(b64);
    const arr = new Uint8Array(bin.length);
    for (let i = 0; i < bin.length; ++i) {
      arr[i] = bin.charCodeAt(i);
    }
    return arr;
  }
}

function base64FromBytes(arr: Uint8Array): string {
  if ((globalThis as any).Buffer) {
    return globalThis.Buffer.from(arr).toString("base64");
  } else {
    const bin: string[] = [];
    arr.forEach((byte) => {
      bin.push(globalThis.String.fromCharCode(byte));
    });
    return globalThis.btoa(bin.join(""));
  }
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | bigint | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends { readonly $case: string }
    ? { [K in keyof Omit<T, "$case">]?: DeepPartial<T[K]> } & { readonly $case: T["$case"] }
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
export type Exact<P, I extends P> = P extends Builtin ? P
  : P & { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P>>]: never };

function toTimestamp(date: Date): Timestamp {
  const seconds = BigInt(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (globalThis.Number(t.seconds.toString()) || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function longToBigint(long: Long) {
  return BigInt(long.toString());
}

if (_m0.util.Long !== Long) {
  _m0.util.Long = Long as any;
  _m0.configure();
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}
