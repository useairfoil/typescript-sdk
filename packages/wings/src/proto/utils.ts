// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.6.1
//   protoc               unknown
// source: utils.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import { Timestamp } from "./google/protobuf/timestamp.js";
import { CommittedBatch, PartitionValue } from "./log_metadata.js";
import { messageTypeRegistry } from "./typeRegistry.js";

export const protobufPackage = "wings.v1";

/** Represents metadata sent with an ingestion request. */
export interface IngestionRequestMetadata {
  $type: "wings.v1.IngestionRequestMetadata";
  /** A unique identifier for this ingestion request. */
  readonly requestId: bigint;
  /** The partition value associated with this ingestion. */
  readonly partitionValue?:
    | PartitionValue
    | undefined;
  /** Timestamp of when this ingestion was initiated. */
  readonly timestamp?: Date | undefined;
}

/** Represents metadata about a successfully accepted batch of messages. */
export interface AcceptedBatchInfo {
  $type: "wings.v1.AcceptedBatchInfo";
  /** The offset of the first message in the batch. */
  readonly startOffset: bigint;
  /** The offset of the last message in the batch. */
  readonly endOffset: bigint;
  /** The timestamp of the batch. */
  readonly timestamp: Date | undefined;
}

/** Represents metadata about a batch that was rejected. */
export interface RejectedBatchInfo {
  $type: "wings.v1.RejectedBatchInfo";
  /** The number of messages in the rejected batch. */
  readonly numMessages: number;
}

/** Represents metadata for an ingestion response. */
export interface IngestionResponseMetadata {
  $type: "wings.v1.IngestionResponseMetadata";
  /** Unique identifier for the ingestion request this response refers to. */
  readonly requestId: bigint;
  /** The result of the ingestion request, which may be accepted or rejected. */
  readonly result: CommittedBatch | undefined;
}

export interface FetchTicket {
  $type: "wings.v1.FetchTicket";
  readonly topicName: string;
  readonly partitionValue?: PartitionValue | undefined;
  readonly offset: bigint;
  readonly minBatchSize?: number | undefined;
  readonly maxBatchSize?: number | undefined;
}

export interface Any {
  $type: "wings.v1.Any";
  readonly typeUrl: string;
  readonly value: Uint8Array;
}

function createBaseIngestionRequestMetadata(): IngestionRequestMetadata {
  return { $type: "wings.v1.IngestionRequestMetadata", requestId: 0n, partitionValue: undefined, timestamp: undefined };
}

export const IngestionRequestMetadata: MessageFns<IngestionRequestMetadata, "wings.v1.IngestionRequestMetadata"> = {
  $type: "wings.v1.IngestionRequestMetadata" as const,

  encode(message: IngestionRequestMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.requestId !== 0n) {
      if (BigInt.asUintN(64, message.requestId) !== message.requestId) {
        throw new globalThis.Error("value provided for field message.requestId of type uint64 too large");
      }
      writer.uint32(8).uint64(message.requestId);
    }
    if (message.partitionValue !== undefined) {
      PartitionValue.encode(message.partitionValue, writer.uint32(18).fork()).join();
    }
    if (message.timestamp !== undefined) {
      Timestamp.encode(toTimestamp(message.timestamp), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IngestionRequestMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIngestionRequestMetadata() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.requestId = reader.uint64() as bigint;
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.partitionValue = PartitionValue.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.timestamp = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IngestionRequestMetadata {
    return {
      $type: IngestionRequestMetadata.$type,
      requestId: isSet(object.requestId) ? BigInt(object.requestId) : 0n,
      partitionValue: isSet(object.partitionValue) ? PartitionValue.fromJSON(object.partitionValue) : undefined,
      timestamp: isSet(object.timestamp) ? fromJsonTimestamp(object.timestamp) : undefined,
    };
  },

  toJSON(message: IngestionRequestMetadata): unknown {
    const obj: any = {};
    if (message.requestId !== 0n) {
      obj.requestId = message.requestId.toString();
    }
    if (message.partitionValue !== undefined) {
      obj.partitionValue = PartitionValue.toJSON(message.partitionValue);
    }
    if (message.timestamp !== undefined) {
      obj.timestamp = message.timestamp.toISOString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<IngestionRequestMetadata>, I>>(base?: I): IngestionRequestMetadata {
    return IngestionRequestMetadata.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<IngestionRequestMetadata>, I>>(object: I): IngestionRequestMetadata {
    const message = createBaseIngestionRequestMetadata() as any;
    message.requestId = object.requestId ?? 0n;
    message.partitionValue = (object.partitionValue !== undefined && object.partitionValue !== null)
      ? PartitionValue.fromPartial(object.partitionValue)
      : undefined;
    message.timestamp = object.timestamp ?? undefined;
    return message;
  },
};

messageTypeRegistry.set(IngestionRequestMetadata.$type, IngestionRequestMetadata);

function createBaseAcceptedBatchInfo(): AcceptedBatchInfo {
  return { $type: "wings.v1.AcceptedBatchInfo", startOffset: 0n, endOffset: 0n, timestamp: undefined };
}

export const AcceptedBatchInfo: MessageFns<AcceptedBatchInfo, "wings.v1.AcceptedBatchInfo"> = {
  $type: "wings.v1.AcceptedBatchInfo" as const,

  encode(message: AcceptedBatchInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startOffset !== 0n) {
      if (BigInt.asUintN(64, message.startOffset) !== message.startOffset) {
        throw new globalThis.Error("value provided for field message.startOffset of type uint64 too large");
      }
      writer.uint32(8).uint64(message.startOffset);
    }
    if (message.endOffset !== 0n) {
      if (BigInt.asUintN(64, message.endOffset) !== message.endOffset) {
        throw new globalThis.Error("value provided for field message.endOffset of type uint64 too large");
      }
      writer.uint32(16).uint64(message.endOffset);
    }
    if (message.timestamp !== undefined) {
      Timestamp.encode(toTimestamp(message.timestamp), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AcceptedBatchInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAcceptedBatchInfo() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.startOffset = reader.uint64() as bigint;
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.endOffset = reader.uint64() as bigint;
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.timestamp = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AcceptedBatchInfo {
    return {
      $type: AcceptedBatchInfo.$type,
      startOffset: isSet(object.startOffset) ? BigInt(object.startOffset) : 0n,
      endOffset: isSet(object.endOffset) ? BigInt(object.endOffset) : 0n,
      timestamp: isSet(object.timestamp) ? fromJsonTimestamp(object.timestamp) : undefined,
    };
  },

  toJSON(message: AcceptedBatchInfo): unknown {
    const obj: any = {};
    if (message.startOffset !== 0n) {
      obj.startOffset = message.startOffset.toString();
    }
    if (message.endOffset !== 0n) {
      obj.endOffset = message.endOffset.toString();
    }
    if (message.timestamp !== undefined) {
      obj.timestamp = message.timestamp.toISOString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AcceptedBatchInfo>, I>>(base?: I): AcceptedBatchInfo {
    return AcceptedBatchInfo.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AcceptedBatchInfo>, I>>(object: I): AcceptedBatchInfo {
    const message = createBaseAcceptedBatchInfo() as any;
    message.startOffset = object.startOffset ?? 0n;
    message.endOffset = object.endOffset ?? 0n;
    message.timestamp = object.timestamp ?? undefined;
    return message;
  },
};

messageTypeRegistry.set(AcceptedBatchInfo.$type, AcceptedBatchInfo);

function createBaseRejectedBatchInfo(): RejectedBatchInfo {
  return { $type: "wings.v1.RejectedBatchInfo", numMessages: 0 };
}

export const RejectedBatchInfo: MessageFns<RejectedBatchInfo, "wings.v1.RejectedBatchInfo"> = {
  $type: "wings.v1.RejectedBatchInfo" as const,

  encode(message: RejectedBatchInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.numMessages !== 0) {
      writer.uint32(8).uint32(message.numMessages);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RejectedBatchInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRejectedBatchInfo() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.numMessages = reader.uint32();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RejectedBatchInfo {
    return {
      $type: RejectedBatchInfo.$type,
      numMessages: isSet(object.numMessages) ? globalThis.Number(object.numMessages) : 0,
    };
  },

  toJSON(message: RejectedBatchInfo): unknown {
    const obj: any = {};
    if (message.numMessages !== 0) {
      obj.numMessages = Math.round(message.numMessages);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RejectedBatchInfo>, I>>(base?: I): RejectedBatchInfo {
    return RejectedBatchInfo.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RejectedBatchInfo>, I>>(object: I): RejectedBatchInfo {
    const message = createBaseRejectedBatchInfo() as any;
    message.numMessages = object.numMessages ?? 0;
    return message;
  },
};

messageTypeRegistry.set(RejectedBatchInfo.$type, RejectedBatchInfo);

function createBaseIngestionResponseMetadata(): IngestionResponseMetadata {
  return { $type: "wings.v1.IngestionResponseMetadata", requestId: 0n, result: undefined };
}

export const IngestionResponseMetadata: MessageFns<IngestionResponseMetadata, "wings.v1.IngestionResponseMetadata"> = {
  $type: "wings.v1.IngestionResponseMetadata" as const,

  encode(message: IngestionResponseMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.requestId !== 0n) {
      if (BigInt.asUintN(64, message.requestId) !== message.requestId) {
        throw new globalThis.Error("value provided for field message.requestId of type uint64 too large");
      }
      writer.uint32(8).uint64(message.requestId);
    }
    if (message.result !== undefined) {
      CommittedBatch.encode(message.result, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IngestionResponseMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIngestionResponseMetadata() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.requestId = reader.uint64() as bigint;
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.result = CommittedBatch.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IngestionResponseMetadata {
    return {
      $type: IngestionResponseMetadata.$type,
      requestId: isSet(object.requestId) ? BigInt(object.requestId) : 0n,
      result: isSet(object.result) ? CommittedBatch.fromJSON(object.result) : undefined,
    };
  },

  toJSON(message: IngestionResponseMetadata): unknown {
    const obj: any = {};
    if (message.requestId !== 0n) {
      obj.requestId = message.requestId.toString();
    }
    if (message.result !== undefined) {
      obj.result = CommittedBatch.toJSON(message.result);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<IngestionResponseMetadata>, I>>(base?: I): IngestionResponseMetadata {
    return IngestionResponseMetadata.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<IngestionResponseMetadata>, I>>(object: I): IngestionResponseMetadata {
    const message = createBaseIngestionResponseMetadata() as any;
    message.requestId = object.requestId ?? 0n;
    message.result = (object.result !== undefined && object.result !== null)
      ? CommittedBatch.fromPartial(object.result)
      : undefined;
    return message;
  },
};

messageTypeRegistry.set(IngestionResponseMetadata.$type, IngestionResponseMetadata);

function createBaseFetchTicket(): FetchTicket {
  return {
    $type: "wings.v1.FetchTicket",
    topicName: "",
    partitionValue: undefined,
    offset: 0n,
    minBatchSize: undefined,
    maxBatchSize: undefined,
  };
}

export const FetchTicket: MessageFns<FetchTicket, "wings.v1.FetchTicket"> = {
  $type: "wings.v1.FetchTicket" as const,

  encode(message: FetchTicket, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.topicName !== "") {
      writer.uint32(10).string(message.topicName);
    }
    if (message.partitionValue !== undefined) {
      PartitionValue.encode(message.partitionValue, writer.uint32(18).fork()).join();
    }
    if (message.offset !== 0n) {
      if (BigInt.asUintN(64, message.offset) !== message.offset) {
        throw new globalThis.Error("value provided for field message.offset of type uint64 too large");
      }
      writer.uint32(24).uint64(message.offset);
    }
    if (message.minBatchSize !== undefined) {
      writer.uint32(40).uint32(message.minBatchSize);
    }
    if (message.maxBatchSize !== undefined) {
      writer.uint32(48).uint32(message.maxBatchSize);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FetchTicket {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFetchTicket() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.topicName = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.partitionValue = PartitionValue.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.offset = reader.uint64() as bigint;
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.minBatchSize = reader.uint32();
          continue;
        }
        case 6: {
          if (tag !== 48) {
            break;
          }

          message.maxBatchSize = reader.uint32();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FetchTicket {
    return {
      $type: FetchTicket.$type,
      topicName: isSet(object.topicName) ? globalThis.String(object.topicName) : "",
      partitionValue: isSet(object.partitionValue) ? PartitionValue.fromJSON(object.partitionValue) : undefined,
      offset: isSet(object.offset) ? BigInt(object.offset) : 0n,
      minBatchSize: isSet(object.minBatchSize) ? globalThis.Number(object.minBatchSize) : undefined,
      maxBatchSize: isSet(object.maxBatchSize) ? globalThis.Number(object.maxBatchSize) : undefined,
    };
  },

  toJSON(message: FetchTicket): unknown {
    const obj: any = {};
    if (message.topicName !== "") {
      obj.topicName = message.topicName;
    }
    if (message.partitionValue !== undefined) {
      obj.partitionValue = PartitionValue.toJSON(message.partitionValue);
    }
    if (message.offset !== 0n) {
      obj.offset = message.offset.toString();
    }
    if (message.minBatchSize !== undefined) {
      obj.minBatchSize = Math.round(message.minBatchSize);
    }
    if (message.maxBatchSize !== undefined) {
      obj.maxBatchSize = Math.round(message.maxBatchSize);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<FetchTicket>, I>>(base?: I): FetchTicket {
    return FetchTicket.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<FetchTicket>, I>>(object: I): FetchTicket {
    const message = createBaseFetchTicket() as any;
    message.topicName = object.topicName ?? "";
    message.partitionValue = (object.partitionValue !== undefined && object.partitionValue !== null)
      ? PartitionValue.fromPartial(object.partitionValue)
      : undefined;
    message.offset = object.offset ?? 0n;
    message.minBatchSize = object.minBatchSize ?? undefined;
    message.maxBatchSize = object.maxBatchSize ?? undefined;
    return message;
  },
};

messageTypeRegistry.set(FetchTicket.$type, FetchTicket);

function createBaseAny(): Any {
  return { $type: "wings.v1.Any", typeUrl: "", value: new Uint8Array(0) };
}

export const Any: MessageFns<Any, "wings.v1.Any"> = {
  $type: "wings.v1.Any" as const,

  encode(message: Any, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.typeUrl !== "") {
      writer.uint32(10).string(message.typeUrl);
    }
    if (message.value.length !== 0) {
      writer.uint32(18).bytes(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Any {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAny() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.typeUrl = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.bytes();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Any {
    return {
      $type: Any.$type,
      typeUrl: isSet(object.typeUrl) ? globalThis.String(object.typeUrl) : "",
      value: isSet(object.value) ? bytesFromBase64(object.value) : new Uint8Array(0),
    };
  },

  toJSON(message: Any): unknown {
    const obj: any = {};
    if (message.typeUrl !== "") {
      obj.typeUrl = message.typeUrl;
    }
    if (message.value.length !== 0) {
      obj.value = base64FromBytes(message.value);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Any>, I>>(base?: I): Any {
    return Any.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Any>, I>>(object: I): Any {
    const message = createBaseAny() as any;
    message.typeUrl = object.typeUrl ?? "";
    message.value = object.value ?? new Uint8Array(0);
    return message;
  },
};

messageTypeRegistry.set(Any.$type, Any);

function bytesFromBase64(b64: string): Uint8Array {
  if ((globalThis as any).Buffer) {
    return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
  } else {
    const bin = globalThis.atob(b64);
    const arr = new Uint8Array(bin.length);
    for (let i = 0; i < bin.length; ++i) {
      arr[i] = bin.charCodeAt(i);
    }
    return arr;
  }
}

function base64FromBytes(arr: Uint8Array): string {
  if ((globalThis as any).Buffer) {
    return globalThis.Buffer.from(arr).toString("base64");
  } else {
    const bin: string[] = [];
    arr.forEach((byte) => {
      bin.push(globalThis.String.fromCharCode(byte));
    });
    return globalThis.btoa(bin.join(""));
  }
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | bigint | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends { readonly $case: string }
    ? { [K in keyof Omit<T, "$case">]?: DeepPartial<T[K]> } & { readonly $case: T["$case"] }
  : T extends {} ? { [K in Exclude<keyof T, "$type">]?: DeepPartial<T[K]> }
  : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
export type Exact<P, I extends P> = P extends Builtin ? P
  : P & { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P> | "$type">]: never };

function toTimestamp(date: Date): Timestamp {
  const seconds = BigInt(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { $type: "google.protobuf.Timestamp", seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (globalThis.Number(t.seconds.toString()) || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T, V extends string> {
  readonly $type: V;
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create<I extends Exact<DeepPartial<T>, I>>(base?: I): T;
  fromPartial<I extends Exact<DeepPartial<T>, I>>(object: I): T;
}
