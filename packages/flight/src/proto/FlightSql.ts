// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.6.1
//   protoc               unknown
// source: FlightSql.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import { messageTypeRegistry } from "./typeRegistry.js";

export const protobufPackage = "arrow.flight.protocol.sql";

/** Options for CommandGetSqlInfo. */
export enum SqlInfo {
  /** FLIGHT_SQL_SERVER_NAME - Retrieves a UTF-8 string with the name of the Flight SQL Server. */
  FLIGHT_SQL_SERVER_NAME = 0,
  /** FLIGHT_SQL_SERVER_VERSION - Retrieves a UTF-8 string with the native version of the Flight SQL Server. */
  FLIGHT_SQL_SERVER_VERSION = 1,
  /** FLIGHT_SQL_SERVER_ARROW_VERSION - Retrieves a UTF-8 string with the Arrow format version of the Flight SQL Server. */
  FLIGHT_SQL_SERVER_ARROW_VERSION = 2,
  /**
   * FLIGHT_SQL_SERVER_READ_ONLY - Retrieves a boolean value indicating whether the Flight SQL Server is read only.
   *
   * Returns:
   * - false: if read-write
   * - true: if read only
   */
  FLIGHT_SQL_SERVER_READ_ONLY = 3,
  /**
   * FLIGHT_SQL_SERVER_SQL - Retrieves a boolean value indicating whether the Flight SQL Server supports executing
   * SQL queries.
   *
   * Note that the absence of this info (as opposed to a false value) does not necessarily
   * mean that SQL is not supported, as this property was not originally defined.
   */
  FLIGHT_SQL_SERVER_SQL = 4,
  /**
   * FLIGHT_SQL_SERVER_SUBSTRAIT - Retrieves a boolean value indicating whether the Flight SQL Server supports executing
   * Substrait plans.
   */
  FLIGHT_SQL_SERVER_SUBSTRAIT = 5,
  /**
   * FLIGHT_SQL_SERVER_SUBSTRAIT_MIN_VERSION - Retrieves a string value indicating the minimum supported Substrait version, or null
   * if Substrait is not supported.
   */
  FLIGHT_SQL_SERVER_SUBSTRAIT_MIN_VERSION = 6,
  /**
   * FLIGHT_SQL_SERVER_SUBSTRAIT_MAX_VERSION - Retrieves a string value indicating the maximum supported Substrait version, or null
   * if Substrait is not supported.
   */
  FLIGHT_SQL_SERVER_SUBSTRAIT_MAX_VERSION = 7,
  /**
   * FLIGHT_SQL_SERVER_TRANSACTION - Retrieves an int32 indicating whether the Flight SQL Server supports the
   * BeginTransaction/EndTransaction/BeginSavepoint/EndSavepoint actions.
   *
   * Even if this is not supported, the database may still support explicit "BEGIN
   * TRANSACTION"/"COMMIT" SQL statements (see SQL_TRANSACTIONS_SUPPORTED); this property
   * is only about whether the server implements the Flight SQL API endpoints.
   *
   * The possible values are listed in `SqlSupportedTransaction`.
   */
  FLIGHT_SQL_SERVER_TRANSACTION = 8,
  /**
   * FLIGHT_SQL_SERVER_CANCEL - Retrieves a boolean value indicating whether the Flight SQL Server supports explicit
   * query cancellation (the CancelQuery action).
   */
  FLIGHT_SQL_SERVER_CANCEL = 9,
  /**
   * FLIGHT_SQL_SERVER_BULK_INGESTION - Retrieves a boolean value indicating whether the Flight SQL Server supports executing
   * bulk ingestion.
   */
  FLIGHT_SQL_SERVER_BULK_INGESTION = 10,
  /**
   * FLIGHT_SQL_SERVER_INGEST_TRANSACTIONS_SUPPORTED - Retrieves a boolean value indicating whether transactions are supported for bulk ingestion. If not, invoking
   * the method commit in the context of a bulk ingestion is a noop, and the isolation level is
   * `arrow.flight.protocol.sql.SqlTransactionIsolationLevel.TRANSACTION_NONE`.
   *
   * Returns:
   * - false: if bulk ingestion transactions are unsupported;
   * - true: if bulk ingestion transactions are supported.
   */
  FLIGHT_SQL_SERVER_INGEST_TRANSACTIONS_SUPPORTED = 11,
  /**
   * FLIGHT_SQL_SERVER_STATEMENT_TIMEOUT - Retrieves an int32 indicating the timeout (in milliseconds) for prepared statement handles.
   *
   * If 0, there is no timeout.  Servers should reset the timeout when the handle is used in a command.
   */
  FLIGHT_SQL_SERVER_STATEMENT_TIMEOUT = 100,
  /**
   * FLIGHT_SQL_SERVER_TRANSACTION_TIMEOUT - Retrieves an int32 indicating the timeout (in milliseconds) for transactions, since transactions are not tied to a connection.
   *
   * If 0, there is no timeout.  Servers should reset the timeout when the handle is used in a command.
   */
  FLIGHT_SQL_SERVER_TRANSACTION_TIMEOUT = 101,
  /**
   * SQL_DDL_CATALOG - Retrieves a boolean value indicating whether the Flight SQL Server supports CREATE and DROP of catalogs.
   *
   * Returns:
   * - false: if it doesn't support CREATE and DROP of catalogs.
   * - true: if it supports CREATE and DROP of catalogs.
   */
  SQL_DDL_CATALOG = 500,
  /**
   * SQL_DDL_SCHEMA - Retrieves a boolean value indicating whether the Flight SQL Server supports CREATE and DROP of schemas.
   *
   * Returns:
   * - false: if it doesn't support CREATE and DROP of schemas.
   * - true: if it supports CREATE and DROP of schemas.
   */
  SQL_DDL_SCHEMA = 501,
  /**
   * SQL_DDL_TABLE - Indicates whether the Flight SQL Server supports CREATE and DROP of tables.
   *
   * Returns:
   * - false: if it doesn't support CREATE and DROP of tables.
   * - true: if it supports CREATE and DROP of tables.
   */
  SQL_DDL_TABLE = 502,
  /**
   * SQL_IDENTIFIER_CASE - Retrieves a int32 ordinal representing the case sensitivity of catalog, table, schema and table names.
   *
   * The possible values are listed in `arrow.flight.protocol.sql.SqlSupportedCaseSensitivity`.
   */
  SQL_IDENTIFIER_CASE = 503,
  /** SQL_IDENTIFIER_QUOTE_CHAR - Retrieves a UTF-8 string with the supported character(s) used to surround a delimited identifier. */
  SQL_IDENTIFIER_QUOTE_CHAR = 504,
  /**
   * SQL_QUOTED_IDENTIFIER_CASE - Retrieves a int32 describing the case sensitivity of quoted identifiers.
   *
   * The possible values are listed in `arrow.flight.protocol.sql.SqlSupportedCaseSensitivity`.
   */
  SQL_QUOTED_IDENTIFIER_CASE = 505,
  /**
   * SQL_ALL_TABLES_ARE_SELECTABLE - Retrieves a boolean value indicating whether all tables are selectable.
   *
   * Returns:
   * - false: if not all tables are selectable or if none are;
   * - true: if all tables are selectable.
   */
  SQL_ALL_TABLES_ARE_SELECTABLE = 506,
  /**
   * SQL_NULL_ORDERING - Retrieves the null ordering.
   *
   * Returns a int32 ordinal for the null ordering being used, as described in
   * `arrow.flight.protocol.sql.SqlNullOrdering`.
   */
  SQL_NULL_ORDERING = 507,
  /** SQL_KEYWORDS - Retrieves a UTF-8 string list with values of the supported keywords. */
  SQL_KEYWORDS = 508,
  /** SQL_NUMERIC_FUNCTIONS - Retrieves a UTF-8 string list with values of the supported numeric functions. */
  SQL_NUMERIC_FUNCTIONS = 509,
  /** SQL_STRING_FUNCTIONS - Retrieves a UTF-8 string list with values of the supported string functions. */
  SQL_STRING_FUNCTIONS = 510,
  /** SQL_SYSTEM_FUNCTIONS - Retrieves a UTF-8 string list with values of the supported system functions. */
  SQL_SYSTEM_FUNCTIONS = 511,
  /** SQL_DATETIME_FUNCTIONS - Retrieves a UTF-8 string list with values of the supported datetime functions. */
  SQL_DATETIME_FUNCTIONS = 512,
  /**
   * SQL_SEARCH_STRING_ESCAPE - Retrieves the UTF-8 string that can be used to escape wildcard characters.
   * This is the string that can be used to escape '_' or '%' in the catalog search parameters that are a pattern
   * (and therefore use one of the wildcard characters).
   * The '_' character represents any single character; the '%' character represents any sequence of zero or more
   * characters.
   */
  SQL_SEARCH_STRING_ESCAPE = 513,
  /**
   * SQL_EXTRA_NAME_CHARACTERS - Retrieves a UTF-8 string with all the "extra" characters that can be used in unquoted identifier names
   * (those beyond a-z, A-Z, 0-9 and _).
   */
  SQL_EXTRA_NAME_CHARACTERS = 514,
  /**
   * SQL_SUPPORTS_COLUMN_ALIASING - Retrieves a boolean value indicating whether column aliasing is supported.
   * If so, the SQL AS clause can be used to provide names for computed columns or to provide alias names for columns
   * as required.
   *
   * Returns:
   * - false: if column aliasing is unsupported;
   * - true: if column aliasing is supported.
   */
  SQL_SUPPORTS_COLUMN_ALIASING = 515,
  /**
   * SQL_NULL_PLUS_NULL_IS_NULL - Retrieves a boolean value indicating whether concatenations between null and non-null values being
   * null are supported.
   *
   * - Returns:
   * - false: if concatenations between null and non-null values being null are unsupported;
   * - true: if concatenations between null and non-null values being null are supported.
   */
  SQL_NULL_PLUS_NULL_IS_NULL = 516,
  /**
   * SQL_SUPPORTS_CONVERT - Retrieves a map where the key is the type to convert from and the value is a list with the types to convert to,
   * indicating the supported conversions. Each key and each item on the list value is a value to a predefined type on
   * SqlSupportsConvert enum.
   * The returned map will be:  map<int32, list<int32>>
   */
  SQL_SUPPORTS_CONVERT = 517,
  /**
   * SQL_SUPPORTS_TABLE_CORRELATION_NAMES - Retrieves a boolean value indicating whether, when table correlation names are supported,
   * they are restricted to being different from the names of the tables.
   *
   * Returns:
   * - false: if table correlation names are unsupported;
   * - true: if table correlation names are supported.
   */
  SQL_SUPPORTS_TABLE_CORRELATION_NAMES = 518,
  /**
   * SQL_SUPPORTS_DIFFERENT_TABLE_CORRELATION_NAMES - Retrieves a boolean value indicating whether, when table correlation names are supported,
   * they are restricted to being different from the names of the tables.
   *
   * Returns:
   * - false: if different table correlation names are unsupported;
   * - true: if different table correlation names are supported
   */
  SQL_SUPPORTS_DIFFERENT_TABLE_CORRELATION_NAMES = 519,
  /**
   * SQL_SUPPORTS_EXPRESSIONS_IN_ORDER_BY - Retrieves a boolean value indicating whether expressions in ORDER BY lists are supported.
   *
   * Returns:
   * - false: if expressions in ORDER BY are unsupported;
   * - true: if expressions in ORDER BY are supported;
   */
  SQL_SUPPORTS_EXPRESSIONS_IN_ORDER_BY = 520,
  /**
   * SQL_SUPPORTS_ORDER_BY_UNRELATED - Retrieves a boolean value indicating whether using a column that is not in the SELECT statement in a GROUP BY
   * clause is supported.
   *
   * Returns:
   * - false: if using a column that is not in the SELECT statement in a GROUP BY clause is unsupported;
   * - true: if using a column that is not in the SELECT statement in a GROUP BY clause is supported.
   */
  SQL_SUPPORTS_ORDER_BY_UNRELATED = 521,
  /**
   * SQL_SUPPORTED_GROUP_BY - Retrieves the supported GROUP BY commands;
   *
   * Returns an int32 bitmask value representing the supported commands.
   * The returned bitmask should be parsed in order to retrieve the supported commands.
   *
   * For instance:
   * - return 0 (\b0)   => [] (GROUP BY is unsupported);
   * - return 1 (\b1)   => [SQL_GROUP_BY_UNRELATED];
   * - return 2 (\b10)  => [SQL_GROUP_BY_BEYOND_SELECT];
   * - return 3 (\b11)  => [SQL_GROUP_BY_UNRELATED, SQL_GROUP_BY_BEYOND_SELECT].
   * Valid GROUP BY types are described under `arrow.flight.protocol.sql.SqlSupportedGroupBy`.
   */
  SQL_SUPPORTED_GROUP_BY = 522,
  /**
   * SQL_SUPPORTS_LIKE_ESCAPE_CLAUSE - Retrieves a boolean value indicating whether specifying a LIKE escape clause is supported.
   *
   * Returns:
   * - false: if specifying a LIKE escape clause is unsupported;
   * - true: if specifying a LIKE escape clause is supported.
   */
  SQL_SUPPORTS_LIKE_ESCAPE_CLAUSE = 523,
  /**
   * SQL_SUPPORTS_NON_NULLABLE_COLUMNS - Retrieves a boolean value indicating whether columns may be defined as non-nullable.
   *
   * Returns:
   * - false: if columns cannot be defined as non-nullable;
   * - true: if columns may be defined as non-nullable.
   */
  SQL_SUPPORTS_NON_NULLABLE_COLUMNS = 524,
  /**
   * SQL_SUPPORTED_GRAMMAR - Retrieves the supported SQL grammar level as per the ODBC specification.
   *
   * Returns an int32 bitmask value representing the supported SQL grammar level.
   * The returned bitmask should be parsed in order to retrieve the supported grammar levels.
   *
   * For instance:
   * - return 0 (\b0)   => [] (SQL grammar is unsupported);
   * - return 1 (\b1)   => [SQL_MINIMUM_GRAMMAR];
   * - return 2 (\b10)  => [SQL_CORE_GRAMMAR];
   * - return 3 (\b11)  => [SQL_MINIMUM_GRAMMAR, SQL_CORE_GRAMMAR];
   * - return 4 (\b100) => [SQL_EXTENDED_GRAMMAR];
   * - return 5 (\b101) => [SQL_MINIMUM_GRAMMAR, SQL_EXTENDED_GRAMMAR];
   * - return 6 (\b110) => [SQL_CORE_GRAMMAR, SQL_EXTENDED_GRAMMAR];
   * - return 7 (\b111) => [SQL_MINIMUM_GRAMMAR, SQL_CORE_GRAMMAR, SQL_EXTENDED_GRAMMAR].
   * Valid SQL grammar levels are described under `arrow.flight.protocol.sql.SupportedSqlGrammar`.
   */
  SQL_SUPPORTED_GRAMMAR = 525,
  /**
   * SQL_ANSI92_SUPPORTED_LEVEL - Retrieves the supported ANSI92 SQL grammar level.
   *
   * Returns an int32 bitmask value representing the supported ANSI92 SQL grammar level.
   * The returned bitmask should be parsed in order to retrieve the supported commands.
   *
   * For instance:
   * - return 0 (\b0)   => [] (ANSI92 SQL grammar is unsupported);
   * - return 1 (\b1)   => [ANSI92_ENTRY_SQL];
   * - return 2 (\b10)  => [ANSI92_INTERMEDIATE_SQL];
   * - return 3 (\b11)  => [ANSI92_ENTRY_SQL, ANSI92_INTERMEDIATE_SQL];
   * - return 4 (\b100) => [ANSI92_FULL_SQL];
   * - return 5 (\b101) => [ANSI92_ENTRY_SQL, ANSI92_FULL_SQL];
   * - return 6 (\b110) => [ANSI92_INTERMEDIATE_SQL, ANSI92_FULL_SQL];
   * - return 7 (\b111) => [ANSI92_ENTRY_SQL, ANSI92_INTERMEDIATE_SQL, ANSI92_FULL_SQL].
   * Valid ANSI92 SQL grammar levels are described under `arrow.flight.protocol.sql.SupportedAnsi92SqlGrammarLevel`.
   */
  SQL_ANSI92_SUPPORTED_LEVEL = 526,
  /**
   * SQL_SUPPORTS_INTEGRITY_ENHANCEMENT_FACILITY - Retrieves a boolean value indicating whether the SQL Integrity Enhancement Facility is supported.
   *
   * Returns:
   * - false: if the SQL Integrity Enhancement Facility is supported;
   * - true: if the SQL Integrity Enhancement Facility is supported.
   */
  SQL_SUPPORTS_INTEGRITY_ENHANCEMENT_FACILITY = 527,
  /**
   * SQL_OUTER_JOINS_SUPPORT_LEVEL - Retrieves the support level for SQL OUTER JOINs.
   *
   * Returns a int32 ordinal for the SQL ordering being used, as described in
   * `arrow.flight.protocol.sql.SqlOuterJoinsSupportLevel`.
   */
  SQL_OUTER_JOINS_SUPPORT_LEVEL = 528,
  /** SQL_SCHEMA_TERM - Retrieves a UTF-8 string with the preferred term for "schema". */
  SQL_SCHEMA_TERM = 529,
  /** SQL_PROCEDURE_TERM - Retrieves a UTF-8 string with the preferred term for "procedure". */
  SQL_PROCEDURE_TERM = 530,
  /**
   * SQL_CATALOG_TERM - Retrieves a UTF-8 string with the preferred term for "catalog".
   * If a empty string is returned its assumed that the server does NOT supports catalogs.
   */
  SQL_CATALOG_TERM = 531,
  /**
   * SQL_CATALOG_AT_START - Retrieves a boolean value indicating whether a catalog appears at the start of a fully qualified table name.
   *
   * - false: if a catalog does not appear at the start of a fully qualified table name;
   * - true: if a catalog appears at the start of a fully qualified table name.
   */
  SQL_CATALOG_AT_START = 532,
  /**
   * SQL_SCHEMAS_SUPPORTED_ACTIONS - Retrieves the supported actions for a SQL schema.
   *
   * Returns an int32 bitmask value representing the supported actions for a SQL schema.
   * The returned bitmask should be parsed in order to retrieve the supported actions for a SQL schema.
   *
   * For instance:
   * - return 0 (\b0)   => [] (no supported actions for SQL schema);
   * - return 1 (\b1)   => [SQL_ELEMENT_IN_PROCEDURE_CALLS];
   * - return 2 (\b10)  => [SQL_ELEMENT_IN_INDEX_DEFINITIONS];
   * - return 3 (\b11)  => [SQL_ELEMENT_IN_PROCEDURE_CALLS, SQL_ELEMENT_IN_INDEX_DEFINITIONS];
   * - return 4 (\b100) => [SQL_ELEMENT_IN_PRIVILEGE_DEFINITIONS];
   * - return 5 (\b101) => [SQL_ELEMENT_IN_PROCEDURE_CALLS, SQL_ELEMENT_IN_PRIVILEGE_DEFINITIONS];
   * - return 6 (\b110) => [SQL_ELEMENT_IN_INDEX_DEFINITIONS, SQL_ELEMENT_IN_PRIVILEGE_DEFINITIONS];
   * - return 7 (\b111) => [SQL_ELEMENT_IN_PROCEDURE_CALLS, SQL_ELEMENT_IN_INDEX_DEFINITIONS, SQL_ELEMENT_IN_PRIVILEGE_DEFINITIONS].
   * Valid actions for a SQL schema described under `arrow.flight.protocol.sql.SqlSupportedElementActions`.
   */
  SQL_SCHEMAS_SUPPORTED_ACTIONS = 533,
  /**
   * SQL_CATALOGS_SUPPORTED_ACTIONS - Retrieves the supported actions for a SQL schema.
   *
   * Returns an int32 bitmask value representing the supported actions for a SQL catalog.
   * The returned bitmask should be parsed in order to retrieve the supported actions for a SQL catalog.
   *
   * For instance:
   * - return 0 (\b0)   => [] (no supported actions for SQL catalog);
   * - return 1 (\b1)   => [SQL_ELEMENT_IN_PROCEDURE_CALLS];
   * - return 2 (\b10)  => [SQL_ELEMENT_IN_INDEX_DEFINITIONS];
   * - return 3 (\b11)  => [SQL_ELEMENT_IN_PROCEDURE_CALLS, SQL_ELEMENT_IN_INDEX_DEFINITIONS];
   * - return 4 (\b100) => [SQL_ELEMENT_IN_PRIVILEGE_DEFINITIONS];
   * - return 5 (\b101) => [SQL_ELEMENT_IN_PROCEDURE_CALLS, SQL_ELEMENT_IN_PRIVILEGE_DEFINITIONS];
   * - return 6 (\b110) => [SQL_ELEMENT_IN_INDEX_DEFINITIONS, SQL_ELEMENT_IN_PRIVILEGE_DEFINITIONS];
   * - return 7 (\b111) => [SQL_ELEMENT_IN_PROCEDURE_CALLS, SQL_ELEMENT_IN_INDEX_DEFINITIONS, SQL_ELEMENT_IN_PRIVILEGE_DEFINITIONS].
   * Valid actions for a SQL catalog are described under `arrow.flight.protocol.sql.SqlSupportedElementActions`.
   */
  SQL_CATALOGS_SUPPORTED_ACTIONS = 534,
  /**
   * SQL_SUPPORTED_POSITIONED_COMMANDS - Retrieves the supported SQL positioned commands.
   *
   * Returns an int32 bitmask value representing the supported SQL positioned commands.
   * The returned bitmask should be parsed in order to retrieve the supported SQL positioned commands.
   *
   * For instance:
   * - return 0 (\b0)   => [] (no supported SQL positioned commands);
   * - return 1 (\b1)   => [SQL_POSITIONED_DELETE];
   * - return 2 (\b10)  => [SQL_POSITIONED_UPDATE];
   * - return 3 (\b11)  => [SQL_POSITIONED_DELETE, SQL_POSITIONED_UPDATE].
   * Valid SQL positioned commands are described under `arrow.flight.protocol.sql.SqlSupportedPositionedCommands`.
   */
  SQL_SUPPORTED_POSITIONED_COMMANDS = 535,
  /**
   * SQL_SELECT_FOR_UPDATE_SUPPORTED - Retrieves a boolean value indicating whether SELECT FOR UPDATE statements are supported.
   *
   * Returns:
   * - false: if SELECT FOR UPDATE statements are unsupported;
   * - true: if SELECT FOR UPDATE statements are supported.
   */
  SQL_SELECT_FOR_UPDATE_SUPPORTED = 536,
  /**
   * SQL_STORED_PROCEDURES_SUPPORTED - Retrieves a boolean value indicating whether stored procedure calls that use the stored procedure escape syntax
   * are supported.
   *
   * Returns:
   * - false: if stored procedure calls that use the stored procedure escape syntax are unsupported;
   * - true: if stored procedure calls that use the stored procedure escape syntax are supported.
   */
  SQL_STORED_PROCEDURES_SUPPORTED = 537,
  /**
   * SQL_SUPPORTED_SUBQUERIES - Retrieves the supported SQL subqueries.
   *
   * Returns an int32 bitmask value representing the supported SQL subqueries.
   * The returned bitmask should be parsed in order to retrieve the supported SQL subqueries.
   *
   * For instance:
   * - return 0   (\b0)     => [] (no supported SQL subqueries);
   * - return 1   (\b1)     => [SQL_SUBQUERIES_IN_COMPARISONS];
   * - return 2   (\b10)    => [SQL_SUBQUERIES_IN_EXISTS];
   * - return 3   (\b11)    => [SQL_SUBQUERIES_IN_COMPARISONS, SQL_SUBQUERIES_IN_EXISTS];
   * - return 4   (\b100)   => [SQL_SUBQUERIES_IN_INS];
   * - return 5   (\b101)   => [SQL_SUBQUERIES_IN_COMPARISONS, SQL_SUBQUERIES_IN_INS];
   * - return 6   (\b110)   => [SQL_SUBQUERIES_IN_INS, SQL_SUBQUERIES_IN_EXISTS];
   * - return 7   (\b111)   => [SQL_SUBQUERIES_IN_COMPARISONS, SQL_SUBQUERIES_IN_EXISTS, SQL_SUBQUERIES_IN_INS];
   * - return 8   (\b1000)  => [SQL_SUBQUERIES_IN_QUANTIFIEDS];
   * - return 9   (\b1001)  => [SQL_SUBQUERIES_IN_COMPARISONS, SQL_SUBQUERIES_IN_QUANTIFIEDS];
   * - return 10  (\b1010)  => [SQL_SUBQUERIES_IN_EXISTS, SQL_SUBQUERIES_IN_QUANTIFIEDS];
   * - return 11  (\b1011)  => [SQL_SUBQUERIES_IN_COMPARISONS, SQL_SUBQUERIES_IN_EXISTS, SQL_SUBQUERIES_IN_QUANTIFIEDS];
   * - return 12  (\b1100)  => [SQL_SUBQUERIES_IN_INS, SQL_SUBQUERIES_IN_QUANTIFIEDS];
   * - return 13  (\b1101)  => [SQL_SUBQUERIES_IN_COMPARISONS, SQL_SUBQUERIES_IN_INS, SQL_SUBQUERIES_IN_QUANTIFIEDS];
   * - return 14  (\b1110)  => [SQL_SUBQUERIES_IN_EXISTS, SQL_SUBQUERIES_IN_INS, SQL_SUBQUERIES_IN_QUANTIFIEDS];
   * - return 15  (\b1111)  => [SQL_SUBQUERIES_IN_COMPARISONS, SQL_SUBQUERIES_IN_EXISTS, SQL_SUBQUERIES_IN_INS, SQL_SUBQUERIES_IN_QUANTIFIEDS];
   * - ...
   * Valid SQL subqueries are described under `arrow.flight.protocol.sql.SqlSupportedSubqueries`.
   */
  SQL_SUPPORTED_SUBQUERIES = 538,
  /**
   * SQL_CORRELATED_SUBQUERIES_SUPPORTED - Retrieves a boolean value indicating whether correlated subqueries are supported.
   *
   * Returns:
   * - false: if correlated subqueries are unsupported;
   * - true: if correlated subqueries are supported.
   */
  SQL_CORRELATED_SUBQUERIES_SUPPORTED = 539,
  /**
   * SQL_SUPPORTED_UNIONS - Retrieves the supported SQL UNIONs.
   *
   * Returns an int32 bitmask value representing the supported SQL UNIONs.
   * The returned bitmask should be parsed in order to retrieve the supported SQL UNIONs.
   *
   * For instance:
   * - return 0 (\b0)   => [] (no supported SQL positioned commands);
   * - return 1 (\b1)   => [SQL_UNION];
   * - return 2 (\b10)  => [SQL_UNION_ALL];
   * - return 3 (\b11)  => [SQL_UNION, SQL_UNION_ALL].
   * Valid SQL positioned commands are described under `arrow.flight.protocol.sql.SqlSupportedUnions`.
   */
  SQL_SUPPORTED_UNIONS = 540,
  /** SQL_MAX_BINARY_LITERAL_LENGTH - Retrieves a int64 value representing the maximum number of hex characters allowed in an inline binary literal. */
  SQL_MAX_BINARY_LITERAL_LENGTH = 541,
  /** SQL_MAX_CHAR_LITERAL_LENGTH - Retrieves a int64 value representing the maximum number of characters allowed for a character literal. */
  SQL_MAX_CHAR_LITERAL_LENGTH = 542,
  /** SQL_MAX_COLUMN_NAME_LENGTH - Retrieves a int64 value representing the maximum number of characters allowed for a column name. */
  SQL_MAX_COLUMN_NAME_LENGTH = 543,
  /** SQL_MAX_COLUMNS_IN_GROUP_BY - Retrieves a int64 value representing the maximum number of columns allowed in a GROUP BY clause. */
  SQL_MAX_COLUMNS_IN_GROUP_BY = 544,
  /** SQL_MAX_COLUMNS_IN_INDEX - Retrieves a int64 value representing the maximum number of columns allowed in an index. */
  SQL_MAX_COLUMNS_IN_INDEX = 545,
  /** SQL_MAX_COLUMNS_IN_ORDER_BY - Retrieves a int64 value representing the maximum number of columns allowed in an ORDER BY clause. */
  SQL_MAX_COLUMNS_IN_ORDER_BY = 546,
  /** SQL_MAX_COLUMNS_IN_SELECT - Retrieves a int64 value representing the maximum number of columns allowed in a SELECT list. */
  SQL_MAX_COLUMNS_IN_SELECT = 547,
  /** SQL_MAX_COLUMNS_IN_TABLE - Retrieves a int64 value representing the maximum number of columns allowed in a table. */
  SQL_MAX_COLUMNS_IN_TABLE = 548,
  /** SQL_MAX_CONNECTIONS - Retrieves a int64 value representing the maximum number of concurrent connections possible. */
  SQL_MAX_CONNECTIONS = 549,
  /** SQL_MAX_CURSOR_NAME_LENGTH - Retrieves a int64 value the maximum number of characters allowed in a cursor name. */
  SQL_MAX_CURSOR_NAME_LENGTH = 550,
  /**
   * SQL_MAX_INDEX_LENGTH - Retrieves a int64 value representing the maximum number of bytes allowed for an index,
   * including all of the parts of the index.
   */
  SQL_MAX_INDEX_LENGTH = 551,
  /** SQL_DB_SCHEMA_NAME_LENGTH - Retrieves a int64 value representing the maximum number of characters allowed in a schema name. */
  SQL_DB_SCHEMA_NAME_LENGTH = 552,
  /** SQL_MAX_PROCEDURE_NAME_LENGTH - Retrieves a int64 value representing the maximum number of characters allowed in a procedure name. */
  SQL_MAX_PROCEDURE_NAME_LENGTH = 553,
  /** SQL_MAX_CATALOG_NAME_LENGTH - Retrieves a int64 value representing the maximum number of characters allowed in a catalog name. */
  SQL_MAX_CATALOG_NAME_LENGTH = 554,
  /** SQL_MAX_ROW_SIZE - Retrieves a int64 value representing the maximum number of bytes allowed in a single row. */
  SQL_MAX_ROW_SIZE = 555,
  /**
   * SQL_MAX_ROW_SIZE_INCLUDES_BLOBS - Retrieves a boolean indicating whether the return value for the JDBC method getMaxRowSize includes the SQL
   * data types LONGVARCHAR and LONGVARBINARY.
   *
   * Returns:
   * - false: if return value for the JDBC method getMaxRowSize does
   *          not include the SQL data types LONGVARCHAR and LONGVARBINARY;
   * - true: if return value for the JDBC method getMaxRowSize includes
   *         the SQL data types LONGVARCHAR and LONGVARBINARY.
   */
  SQL_MAX_ROW_SIZE_INCLUDES_BLOBS = 556,
  /**
   * SQL_MAX_STATEMENT_LENGTH - Retrieves a int64 value representing the maximum number of characters allowed for an SQL statement;
   * a result of 0 (zero) means that there is no limit or the limit is not known.
   */
  SQL_MAX_STATEMENT_LENGTH = 557,
  /** SQL_MAX_STATEMENTS - Retrieves a int64 value representing the maximum number of active statements that can be open at the same time. */
  SQL_MAX_STATEMENTS = 558,
  /** SQL_MAX_TABLE_NAME_LENGTH - Retrieves a int64 value representing the maximum number of characters allowed in a table name. */
  SQL_MAX_TABLE_NAME_LENGTH = 559,
  /** SQL_MAX_TABLES_IN_SELECT - Retrieves a int64 value representing the maximum number of tables allowed in a SELECT statement. */
  SQL_MAX_TABLES_IN_SELECT = 560,
  /** SQL_MAX_USERNAME_LENGTH - Retrieves a int64 value representing the maximum number of characters allowed in a user name. */
  SQL_MAX_USERNAME_LENGTH = 561,
  /**
   * SQL_DEFAULT_TRANSACTION_ISOLATION - Retrieves this database's default transaction isolation level as described in
   * `arrow.flight.protocol.sql.SqlTransactionIsolationLevel`.
   *
   * Returns a int32 ordinal for the SQL transaction isolation level.
   */
  SQL_DEFAULT_TRANSACTION_ISOLATION = 562,
  /**
   * SQL_TRANSACTIONS_SUPPORTED - Retrieves a boolean value indicating whether transactions are supported. If not, invoking the method commit is a
   * noop, and the isolation level is `arrow.flight.protocol.sql.SqlTransactionIsolationLevel.TRANSACTION_NONE`.
   *
   * Returns:
   * - false: if transactions are unsupported;
   * - true: if transactions are supported.
   */
  SQL_TRANSACTIONS_SUPPORTED = 563,
  /**
   * SQL_SUPPORTED_TRANSACTIONS_ISOLATION_LEVELS - Retrieves the supported transactions isolation levels.
   *
   * Returns an int32 bitmask value representing the supported transactions isolation levels.
   * The returned bitmask should be parsed in order to retrieve the supported transactions isolation levels.
   *
   * For instance:
   * - return 0   (\b0)     => [] (no supported SQL transactions isolation levels);
   * - return 1   (\b1)     => [SQL_TRANSACTION_NONE];
   * - return 2   (\b10)    => [SQL_TRANSACTION_READ_UNCOMMITTED];
   * - return 3   (\b11)    => [SQL_TRANSACTION_NONE, SQL_TRANSACTION_READ_UNCOMMITTED];
   * - return 4   (\b100)   => [SQL_TRANSACTION_REPEATABLE_READ];
   * - return 5   (\b101)   => [SQL_TRANSACTION_NONE, SQL_TRANSACTION_REPEATABLE_READ];
   * - return 6   (\b110)   => [SQL_TRANSACTION_READ_UNCOMMITTED, SQL_TRANSACTION_REPEATABLE_READ];
   * - return 7   (\b111)   => [SQL_TRANSACTION_NONE, SQL_TRANSACTION_READ_UNCOMMITTED, SQL_TRANSACTION_REPEATABLE_READ];
   * - return 8   (\b1000)  => [SQL_TRANSACTION_REPEATABLE_READ];
   * - return 9   (\b1001)  => [SQL_TRANSACTION_NONE, SQL_TRANSACTION_REPEATABLE_READ];
   * - return 10  (\b1010)  => [SQL_TRANSACTION_READ_UNCOMMITTED, SQL_TRANSACTION_REPEATABLE_READ];
   * - return 11  (\b1011)  => [SQL_TRANSACTION_NONE, SQL_TRANSACTION_READ_UNCOMMITTED, SQL_TRANSACTION_REPEATABLE_READ];
   * - return 12  (\b1100)  => [SQL_TRANSACTION_REPEATABLE_READ, SQL_TRANSACTION_REPEATABLE_READ];
   * - return 13  (\b1101)  => [SQL_TRANSACTION_NONE, SQL_TRANSACTION_REPEATABLE_READ, SQL_TRANSACTION_REPEATABLE_READ];
   * - return 14  (\b1110)  => [SQL_TRANSACTION_READ_UNCOMMITTED, SQL_TRANSACTION_REPEATABLE_READ, SQL_TRANSACTION_REPEATABLE_READ];
   * - return 15  (\b1111)  => [SQL_TRANSACTION_NONE, SQL_TRANSACTION_READ_UNCOMMITTED, SQL_TRANSACTION_REPEATABLE_READ, SQL_TRANSACTION_REPEATABLE_READ];
   * - return 16  (\b10000) => [SQL_TRANSACTION_SERIALIZABLE];
   * - ...
   * Valid SQL positioned commands are described under `arrow.flight.protocol.sql.SqlTransactionIsolationLevel`.
   */
  SQL_SUPPORTED_TRANSACTIONS_ISOLATION_LEVELS = 564,
  /**
   * SQL_DATA_DEFINITION_CAUSES_TRANSACTION_COMMIT - Retrieves a boolean value indicating whether a data definition statement within a transaction forces
   * the transaction to commit.
   *
   * Returns:
   * - false: if a data definition statement within a transaction does not force the transaction to commit;
   * - true: if a data definition statement within a transaction forces the transaction to commit.
   */
  SQL_DATA_DEFINITION_CAUSES_TRANSACTION_COMMIT = 565,
  /**
   * SQL_DATA_DEFINITIONS_IN_TRANSACTIONS_IGNORED - Retrieves a boolean value indicating whether a data definition statement within a transaction is ignored.
   *
   * Returns:
   * - false: if a data definition statement within a transaction is taken into account;
   * - true: a data definition statement within a transaction is ignored.
   */
  SQL_DATA_DEFINITIONS_IN_TRANSACTIONS_IGNORED = 566,
  /**
   * SQL_SUPPORTED_RESULT_SET_TYPES - Retrieves an int32 bitmask value representing the supported result set types.
   * The returned bitmask should be parsed in order to retrieve the supported result set types.
   *
   * For instance:
   * - return 0   (\b0)     => [] (no supported result set types);
   * - return 1   (\b1)     => [SQL_RESULT_SET_TYPE_UNSPECIFIED];
   * - return 2   (\b10)    => [SQL_RESULT_SET_TYPE_FORWARD_ONLY];
   * - return 3   (\b11)    => [SQL_RESULT_SET_TYPE_UNSPECIFIED, SQL_RESULT_SET_TYPE_FORWARD_ONLY];
   * - return 4   (\b100)   => [SQL_RESULT_SET_TYPE_SCROLL_INSENSITIVE];
   * - return 5   (\b101)   => [SQL_RESULT_SET_TYPE_UNSPECIFIED, SQL_RESULT_SET_TYPE_SCROLL_INSENSITIVE];
   * - return 6   (\b110)   => [SQL_RESULT_SET_TYPE_FORWARD_ONLY, SQL_RESULT_SET_TYPE_SCROLL_INSENSITIVE];
   * - return 7   (\b111)   => [SQL_RESULT_SET_TYPE_UNSPECIFIED, SQL_RESULT_SET_TYPE_FORWARD_ONLY, SQL_RESULT_SET_TYPE_SCROLL_INSENSITIVE];
   * - return 8   (\b1000)  => [SQL_RESULT_SET_TYPE_SCROLL_SENSITIVE];
   * - ...
   * Valid result set types are described under `arrow.flight.protocol.sql.SqlSupportedResultSetType`.
   */
  SQL_SUPPORTED_RESULT_SET_TYPES = 567,
  /**
   * SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_UNSPECIFIED - Returns an int32 bitmask value concurrency types supported for
   * `arrow.flight.protocol.sql.SqlSupportedResultSetType.SQL_RESULT_SET_TYPE_UNSPECIFIED`.
   *
   * For instance:
   * - return 0 (\b0)   => [] (no supported concurrency types for this result set type)
   * - return 1 (\b1)   => [SQL_RESULT_SET_CONCURRENCY_UNSPECIFIED]
   * - return 2 (\b10)  => [SQL_RESULT_SET_CONCURRENCY_READ_ONLY]
   * - return 3 (\b11)  => [SQL_RESULT_SET_CONCURRENCY_UNSPECIFIED, SQL_RESULT_SET_CONCURRENCY_READ_ONLY]
   * - return 4 (\b100) => [SQL_RESULT_SET_CONCURRENCY_UPDATABLE]
   * - return 5 (\b101) => [SQL_RESULT_SET_CONCURRENCY_UNSPECIFIED, SQL_RESULT_SET_CONCURRENCY_UPDATABLE]
   * - return 6 (\b110)  => [SQL_RESULT_SET_CONCURRENCY_READ_ONLY, SQL_RESULT_SET_CONCURRENCY_UPDATABLE]
   * - return 7 (\b111)  => [SQL_RESULT_SET_CONCURRENCY_UNSPECIFIED, SQL_RESULT_SET_CONCURRENCY_READ_ONLY, SQL_RESULT_SET_CONCURRENCY_UPDATABLE]
   * Valid result set types are described under `arrow.flight.protocol.sql.SqlSupportedResultSetConcurrency`.
   */
  SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_UNSPECIFIED = 568,
  /**
   * SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_FORWARD_ONLY - Returns an int32 bitmask value concurrency types supported for
   * `arrow.flight.protocol.sql.SqlSupportedResultSetType.SQL_RESULT_SET_TYPE_FORWARD_ONLY`.
   *
   * For instance:
   * - return 0 (\b0)   => [] (no supported concurrency types for this result set type)
   * - return 1 (\b1)   => [SQL_RESULT_SET_CONCURRENCY_UNSPECIFIED]
   * - return 2 (\b10)  => [SQL_RESULT_SET_CONCURRENCY_READ_ONLY]
   * - return 3 (\b11)  => [SQL_RESULT_SET_CONCURRENCY_UNSPECIFIED, SQL_RESULT_SET_CONCURRENCY_READ_ONLY]
   * - return 4 (\b100) => [SQL_RESULT_SET_CONCURRENCY_UPDATABLE]
   * - return 5 (\b101) => [SQL_RESULT_SET_CONCURRENCY_UNSPECIFIED, SQL_RESULT_SET_CONCURRENCY_UPDATABLE]
   * - return 6 (\b110)  => [SQL_RESULT_SET_CONCURRENCY_READ_ONLY, SQL_RESULT_SET_CONCURRENCY_UPDATABLE]
   * - return 7 (\b111)  => [SQL_RESULT_SET_CONCURRENCY_UNSPECIFIED, SQL_RESULT_SET_CONCURRENCY_READ_ONLY, SQL_RESULT_SET_CONCURRENCY_UPDATABLE]
   * Valid result set types are described under `arrow.flight.protocol.sql.SqlSupportedResultSetConcurrency`.
   */
  SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_FORWARD_ONLY = 569,
  /**
   * SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_SCROLL_SENSITIVE - Returns an int32 bitmask value concurrency types supported for
   * `arrow.flight.protocol.sql.SqlSupportedResultSetType.SQL_RESULT_SET_TYPE_SCROLL_SENSITIVE`.
   *
   * For instance:
   * - return 0 (\b0)   => [] (no supported concurrency types for this result set type)
   * - return 1 (\b1)   => [SQL_RESULT_SET_CONCURRENCY_UNSPECIFIED]
   * - return 2 (\b10)  => [SQL_RESULT_SET_CONCURRENCY_READ_ONLY]
   * - return 3 (\b11)  => [SQL_RESULT_SET_CONCURRENCY_UNSPECIFIED, SQL_RESULT_SET_CONCURRENCY_READ_ONLY]
   * - return 4 (\b100) => [SQL_RESULT_SET_CONCURRENCY_UPDATABLE]
   * - return 5 (\b101) => [SQL_RESULT_SET_CONCURRENCY_UNSPECIFIED, SQL_RESULT_SET_CONCURRENCY_UPDATABLE]
   * - return 6 (\b110)  => [SQL_RESULT_SET_CONCURRENCY_READ_ONLY, SQL_RESULT_SET_CONCURRENCY_UPDATABLE]
   * - return 7 (\b111)  => [SQL_RESULT_SET_CONCURRENCY_UNSPECIFIED, SQL_RESULT_SET_CONCURRENCY_READ_ONLY, SQL_RESULT_SET_CONCURRENCY_UPDATABLE]
   * Valid result set types are described under `arrow.flight.protocol.sql.SqlSupportedResultSetConcurrency`.
   */
  SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_SCROLL_SENSITIVE = 570,
  /**
   * SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_SCROLL_INSENSITIVE - Returns an int32 bitmask value concurrency types supported for
   * `arrow.flight.protocol.sql.SqlSupportedResultSetType.SQL_RESULT_SET_TYPE_SCROLL_INSENSITIVE`.
   *
   * For instance:
   * - return 0 (\b0)   => [] (no supported concurrency types for this result set type)
   * - return 1 (\b1)   => [SQL_RESULT_SET_CONCURRENCY_UNSPECIFIED]
   * - return 2 (\b10)  => [SQL_RESULT_SET_CONCURRENCY_READ_ONLY]
   * - return 3 (\b11)  => [SQL_RESULT_SET_CONCURRENCY_UNSPECIFIED, SQL_RESULT_SET_CONCURRENCY_READ_ONLY]
   * - return 4 (\b100) => [SQL_RESULT_SET_CONCURRENCY_UPDATABLE]
   * - return 5 (\b101) => [SQL_RESULT_SET_CONCURRENCY_UNSPECIFIED, SQL_RESULT_SET_CONCURRENCY_UPDATABLE]
   * - return 6 (\b110)  => [SQL_RESULT_SET_CONCURRENCY_READ_ONLY, SQL_RESULT_SET_CONCURRENCY_UPDATABLE]
   * - return 7 (\b111)  => [SQL_RESULT_SET_CONCURRENCY_UNSPECIFIED, SQL_RESULT_SET_CONCURRENCY_READ_ONLY, SQL_RESULT_SET_CONCURRENCY_UPDATABLE]
   * Valid result set types are described under `arrow.flight.protocol.sql.SqlSupportedResultSetConcurrency`.
   */
  SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_SCROLL_INSENSITIVE = 571,
  /**
   * SQL_BATCH_UPDATES_SUPPORTED - Retrieves a boolean value indicating whether this database supports batch updates.
   *
   * - false: if this database does not support batch updates;
   * - true: if this database supports batch updates.
   */
  SQL_BATCH_UPDATES_SUPPORTED = 572,
  /**
   * SQL_SAVEPOINTS_SUPPORTED - Retrieves a boolean value indicating whether this database supports savepoints.
   *
   * Returns:
   * - false: if this database does not support savepoints;
   * - true: if this database supports savepoints.
   */
  SQL_SAVEPOINTS_SUPPORTED = 573,
  /**
   * SQL_NAMED_PARAMETERS_SUPPORTED - Retrieves a boolean value indicating whether named parameters are supported in callable statements.
   *
   * Returns:
   * - false: if named parameters in callable statements are unsupported;
   * - true: if named parameters in callable statements are supported.
   */
  SQL_NAMED_PARAMETERS_SUPPORTED = 574,
  /**
   * SQL_LOCATORS_UPDATE_COPY - Retrieves a boolean value indicating whether updates made to a LOB are made on a copy or directly to the LOB.
   *
   * Returns:
   * - false: if updates made to a LOB are made directly to the LOB;
   * - true: if updates made to a LOB are made on a copy.
   */
  SQL_LOCATORS_UPDATE_COPY = 575,
  /**
   * SQL_STORED_FUNCTIONS_USING_CALL_SYNTAX_SUPPORTED - Retrieves a boolean value indicating whether invoking user-defined or vendor functions
   * using the stored procedure escape syntax is supported.
   *
   * Returns:
   * - false: if invoking user-defined or vendor functions using the stored procedure escape syntax is unsupported;
   * - true: if invoking user-defined or vendor functions using the stored procedure escape syntax is supported.
   */
  SQL_STORED_FUNCTIONS_USING_CALL_SYNTAX_SUPPORTED = 576,
  UNRECOGNIZED = -1,
}

export function sqlInfoFromJSON(object: any): SqlInfo {
  switch (object) {
    case 0:
    case "FLIGHT_SQL_SERVER_NAME":
      return SqlInfo.FLIGHT_SQL_SERVER_NAME;
    case 1:
    case "FLIGHT_SQL_SERVER_VERSION":
      return SqlInfo.FLIGHT_SQL_SERVER_VERSION;
    case 2:
    case "FLIGHT_SQL_SERVER_ARROW_VERSION":
      return SqlInfo.FLIGHT_SQL_SERVER_ARROW_VERSION;
    case 3:
    case "FLIGHT_SQL_SERVER_READ_ONLY":
      return SqlInfo.FLIGHT_SQL_SERVER_READ_ONLY;
    case 4:
    case "FLIGHT_SQL_SERVER_SQL":
      return SqlInfo.FLIGHT_SQL_SERVER_SQL;
    case 5:
    case "FLIGHT_SQL_SERVER_SUBSTRAIT":
      return SqlInfo.FLIGHT_SQL_SERVER_SUBSTRAIT;
    case 6:
    case "FLIGHT_SQL_SERVER_SUBSTRAIT_MIN_VERSION":
      return SqlInfo.FLIGHT_SQL_SERVER_SUBSTRAIT_MIN_VERSION;
    case 7:
    case "FLIGHT_SQL_SERVER_SUBSTRAIT_MAX_VERSION":
      return SqlInfo.FLIGHT_SQL_SERVER_SUBSTRAIT_MAX_VERSION;
    case 8:
    case "FLIGHT_SQL_SERVER_TRANSACTION":
      return SqlInfo.FLIGHT_SQL_SERVER_TRANSACTION;
    case 9:
    case "FLIGHT_SQL_SERVER_CANCEL":
      return SqlInfo.FLIGHT_SQL_SERVER_CANCEL;
    case 10:
    case "FLIGHT_SQL_SERVER_BULK_INGESTION":
      return SqlInfo.FLIGHT_SQL_SERVER_BULK_INGESTION;
    case 11:
    case "FLIGHT_SQL_SERVER_INGEST_TRANSACTIONS_SUPPORTED":
      return SqlInfo.FLIGHT_SQL_SERVER_INGEST_TRANSACTIONS_SUPPORTED;
    case 100:
    case "FLIGHT_SQL_SERVER_STATEMENT_TIMEOUT":
      return SqlInfo.FLIGHT_SQL_SERVER_STATEMENT_TIMEOUT;
    case 101:
    case "FLIGHT_SQL_SERVER_TRANSACTION_TIMEOUT":
      return SqlInfo.FLIGHT_SQL_SERVER_TRANSACTION_TIMEOUT;
    case 500:
    case "SQL_DDL_CATALOG":
      return SqlInfo.SQL_DDL_CATALOG;
    case 501:
    case "SQL_DDL_SCHEMA":
      return SqlInfo.SQL_DDL_SCHEMA;
    case 502:
    case "SQL_DDL_TABLE":
      return SqlInfo.SQL_DDL_TABLE;
    case 503:
    case "SQL_IDENTIFIER_CASE":
      return SqlInfo.SQL_IDENTIFIER_CASE;
    case 504:
    case "SQL_IDENTIFIER_QUOTE_CHAR":
      return SqlInfo.SQL_IDENTIFIER_QUOTE_CHAR;
    case 505:
    case "SQL_QUOTED_IDENTIFIER_CASE":
      return SqlInfo.SQL_QUOTED_IDENTIFIER_CASE;
    case 506:
    case "SQL_ALL_TABLES_ARE_SELECTABLE":
      return SqlInfo.SQL_ALL_TABLES_ARE_SELECTABLE;
    case 507:
    case "SQL_NULL_ORDERING":
      return SqlInfo.SQL_NULL_ORDERING;
    case 508:
    case "SQL_KEYWORDS":
      return SqlInfo.SQL_KEYWORDS;
    case 509:
    case "SQL_NUMERIC_FUNCTIONS":
      return SqlInfo.SQL_NUMERIC_FUNCTIONS;
    case 510:
    case "SQL_STRING_FUNCTIONS":
      return SqlInfo.SQL_STRING_FUNCTIONS;
    case 511:
    case "SQL_SYSTEM_FUNCTIONS":
      return SqlInfo.SQL_SYSTEM_FUNCTIONS;
    case 512:
    case "SQL_DATETIME_FUNCTIONS":
      return SqlInfo.SQL_DATETIME_FUNCTIONS;
    case 513:
    case "SQL_SEARCH_STRING_ESCAPE":
      return SqlInfo.SQL_SEARCH_STRING_ESCAPE;
    case 514:
    case "SQL_EXTRA_NAME_CHARACTERS":
      return SqlInfo.SQL_EXTRA_NAME_CHARACTERS;
    case 515:
    case "SQL_SUPPORTS_COLUMN_ALIASING":
      return SqlInfo.SQL_SUPPORTS_COLUMN_ALIASING;
    case 516:
    case "SQL_NULL_PLUS_NULL_IS_NULL":
      return SqlInfo.SQL_NULL_PLUS_NULL_IS_NULL;
    case 517:
    case "SQL_SUPPORTS_CONVERT":
      return SqlInfo.SQL_SUPPORTS_CONVERT;
    case 518:
    case "SQL_SUPPORTS_TABLE_CORRELATION_NAMES":
      return SqlInfo.SQL_SUPPORTS_TABLE_CORRELATION_NAMES;
    case 519:
    case "SQL_SUPPORTS_DIFFERENT_TABLE_CORRELATION_NAMES":
      return SqlInfo.SQL_SUPPORTS_DIFFERENT_TABLE_CORRELATION_NAMES;
    case 520:
    case "SQL_SUPPORTS_EXPRESSIONS_IN_ORDER_BY":
      return SqlInfo.SQL_SUPPORTS_EXPRESSIONS_IN_ORDER_BY;
    case 521:
    case "SQL_SUPPORTS_ORDER_BY_UNRELATED":
      return SqlInfo.SQL_SUPPORTS_ORDER_BY_UNRELATED;
    case 522:
    case "SQL_SUPPORTED_GROUP_BY":
      return SqlInfo.SQL_SUPPORTED_GROUP_BY;
    case 523:
    case "SQL_SUPPORTS_LIKE_ESCAPE_CLAUSE":
      return SqlInfo.SQL_SUPPORTS_LIKE_ESCAPE_CLAUSE;
    case 524:
    case "SQL_SUPPORTS_NON_NULLABLE_COLUMNS":
      return SqlInfo.SQL_SUPPORTS_NON_NULLABLE_COLUMNS;
    case 525:
    case "SQL_SUPPORTED_GRAMMAR":
      return SqlInfo.SQL_SUPPORTED_GRAMMAR;
    case 526:
    case "SQL_ANSI92_SUPPORTED_LEVEL":
      return SqlInfo.SQL_ANSI92_SUPPORTED_LEVEL;
    case 527:
    case "SQL_SUPPORTS_INTEGRITY_ENHANCEMENT_FACILITY":
      return SqlInfo.SQL_SUPPORTS_INTEGRITY_ENHANCEMENT_FACILITY;
    case 528:
    case "SQL_OUTER_JOINS_SUPPORT_LEVEL":
      return SqlInfo.SQL_OUTER_JOINS_SUPPORT_LEVEL;
    case 529:
    case "SQL_SCHEMA_TERM":
      return SqlInfo.SQL_SCHEMA_TERM;
    case 530:
    case "SQL_PROCEDURE_TERM":
      return SqlInfo.SQL_PROCEDURE_TERM;
    case 531:
    case "SQL_CATALOG_TERM":
      return SqlInfo.SQL_CATALOG_TERM;
    case 532:
    case "SQL_CATALOG_AT_START":
      return SqlInfo.SQL_CATALOG_AT_START;
    case 533:
    case "SQL_SCHEMAS_SUPPORTED_ACTIONS":
      return SqlInfo.SQL_SCHEMAS_SUPPORTED_ACTIONS;
    case 534:
    case "SQL_CATALOGS_SUPPORTED_ACTIONS":
      return SqlInfo.SQL_CATALOGS_SUPPORTED_ACTIONS;
    case 535:
    case "SQL_SUPPORTED_POSITIONED_COMMANDS":
      return SqlInfo.SQL_SUPPORTED_POSITIONED_COMMANDS;
    case 536:
    case "SQL_SELECT_FOR_UPDATE_SUPPORTED":
      return SqlInfo.SQL_SELECT_FOR_UPDATE_SUPPORTED;
    case 537:
    case "SQL_STORED_PROCEDURES_SUPPORTED":
      return SqlInfo.SQL_STORED_PROCEDURES_SUPPORTED;
    case 538:
    case "SQL_SUPPORTED_SUBQUERIES":
      return SqlInfo.SQL_SUPPORTED_SUBQUERIES;
    case 539:
    case "SQL_CORRELATED_SUBQUERIES_SUPPORTED":
      return SqlInfo.SQL_CORRELATED_SUBQUERIES_SUPPORTED;
    case 540:
    case "SQL_SUPPORTED_UNIONS":
      return SqlInfo.SQL_SUPPORTED_UNIONS;
    case 541:
    case "SQL_MAX_BINARY_LITERAL_LENGTH":
      return SqlInfo.SQL_MAX_BINARY_LITERAL_LENGTH;
    case 542:
    case "SQL_MAX_CHAR_LITERAL_LENGTH":
      return SqlInfo.SQL_MAX_CHAR_LITERAL_LENGTH;
    case 543:
    case "SQL_MAX_COLUMN_NAME_LENGTH":
      return SqlInfo.SQL_MAX_COLUMN_NAME_LENGTH;
    case 544:
    case "SQL_MAX_COLUMNS_IN_GROUP_BY":
      return SqlInfo.SQL_MAX_COLUMNS_IN_GROUP_BY;
    case 545:
    case "SQL_MAX_COLUMNS_IN_INDEX":
      return SqlInfo.SQL_MAX_COLUMNS_IN_INDEX;
    case 546:
    case "SQL_MAX_COLUMNS_IN_ORDER_BY":
      return SqlInfo.SQL_MAX_COLUMNS_IN_ORDER_BY;
    case 547:
    case "SQL_MAX_COLUMNS_IN_SELECT":
      return SqlInfo.SQL_MAX_COLUMNS_IN_SELECT;
    case 548:
    case "SQL_MAX_COLUMNS_IN_TABLE":
      return SqlInfo.SQL_MAX_COLUMNS_IN_TABLE;
    case 549:
    case "SQL_MAX_CONNECTIONS":
      return SqlInfo.SQL_MAX_CONNECTIONS;
    case 550:
    case "SQL_MAX_CURSOR_NAME_LENGTH":
      return SqlInfo.SQL_MAX_CURSOR_NAME_LENGTH;
    case 551:
    case "SQL_MAX_INDEX_LENGTH":
      return SqlInfo.SQL_MAX_INDEX_LENGTH;
    case 552:
    case "SQL_DB_SCHEMA_NAME_LENGTH":
      return SqlInfo.SQL_DB_SCHEMA_NAME_LENGTH;
    case 553:
    case "SQL_MAX_PROCEDURE_NAME_LENGTH":
      return SqlInfo.SQL_MAX_PROCEDURE_NAME_LENGTH;
    case 554:
    case "SQL_MAX_CATALOG_NAME_LENGTH":
      return SqlInfo.SQL_MAX_CATALOG_NAME_LENGTH;
    case 555:
    case "SQL_MAX_ROW_SIZE":
      return SqlInfo.SQL_MAX_ROW_SIZE;
    case 556:
    case "SQL_MAX_ROW_SIZE_INCLUDES_BLOBS":
      return SqlInfo.SQL_MAX_ROW_SIZE_INCLUDES_BLOBS;
    case 557:
    case "SQL_MAX_STATEMENT_LENGTH":
      return SqlInfo.SQL_MAX_STATEMENT_LENGTH;
    case 558:
    case "SQL_MAX_STATEMENTS":
      return SqlInfo.SQL_MAX_STATEMENTS;
    case 559:
    case "SQL_MAX_TABLE_NAME_LENGTH":
      return SqlInfo.SQL_MAX_TABLE_NAME_LENGTH;
    case 560:
    case "SQL_MAX_TABLES_IN_SELECT":
      return SqlInfo.SQL_MAX_TABLES_IN_SELECT;
    case 561:
    case "SQL_MAX_USERNAME_LENGTH":
      return SqlInfo.SQL_MAX_USERNAME_LENGTH;
    case 562:
    case "SQL_DEFAULT_TRANSACTION_ISOLATION":
      return SqlInfo.SQL_DEFAULT_TRANSACTION_ISOLATION;
    case 563:
    case "SQL_TRANSACTIONS_SUPPORTED":
      return SqlInfo.SQL_TRANSACTIONS_SUPPORTED;
    case 564:
    case "SQL_SUPPORTED_TRANSACTIONS_ISOLATION_LEVELS":
      return SqlInfo.SQL_SUPPORTED_TRANSACTIONS_ISOLATION_LEVELS;
    case 565:
    case "SQL_DATA_DEFINITION_CAUSES_TRANSACTION_COMMIT":
      return SqlInfo.SQL_DATA_DEFINITION_CAUSES_TRANSACTION_COMMIT;
    case 566:
    case "SQL_DATA_DEFINITIONS_IN_TRANSACTIONS_IGNORED":
      return SqlInfo.SQL_DATA_DEFINITIONS_IN_TRANSACTIONS_IGNORED;
    case 567:
    case "SQL_SUPPORTED_RESULT_SET_TYPES":
      return SqlInfo.SQL_SUPPORTED_RESULT_SET_TYPES;
    case 568:
    case "SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_UNSPECIFIED":
      return SqlInfo.SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_UNSPECIFIED;
    case 569:
    case "SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_FORWARD_ONLY":
      return SqlInfo.SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_FORWARD_ONLY;
    case 570:
    case "SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_SCROLL_SENSITIVE":
      return SqlInfo.SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_SCROLL_SENSITIVE;
    case 571:
    case "SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_SCROLL_INSENSITIVE":
      return SqlInfo.SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_SCROLL_INSENSITIVE;
    case 572:
    case "SQL_BATCH_UPDATES_SUPPORTED":
      return SqlInfo.SQL_BATCH_UPDATES_SUPPORTED;
    case 573:
    case "SQL_SAVEPOINTS_SUPPORTED":
      return SqlInfo.SQL_SAVEPOINTS_SUPPORTED;
    case 574:
    case "SQL_NAMED_PARAMETERS_SUPPORTED":
      return SqlInfo.SQL_NAMED_PARAMETERS_SUPPORTED;
    case 575:
    case "SQL_LOCATORS_UPDATE_COPY":
      return SqlInfo.SQL_LOCATORS_UPDATE_COPY;
    case 576:
    case "SQL_STORED_FUNCTIONS_USING_CALL_SYNTAX_SUPPORTED":
      return SqlInfo.SQL_STORED_FUNCTIONS_USING_CALL_SYNTAX_SUPPORTED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlInfo.UNRECOGNIZED;
  }
}

export function sqlInfoToJSON(object: SqlInfo): string {
  switch (object) {
    case SqlInfo.FLIGHT_SQL_SERVER_NAME:
      return "FLIGHT_SQL_SERVER_NAME";
    case SqlInfo.FLIGHT_SQL_SERVER_VERSION:
      return "FLIGHT_SQL_SERVER_VERSION";
    case SqlInfo.FLIGHT_SQL_SERVER_ARROW_VERSION:
      return "FLIGHT_SQL_SERVER_ARROW_VERSION";
    case SqlInfo.FLIGHT_SQL_SERVER_READ_ONLY:
      return "FLIGHT_SQL_SERVER_READ_ONLY";
    case SqlInfo.FLIGHT_SQL_SERVER_SQL:
      return "FLIGHT_SQL_SERVER_SQL";
    case SqlInfo.FLIGHT_SQL_SERVER_SUBSTRAIT:
      return "FLIGHT_SQL_SERVER_SUBSTRAIT";
    case SqlInfo.FLIGHT_SQL_SERVER_SUBSTRAIT_MIN_VERSION:
      return "FLIGHT_SQL_SERVER_SUBSTRAIT_MIN_VERSION";
    case SqlInfo.FLIGHT_SQL_SERVER_SUBSTRAIT_MAX_VERSION:
      return "FLIGHT_SQL_SERVER_SUBSTRAIT_MAX_VERSION";
    case SqlInfo.FLIGHT_SQL_SERVER_TRANSACTION:
      return "FLIGHT_SQL_SERVER_TRANSACTION";
    case SqlInfo.FLIGHT_SQL_SERVER_CANCEL:
      return "FLIGHT_SQL_SERVER_CANCEL";
    case SqlInfo.FLIGHT_SQL_SERVER_BULK_INGESTION:
      return "FLIGHT_SQL_SERVER_BULK_INGESTION";
    case SqlInfo.FLIGHT_SQL_SERVER_INGEST_TRANSACTIONS_SUPPORTED:
      return "FLIGHT_SQL_SERVER_INGEST_TRANSACTIONS_SUPPORTED";
    case SqlInfo.FLIGHT_SQL_SERVER_STATEMENT_TIMEOUT:
      return "FLIGHT_SQL_SERVER_STATEMENT_TIMEOUT";
    case SqlInfo.FLIGHT_SQL_SERVER_TRANSACTION_TIMEOUT:
      return "FLIGHT_SQL_SERVER_TRANSACTION_TIMEOUT";
    case SqlInfo.SQL_DDL_CATALOG:
      return "SQL_DDL_CATALOG";
    case SqlInfo.SQL_DDL_SCHEMA:
      return "SQL_DDL_SCHEMA";
    case SqlInfo.SQL_DDL_TABLE:
      return "SQL_DDL_TABLE";
    case SqlInfo.SQL_IDENTIFIER_CASE:
      return "SQL_IDENTIFIER_CASE";
    case SqlInfo.SQL_IDENTIFIER_QUOTE_CHAR:
      return "SQL_IDENTIFIER_QUOTE_CHAR";
    case SqlInfo.SQL_QUOTED_IDENTIFIER_CASE:
      return "SQL_QUOTED_IDENTIFIER_CASE";
    case SqlInfo.SQL_ALL_TABLES_ARE_SELECTABLE:
      return "SQL_ALL_TABLES_ARE_SELECTABLE";
    case SqlInfo.SQL_NULL_ORDERING:
      return "SQL_NULL_ORDERING";
    case SqlInfo.SQL_KEYWORDS:
      return "SQL_KEYWORDS";
    case SqlInfo.SQL_NUMERIC_FUNCTIONS:
      return "SQL_NUMERIC_FUNCTIONS";
    case SqlInfo.SQL_STRING_FUNCTIONS:
      return "SQL_STRING_FUNCTIONS";
    case SqlInfo.SQL_SYSTEM_FUNCTIONS:
      return "SQL_SYSTEM_FUNCTIONS";
    case SqlInfo.SQL_DATETIME_FUNCTIONS:
      return "SQL_DATETIME_FUNCTIONS";
    case SqlInfo.SQL_SEARCH_STRING_ESCAPE:
      return "SQL_SEARCH_STRING_ESCAPE";
    case SqlInfo.SQL_EXTRA_NAME_CHARACTERS:
      return "SQL_EXTRA_NAME_CHARACTERS";
    case SqlInfo.SQL_SUPPORTS_COLUMN_ALIASING:
      return "SQL_SUPPORTS_COLUMN_ALIASING";
    case SqlInfo.SQL_NULL_PLUS_NULL_IS_NULL:
      return "SQL_NULL_PLUS_NULL_IS_NULL";
    case SqlInfo.SQL_SUPPORTS_CONVERT:
      return "SQL_SUPPORTS_CONVERT";
    case SqlInfo.SQL_SUPPORTS_TABLE_CORRELATION_NAMES:
      return "SQL_SUPPORTS_TABLE_CORRELATION_NAMES";
    case SqlInfo.SQL_SUPPORTS_DIFFERENT_TABLE_CORRELATION_NAMES:
      return "SQL_SUPPORTS_DIFFERENT_TABLE_CORRELATION_NAMES";
    case SqlInfo.SQL_SUPPORTS_EXPRESSIONS_IN_ORDER_BY:
      return "SQL_SUPPORTS_EXPRESSIONS_IN_ORDER_BY";
    case SqlInfo.SQL_SUPPORTS_ORDER_BY_UNRELATED:
      return "SQL_SUPPORTS_ORDER_BY_UNRELATED";
    case SqlInfo.SQL_SUPPORTED_GROUP_BY:
      return "SQL_SUPPORTED_GROUP_BY";
    case SqlInfo.SQL_SUPPORTS_LIKE_ESCAPE_CLAUSE:
      return "SQL_SUPPORTS_LIKE_ESCAPE_CLAUSE";
    case SqlInfo.SQL_SUPPORTS_NON_NULLABLE_COLUMNS:
      return "SQL_SUPPORTS_NON_NULLABLE_COLUMNS";
    case SqlInfo.SQL_SUPPORTED_GRAMMAR:
      return "SQL_SUPPORTED_GRAMMAR";
    case SqlInfo.SQL_ANSI92_SUPPORTED_LEVEL:
      return "SQL_ANSI92_SUPPORTED_LEVEL";
    case SqlInfo.SQL_SUPPORTS_INTEGRITY_ENHANCEMENT_FACILITY:
      return "SQL_SUPPORTS_INTEGRITY_ENHANCEMENT_FACILITY";
    case SqlInfo.SQL_OUTER_JOINS_SUPPORT_LEVEL:
      return "SQL_OUTER_JOINS_SUPPORT_LEVEL";
    case SqlInfo.SQL_SCHEMA_TERM:
      return "SQL_SCHEMA_TERM";
    case SqlInfo.SQL_PROCEDURE_TERM:
      return "SQL_PROCEDURE_TERM";
    case SqlInfo.SQL_CATALOG_TERM:
      return "SQL_CATALOG_TERM";
    case SqlInfo.SQL_CATALOG_AT_START:
      return "SQL_CATALOG_AT_START";
    case SqlInfo.SQL_SCHEMAS_SUPPORTED_ACTIONS:
      return "SQL_SCHEMAS_SUPPORTED_ACTIONS";
    case SqlInfo.SQL_CATALOGS_SUPPORTED_ACTIONS:
      return "SQL_CATALOGS_SUPPORTED_ACTIONS";
    case SqlInfo.SQL_SUPPORTED_POSITIONED_COMMANDS:
      return "SQL_SUPPORTED_POSITIONED_COMMANDS";
    case SqlInfo.SQL_SELECT_FOR_UPDATE_SUPPORTED:
      return "SQL_SELECT_FOR_UPDATE_SUPPORTED";
    case SqlInfo.SQL_STORED_PROCEDURES_SUPPORTED:
      return "SQL_STORED_PROCEDURES_SUPPORTED";
    case SqlInfo.SQL_SUPPORTED_SUBQUERIES:
      return "SQL_SUPPORTED_SUBQUERIES";
    case SqlInfo.SQL_CORRELATED_SUBQUERIES_SUPPORTED:
      return "SQL_CORRELATED_SUBQUERIES_SUPPORTED";
    case SqlInfo.SQL_SUPPORTED_UNIONS:
      return "SQL_SUPPORTED_UNIONS";
    case SqlInfo.SQL_MAX_BINARY_LITERAL_LENGTH:
      return "SQL_MAX_BINARY_LITERAL_LENGTH";
    case SqlInfo.SQL_MAX_CHAR_LITERAL_LENGTH:
      return "SQL_MAX_CHAR_LITERAL_LENGTH";
    case SqlInfo.SQL_MAX_COLUMN_NAME_LENGTH:
      return "SQL_MAX_COLUMN_NAME_LENGTH";
    case SqlInfo.SQL_MAX_COLUMNS_IN_GROUP_BY:
      return "SQL_MAX_COLUMNS_IN_GROUP_BY";
    case SqlInfo.SQL_MAX_COLUMNS_IN_INDEX:
      return "SQL_MAX_COLUMNS_IN_INDEX";
    case SqlInfo.SQL_MAX_COLUMNS_IN_ORDER_BY:
      return "SQL_MAX_COLUMNS_IN_ORDER_BY";
    case SqlInfo.SQL_MAX_COLUMNS_IN_SELECT:
      return "SQL_MAX_COLUMNS_IN_SELECT";
    case SqlInfo.SQL_MAX_COLUMNS_IN_TABLE:
      return "SQL_MAX_COLUMNS_IN_TABLE";
    case SqlInfo.SQL_MAX_CONNECTIONS:
      return "SQL_MAX_CONNECTIONS";
    case SqlInfo.SQL_MAX_CURSOR_NAME_LENGTH:
      return "SQL_MAX_CURSOR_NAME_LENGTH";
    case SqlInfo.SQL_MAX_INDEX_LENGTH:
      return "SQL_MAX_INDEX_LENGTH";
    case SqlInfo.SQL_DB_SCHEMA_NAME_LENGTH:
      return "SQL_DB_SCHEMA_NAME_LENGTH";
    case SqlInfo.SQL_MAX_PROCEDURE_NAME_LENGTH:
      return "SQL_MAX_PROCEDURE_NAME_LENGTH";
    case SqlInfo.SQL_MAX_CATALOG_NAME_LENGTH:
      return "SQL_MAX_CATALOG_NAME_LENGTH";
    case SqlInfo.SQL_MAX_ROW_SIZE:
      return "SQL_MAX_ROW_SIZE";
    case SqlInfo.SQL_MAX_ROW_SIZE_INCLUDES_BLOBS:
      return "SQL_MAX_ROW_SIZE_INCLUDES_BLOBS";
    case SqlInfo.SQL_MAX_STATEMENT_LENGTH:
      return "SQL_MAX_STATEMENT_LENGTH";
    case SqlInfo.SQL_MAX_STATEMENTS:
      return "SQL_MAX_STATEMENTS";
    case SqlInfo.SQL_MAX_TABLE_NAME_LENGTH:
      return "SQL_MAX_TABLE_NAME_LENGTH";
    case SqlInfo.SQL_MAX_TABLES_IN_SELECT:
      return "SQL_MAX_TABLES_IN_SELECT";
    case SqlInfo.SQL_MAX_USERNAME_LENGTH:
      return "SQL_MAX_USERNAME_LENGTH";
    case SqlInfo.SQL_DEFAULT_TRANSACTION_ISOLATION:
      return "SQL_DEFAULT_TRANSACTION_ISOLATION";
    case SqlInfo.SQL_TRANSACTIONS_SUPPORTED:
      return "SQL_TRANSACTIONS_SUPPORTED";
    case SqlInfo.SQL_SUPPORTED_TRANSACTIONS_ISOLATION_LEVELS:
      return "SQL_SUPPORTED_TRANSACTIONS_ISOLATION_LEVELS";
    case SqlInfo.SQL_DATA_DEFINITION_CAUSES_TRANSACTION_COMMIT:
      return "SQL_DATA_DEFINITION_CAUSES_TRANSACTION_COMMIT";
    case SqlInfo.SQL_DATA_DEFINITIONS_IN_TRANSACTIONS_IGNORED:
      return "SQL_DATA_DEFINITIONS_IN_TRANSACTIONS_IGNORED";
    case SqlInfo.SQL_SUPPORTED_RESULT_SET_TYPES:
      return "SQL_SUPPORTED_RESULT_SET_TYPES";
    case SqlInfo.SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_UNSPECIFIED:
      return "SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_UNSPECIFIED";
    case SqlInfo.SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_FORWARD_ONLY:
      return "SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_FORWARD_ONLY";
    case SqlInfo.SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_SCROLL_SENSITIVE:
      return "SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_SCROLL_SENSITIVE";
    case SqlInfo.SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_SCROLL_INSENSITIVE:
      return "SQL_SUPPORTED_CONCURRENCIES_FOR_RESULT_SET_SCROLL_INSENSITIVE";
    case SqlInfo.SQL_BATCH_UPDATES_SUPPORTED:
      return "SQL_BATCH_UPDATES_SUPPORTED";
    case SqlInfo.SQL_SAVEPOINTS_SUPPORTED:
      return "SQL_SAVEPOINTS_SUPPORTED";
    case SqlInfo.SQL_NAMED_PARAMETERS_SUPPORTED:
      return "SQL_NAMED_PARAMETERS_SUPPORTED";
    case SqlInfo.SQL_LOCATORS_UPDATE_COPY:
      return "SQL_LOCATORS_UPDATE_COPY";
    case SqlInfo.SQL_STORED_FUNCTIONS_USING_CALL_SYNTAX_SUPPORTED:
      return "SQL_STORED_FUNCTIONS_USING_CALL_SYNTAX_SUPPORTED";
    case SqlInfo.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The level of support for Flight SQL transaction RPCs. */
export enum SqlSupportedTransaction {
  /** NONE - Unknown/not indicated/no support */
  NONE = 0,
  /**
   * TRANSACTION - Transactions, but not savepoints.
   * A savepoint is a mark within a transaction that can be individually
   * rolled back to. Not all databases support savepoints.
   */
  TRANSACTION = 1,
  /** SAVEPOINT - Transactions and savepoints */
  SAVEPOINT = 2,
  UNRECOGNIZED = -1,
}

export function sqlSupportedTransactionFromJSON(object: any): SqlSupportedTransaction {
  switch (object) {
    case 0:
    case "SQL_SUPPORTED_TRANSACTION_NONE":
      return SqlSupportedTransaction.NONE;
    case 1:
    case "SQL_SUPPORTED_TRANSACTION_TRANSACTION":
      return SqlSupportedTransaction.TRANSACTION;
    case 2:
    case "SQL_SUPPORTED_TRANSACTION_SAVEPOINT":
      return SqlSupportedTransaction.SAVEPOINT;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlSupportedTransaction.UNRECOGNIZED;
  }
}

export function sqlSupportedTransactionToJSON(object: SqlSupportedTransaction): string {
  switch (object) {
    case SqlSupportedTransaction.NONE:
      return "SQL_SUPPORTED_TRANSACTION_NONE";
    case SqlSupportedTransaction.TRANSACTION:
      return "SQL_SUPPORTED_TRANSACTION_TRANSACTION";
    case SqlSupportedTransaction.SAVEPOINT:
      return "SQL_SUPPORTED_TRANSACTION_SAVEPOINT";
    case SqlSupportedTransaction.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum SqlSupportedCaseSensitivity {
  SQL_CASE_SENSITIVITY_UNKNOWN = 0,
  SQL_CASE_SENSITIVITY_CASE_INSENSITIVE = 1,
  SQL_CASE_SENSITIVITY_UPPERCASE = 2,
  SQL_CASE_SENSITIVITY_LOWERCASE = 3,
  UNRECOGNIZED = -1,
}

export function sqlSupportedCaseSensitivityFromJSON(object: any): SqlSupportedCaseSensitivity {
  switch (object) {
    case 0:
    case "SQL_CASE_SENSITIVITY_UNKNOWN":
      return SqlSupportedCaseSensitivity.SQL_CASE_SENSITIVITY_UNKNOWN;
    case 1:
    case "SQL_CASE_SENSITIVITY_CASE_INSENSITIVE":
      return SqlSupportedCaseSensitivity.SQL_CASE_SENSITIVITY_CASE_INSENSITIVE;
    case 2:
    case "SQL_CASE_SENSITIVITY_UPPERCASE":
      return SqlSupportedCaseSensitivity.SQL_CASE_SENSITIVITY_UPPERCASE;
    case 3:
    case "SQL_CASE_SENSITIVITY_LOWERCASE":
      return SqlSupportedCaseSensitivity.SQL_CASE_SENSITIVITY_LOWERCASE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlSupportedCaseSensitivity.UNRECOGNIZED;
  }
}

export function sqlSupportedCaseSensitivityToJSON(object: SqlSupportedCaseSensitivity): string {
  switch (object) {
    case SqlSupportedCaseSensitivity.SQL_CASE_SENSITIVITY_UNKNOWN:
      return "SQL_CASE_SENSITIVITY_UNKNOWN";
    case SqlSupportedCaseSensitivity.SQL_CASE_SENSITIVITY_CASE_INSENSITIVE:
      return "SQL_CASE_SENSITIVITY_CASE_INSENSITIVE";
    case SqlSupportedCaseSensitivity.SQL_CASE_SENSITIVITY_UPPERCASE:
      return "SQL_CASE_SENSITIVITY_UPPERCASE";
    case SqlSupportedCaseSensitivity.SQL_CASE_SENSITIVITY_LOWERCASE:
      return "SQL_CASE_SENSITIVITY_LOWERCASE";
    case SqlSupportedCaseSensitivity.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum SqlNullOrdering {
  SQL_NULLS_SORTED_HIGH = 0,
  SQL_NULLS_SORTED_LOW = 1,
  SQL_NULLS_SORTED_AT_START = 2,
  SQL_NULLS_SORTED_AT_END = 3,
  UNRECOGNIZED = -1,
}

export function sqlNullOrderingFromJSON(object: any): SqlNullOrdering {
  switch (object) {
    case 0:
    case "SQL_NULLS_SORTED_HIGH":
      return SqlNullOrdering.SQL_NULLS_SORTED_HIGH;
    case 1:
    case "SQL_NULLS_SORTED_LOW":
      return SqlNullOrdering.SQL_NULLS_SORTED_LOW;
    case 2:
    case "SQL_NULLS_SORTED_AT_START":
      return SqlNullOrdering.SQL_NULLS_SORTED_AT_START;
    case 3:
    case "SQL_NULLS_SORTED_AT_END":
      return SqlNullOrdering.SQL_NULLS_SORTED_AT_END;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlNullOrdering.UNRECOGNIZED;
  }
}

export function sqlNullOrderingToJSON(object: SqlNullOrdering): string {
  switch (object) {
    case SqlNullOrdering.SQL_NULLS_SORTED_HIGH:
      return "SQL_NULLS_SORTED_HIGH";
    case SqlNullOrdering.SQL_NULLS_SORTED_LOW:
      return "SQL_NULLS_SORTED_LOW";
    case SqlNullOrdering.SQL_NULLS_SORTED_AT_START:
      return "SQL_NULLS_SORTED_AT_START";
    case SqlNullOrdering.SQL_NULLS_SORTED_AT_END:
      return "SQL_NULLS_SORTED_AT_END";
    case SqlNullOrdering.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum SupportedSqlGrammar {
  SQL_MINIMUM_GRAMMAR = 0,
  SQL_CORE_GRAMMAR = 1,
  SQL_EXTENDED_GRAMMAR = 2,
  UNRECOGNIZED = -1,
}

export function supportedSqlGrammarFromJSON(object: any): SupportedSqlGrammar {
  switch (object) {
    case 0:
    case "SQL_MINIMUM_GRAMMAR":
      return SupportedSqlGrammar.SQL_MINIMUM_GRAMMAR;
    case 1:
    case "SQL_CORE_GRAMMAR":
      return SupportedSqlGrammar.SQL_CORE_GRAMMAR;
    case 2:
    case "SQL_EXTENDED_GRAMMAR":
      return SupportedSqlGrammar.SQL_EXTENDED_GRAMMAR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SupportedSqlGrammar.UNRECOGNIZED;
  }
}

export function supportedSqlGrammarToJSON(object: SupportedSqlGrammar): string {
  switch (object) {
    case SupportedSqlGrammar.SQL_MINIMUM_GRAMMAR:
      return "SQL_MINIMUM_GRAMMAR";
    case SupportedSqlGrammar.SQL_CORE_GRAMMAR:
      return "SQL_CORE_GRAMMAR";
    case SupportedSqlGrammar.SQL_EXTENDED_GRAMMAR:
      return "SQL_EXTENDED_GRAMMAR";
    case SupportedSqlGrammar.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum SupportedAnsi92SqlGrammarLevel {
  ANSI92_ENTRY_SQL = 0,
  ANSI92_INTERMEDIATE_SQL = 1,
  ANSI92_FULL_SQL = 2,
  UNRECOGNIZED = -1,
}

export function supportedAnsi92SqlGrammarLevelFromJSON(object: any): SupportedAnsi92SqlGrammarLevel {
  switch (object) {
    case 0:
    case "ANSI92_ENTRY_SQL":
      return SupportedAnsi92SqlGrammarLevel.ANSI92_ENTRY_SQL;
    case 1:
    case "ANSI92_INTERMEDIATE_SQL":
      return SupportedAnsi92SqlGrammarLevel.ANSI92_INTERMEDIATE_SQL;
    case 2:
    case "ANSI92_FULL_SQL":
      return SupportedAnsi92SqlGrammarLevel.ANSI92_FULL_SQL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SupportedAnsi92SqlGrammarLevel.UNRECOGNIZED;
  }
}

export function supportedAnsi92SqlGrammarLevelToJSON(object: SupportedAnsi92SqlGrammarLevel): string {
  switch (object) {
    case SupportedAnsi92SqlGrammarLevel.ANSI92_ENTRY_SQL:
      return "ANSI92_ENTRY_SQL";
    case SupportedAnsi92SqlGrammarLevel.ANSI92_INTERMEDIATE_SQL:
      return "ANSI92_INTERMEDIATE_SQL";
    case SupportedAnsi92SqlGrammarLevel.ANSI92_FULL_SQL:
      return "ANSI92_FULL_SQL";
    case SupportedAnsi92SqlGrammarLevel.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum SqlOuterJoinsSupportLevel {
  SQL_JOINS_UNSUPPORTED = 0,
  SQL_LIMITED_OUTER_JOINS = 1,
  SQL_FULL_OUTER_JOINS = 2,
  UNRECOGNIZED = -1,
}

export function sqlOuterJoinsSupportLevelFromJSON(object: any): SqlOuterJoinsSupportLevel {
  switch (object) {
    case 0:
    case "SQL_JOINS_UNSUPPORTED":
      return SqlOuterJoinsSupportLevel.SQL_JOINS_UNSUPPORTED;
    case 1:
    case "SQL_LIMITED_OUTER_JOINS":
      return SqlOuterJoinsSupportLevel.SQL_LIMITED_OUTER_JOINS;
    case 2:
    case "SQL_FULL_OUTER_JOINS":
      return SqlOuterJoinsSupportLevel.SQL_FULL_OUTER_JOINS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlOuterJoinsSupportLevel.UNRECOGNIZED;
  }
}

export function sqlOuterJoinsSupportLevelToJSON(object: SqlOuterJoinsSupportLevel): string {
  switch (object) {
    case SqlOuterJoinsSupportLevel.SQL_JOINS_UNSUPPORTED:
      return "SQL_JOINS_UNSUPPORTED";
    case SqlOuterJoinsSupportLevel.SQL_LIMITED_OUTER_JOINS:
      return "SQL_LIMITED_OUTER_JOINS";
    case SqlOuterJoinsSupportLevel.SQL_FULL_OUTER_JOINS:
      return "SQL_FULL_OUTER_JOINS";
    case SqlOuterJoinsSupportLevel.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum SqlSupportedGroupBy {
  SQL_GROUP_BY_UNRELATED = 0,
  SQL_GROUP_BY_BEYOND_SELECT = 1,
  UNRECOGNIZED = -1,
}

export function sqlSupportedGroupByFromJSON(object: any): SqlSupportedGroupBy {
  switch (object) {
    case 0:
    case "SQL_GROUP_BY_UNRELATED":
      return SqlSupportedGroupBy.SQL_GROUP_BY_UNRELATED;
    case 1:
    case "SQL_GROUP_BY_BEYOND_SELECT":
      return SqlSupportedGroupBy.SQL_GROUP_BY_BEYOND_SELECT;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlSupportedGroupBy.UNRECOGNIZED;
  }
}

export function sqlSupportedGroupByToJSON(object: SqlSupportedGroupBy): string {
  switch (object) {
    case SqlSupportedGroupBy.SQL_GROUP_BY_UNRELATED:
      return "SQL_GROUP_BY_UNRELATED";
    case SqlSupportedGroupBy.SQL_GROUP_BY_BEYOND_SELECT:
      return "SQL_GROUP_BY_BEYOND_SELECT";
    case SqlSupportedGroupBy.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum SqlSupportedElementActions {
  SQL_ELEMENT_IN_PROCEDURE_CALLS = 0,
  SQL_ELEMENT_IN_INDEX_DEFINITIONS = 1,
  SQL_ELEMENT_IN_PRIVILEGE_DEFINITIONS = 2,
  UNRECOGNIZED = -1,
}

export function sqlSupportedElementActionsFromJSON(object: any): SqlSupportedElementActions {
  switch (object) {
    case 0:
    case "SQL_ELEMENT_IN_PROCEDURE_CALLS":
      return SqlSupportedElementActions.SQL_ELEMENT_IN_PROCEDURE_CALLS;
    case 1:
    case "SQL_ELEMENT_IN_INDEX_DEFINITIONS":
      return SqlSupportedElementActions.SQL_ELEMENT_IN_INDEX_DEFINITIONS;
    case 2:
    case "SQL_ELEMENT_IN_PRIVILEGE_DEFINITIONS":
      return SqlSupportedElementActions.SQL_ELEMENT_IN_PRIVILEGE_DEFINITIONS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlSupportedElementActions.UNRECOGNIZED;
  }
}

export function sqlSupportedElementActionsToJSON(object: SqlSupportedElementActions): string {
  switch (object) {
    case SqlSupportedElementActions.SQL_ELEMENT_IN_PROCEDURE_CALLS:
      return "SQL_ELEMENT_IN_PROCEDURE_CALLS";
    case SqlSupportedElementActions.SQL_ELEMENT_IN_INDEX_DEFINITIONS:
      return "SQL_ELEMENT_IN_INDEX_DEFINITIONS";
    case SqlSupportedElementActions.SQL_ELEMENT_IN_PRIVILEGE_DEFINITIONS:
      return "SQL_ELEMENT_IN_PRIVILEGE_DEFINITIONS";
    case SqlSupportedElementActions.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum SqlSupportedPositionedCommands {
  SQL_POSITIONED_DELETE = 0,
  SQL_POSITIONED_UPDATE = 1,
  UNRECOGNIZED = -1,
}

export function sqlSupportedPositionedCommandsFromJSON(object: any): SqlSupportedPositionedCommands {
  switch (object) {
    case 0:
    case "SQL_POSITIONED_DELETE":
      return SqlSupportedPositionedCommands.SQL_POSITIONED_DELETE;
    case 1:
    case "SQL_POSITIONED_UPDATE":
      return SqlSupportedPositionedCommands.SQL_POSITIONED_UPDATE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlSupportedPositionedCommands.UNRECOGNIZED;
  }
}

export function sqlSupportedPositionedCommandsToJSON(object: SqlSupportedPositionedCommands): string {
  switch (object) {
    case SqlSupportedPositionedCommands.SQL_POSITIONED_DELETE:
      return "SQL_POSITIONED_DELETE";
    case SqlSupportedPositionedCommands.SQL_POSITIONED_UPDATE:
      return "SQL_POSITIONED_UPDATE";
    case SqlSupportedPositionedCommands.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum SqlSupportedSubqueries {
  SQL_SUBQUERIES_IN_COMPARISONS = 0,
  SQL_SUBQUERIES_IN_EXISTS = 1,
  SQL_SUBQUERIES_IN_INS = 2,
  SQL_SUBQUERIES_IN_QUANTIFIEDS = 3,
  UNRECOGNIZED = -1,
}

export function sqlSupportedSubqueriesFromJSON(object: any): SqlSupportedSubqueries {
  switch (object) {
    case 0:
    case "SQL_SUBQUERIES_IN_COMPARISONS":
      return SqlSupportedSubqueries.SQL_SUBQUERIES_IN_COMPARISONS;
    case 1:
    case "SQL_SUBQUERIES_IN_EXISTS":
      return SqlSupportedSubqueries.SQL_SUBQUERIES_IN_EXISTS;
    case 2:
    case "SQL_SUBQUERIES_IN_INS":
      return SqlSupportedSubqueries.SQL_SUBQUERIES_IN_INS;
    case 3:
    case "SQL_SUBQUERIES_IN_QUANTIFIEDS":
      return SqlSupportedSubqueries.SQL_SUBQUERIES_IN_QUANTIFIEDS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlSupportedSubqueries.UNRECOGNIZED;
  }
}

export function sqlSupportedSubqueriesToJSON(object: SqlSupportedSubqueries): string {
  switch (object) {
    case SqlSupportedSubqueries.SQL_SUBQUERIES_IN_COMPARISONS:
      return "SQL_SUBQUERIES_IN_COMPARISONS";
    case SqlSupportedSubqueries.SQL_SUBQUERIES_IN_EXISTS:
      return "SQL_SUBQUERIES_IN_EXISTS";
    case SqlSupportedSubqueries.SQL_SUBQUERIES_IN_INS:
      return "SQL_SUBQUERIES_IN_INS";
    case SqlSupportedSubqueries.SQL_SUBQUERIES_IN_QUANTIFIEDS:
      return "SQL_SUBQUERIES_IN_QUANTIFIEDS";
    case SqlSupportedSubqueries.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum SqlSupportedUnions {
  SQL_UNION = 0,
  SQL_UNION_ALL = 1,
  UNRECOGNIZED = -1,
}

export function sqlSupportedUnionsFromJSON(object: any): SqlSupportedUnions {
  switch (object) {
    case 0:
    case "SQL_UNION":
      return SqlSupportedUnions.SQL_UNION;
    case 1:
    case "SQL_UNION_ALL":
      return SqlSupportedUnions.SQL_UNION_ALL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlSupportedUnions.UNRECOGNIZED;
  }
}

export function sqlSupportedUnionsToJSON(object: SqlSupportedUnions): string {
  switch (object) {
    case SqlSupportedUnions.SQL_UNION:
      return "SQL_UNION";
    case SqlSupportedUnions.SQL_UNION_ALL:
      return "SQL_UNION_ALL";
    case SqlSupportedUnions.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum SqlTransactionIsolationLevel {
  SQL_TRANSACTION_NONE = 0,
  SQL_TRANSACTION_READ_UNCOMMITTED = 1,
  SQL_TRANSACTION_READ_COMMITTED = 2,
  SQL_TRANSACTION_REPEATABLE_READ = 3,
  SQL_TRANSACTION_SERIALIZABLE = 4,
  UNRECOGNIZED = -1,
}

export function sqlTransactionIsolationLevelFromJSON(object: any): SqlTransactionIsolationLevel {
  switch (object) {
    case 0:
    case "SQL_TRANSACTION_NONE":
      return SqlTransactionIsolationLevel.SQL_TRANSACTION_NONE;
    case 1:
    case "SQL_TRANSACTION_READ_UNCOMMITTED":
      return SqlTransactionIsolationLevel.SQL_TRANSACTION_READ_UNCOMMITTED;
    case 2:
    case "SQL_TRANSACTION_READ_COMMITTED":
      return SqlTransactionIsolationLevel.SQL_TRANSACTION_READ_COMMITTED;
    case 3:
    case "SQL_TRANSACTION_REPEATABLE_READ":
      return SqlTransactionIsolationLevel.SQL_TRANSACTION_REPEATABLE_READ;
    case 4:
    case "SQL_TRANSACTION_SERIALIZABLE":
      return SqlTransactionIsolationLevel.SQL_TRANSACTION_SERIALIZABLE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlTransactionIsolationLevel.UNRECOGNIZED;
  }
}

export function sqlTransactionIsolationLevelToJSON(object: SqlTransactionIsolationLevel): string {
  switch (object) {
    case SqlTransactionIsolationLevel.SQL_TRANSACTION_NONE:
      return "SQL_TRANSACTION_NONE";
    case SqlTransactionIsolationLevel.SQL_TRANSACTION_READ_UNCOMMITTED:
      return "SQL_TRANSACTION_READ_UNCOMMITTED";
    case SqlTransactionIsolationLevel.SQL_TRANSACTION_READ_COMMITTED:
      return "SQL_TRANSACTION_READ_COMMITTED";
    case SqlTransactionIsolationLevel.SQL_TRANSACTION_REPEATABLE_READ:
      return "SQL_TRANSACTION_REPEATABLE_READ";
    case SqlTransactionIsolationLevel.SQL_TRANSACTION_SERIALIZABLE:
      return "SQL_TRANSACTION_SERIALIZABLE";
    case SqlTransactionIsolationLevel.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum SqlSupportedTransactions {
  SQL_TRANSACTION_UNSPECIFIED = 0,
  SQL_DATA_DEFINITION_TRANSACTIONS = 1,
  SQL_DATA_MANIPULATION_TRANSACTIONS = 2,
  UNRECOGNIZED = -1,
}

export function sqlSupportedTransactionsFromJSON(object: any): SqlSupportedTransactions {
  switch (object) {
    case 0:
    case "SQL_TRANSACTION_UNSPECIFIED":
      return SqlSupportedTransactions.SQL_TRANSACTION_UNSPECIFIED;
    case 1:
    case "SQL_DATA_DEFINITION_TRANSACTIONS":
      return SqlSupportedTransactions.SQL_DATA_DEFINITION_TRANSACTIONS;
    case 2:
    case "SQL_DATA_MANIPULATION_TRANSACTIONS":
      return SqlSupportedTransactions.SQL_DATA_MANIPULATION_TRANSACTIONS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlSupportedTransactions.UNRECOGNIZED;
  }
}

export function sqlSupportedTransactionsToJSON(object: SqlSupportedTransactions): string {
  switch (object) {
    case SqlSupportedTransactions.SQL_TRANSACTION_UNSPECIFIED:
      return "SQL_TRANSACTION_UNSPECIFIED";
    case SqlSupportedTransactions.SQL_DATA_DEFINITION_TRANSACTIONS:
      return "SQL_DATA_DEFINITION_TRANSACTIONS";
    case SqlSupportedTransactions.SQL_DATA_MANIPULATION_TRANSACTIONS:
      return "SQL_DATA_MANIPULATION_TRANSACTIONS";
    case SqlSupportedTransactions.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum SqlSupportedResultSetType {
  SQL_RESULT_SET_TYPE_UNSPECIFIED = 0,
  SQL_RESULT_SET_TYPE_FORWARD_ONLY = 1,
  SQL_RESULT_SET_TYPE_SCROLL_INSENSITIVE = 2,
  SQL_RESULT_SET_TYPE_SCROLL_SENSITIVE = 3,
  UNRECOGNIZED = -1,
}

export function sqlSupportedResultSetTypeFromJSON(object: any): SqlSupportedResultSetType {
  switch (object) {
    case 0:
    case "SQL_RESULT_SET_TYPE_UNSPECIFIED":
      return SqlSupportedResultSetType.SQL_RESULT_SET_TYPE_UNSPECIFIED;
    case 1:
    case "SQL_RESULT_SET_TYPE_FORWARD_ONLY":
      return SqlSupportedResultSetType.SQL_RESULT_SET_TYPE_FORWARD_ONLY;
    case 2:
    case "SQL_RESULT_SET_TYPE_SCROLL_INSENSITIVE":
      return SqlSupportedResultSetType.SQL_RESULT_SET_TYPE_SCROLL_INSENSITIVE;
    case 3:
    case "SQL_RESULT_SET_TYPE_SCROLL_SENSITIVE":
      return SqlSupportedResultSetType.SQL_RESULT_SET_TYPE_SCROLL_SENSITIVE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlSupportedResultSetType.UNRECOGNIZED;
  }
}

export function sqlSupportedResultSetTypeToJSON(object: SqlSupportedResultSetType): string {
  switch (object) {
    case SqlSupportedResultSetType.SQL_RESULT_SET_TYPE_UNSPECIFIED:
      return "SQL_RESULT_SET_TYPE_UNSPECIFIED";
    case SqlSupportedResultSetType.SQL_RESULT_SET_TYPE_FORWARD_ONLY:
      return "SQL_RESULT_SET_TYPE_FORWARD_ONLY";
    case SqlSupportedResultSetType.SQL_RESULT_SET_TYPE_SCROLL_INSENSITIVE:
      return "SQL_RESULT_SET_TYPE_SCROLL_INSENSITIVE";
    case SqlSupportedResultSetType.SQL_RESULT_SET_TYPE_SCROLL_SENSITIVE:
      return "SQL_RESULT_SET_TYPE_SCROLL_SENSITIVE";
    case SqlSupportedResultSetType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum SqlSupportedResultSetConcurrency {
  SQL_RESULT_SET_CONCURRENCY_UNSPECIFIED = 0,
  SQL_RESULT_SET_CONCURRENCY_READ_ONLY = 1,
  SQL_RESULT_SET_CONCURRENCY_UPDATABLE = 2,
  UNRECOGNIZED = -1,
}

export function sqlSupportedResultSetConcurrencyFromJSON(object: any): SqlSupportedResultSetConcurrency {
  switch (object) {
    case 0:
    case "SQL_RESULT_SET_CONCURRENCY_UNSPECIFIED":
      return SqlSupportedResultSetConcurrency.SQL_RESULT_SET_CONCURRENCY_UNSPECIFIED;
    case 1:
    case "SQL_RESULT_SET_CONCURRENCY_READ_ONLY":
      return SqlSupportedResultSetConcurrency.SQL_RESULT_SET_CONCURRENCY_READ_ONLY;
    case 2:
    case "SQL_RESULT_SET_CONCURRENCY_UPDATABLE":
      return SqlSupportedResultSetConcurrency.SQL_RESULT_SET_CONCURRENCY_UPDATABLE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlSupportedResultSetConcurrency.UNRECOGNIZED;
  }
}

export function sqlSupportedResultSetConcurrencyToJSON(object: SqlSupportedResultSetConcurrency): string {
  switch (object) {
    case SqlSupportedResultSetConcurrency.SQL_RESULT_SET_CONCURRENCY_UNSPECIFIED:
      return "SQL_RESULT_SET_CONCURRENCY_UNSPECIFIED";
    case SqlSupportedResultSetConcurrency.SQL_RESULT_SET_CONCURRENCY_READ_ONLY:
      return "SQL_RESULT_SET_CONCURRENCY_READ_ONLY";
    case SqlSupportedResultSetConcurrency.SQL_RESULT_SET_CONCURRENCY_UPDATABLE:
      return "SQL_RESULT_SET_CONCURRENCY_UPDATABLE";
    case SqlSupportedResultSetConcurrency.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum SqlSupportsConvert {
  SQL_CONVERT_BIGINT = 0,
  SQL_CONVERT_BINARY = 1,
  SQL_CONVERT_BIT = 2,
  SQL_CONVERT_CHAR = 3,
  SQL_CONVERT_DATE = 4,
  SQL_CONVERT_DECIMAL = 5,
  SQL_CONVERT_FLOAT = 6,
  SQL_CONVERT_INTEGER = 7,
  SQL_CONVERT_INTERVAL_DAY_TIME = 8,
  SQL_CONVERT_INTERVAL_YEAR_MONTH = 9,
  SQL_CONVERT_LONGVARBINARY = 10,
  SQL_CONVERT_LONGVARCHAR = 11,
  SQL_CONVERT_NUMERIC = 12,
  SQL_CONVERT_REAL = 13,
  SQL_CONVERT_SMALLINT = 14,
  SQL_CONVERT_TIME = 15,
  SQL_CONVERT_TIMESTAMP = 16,
  SQL_CONVERT_TINYINT = 17,
  SQL_CONVERT_VARBINARY = 18,
  SQL_CONVERT_VARCHAR = 19,
  UNRECOGNIZED = -1,
}

export function sqlSupportsConvertFromJSON(object: any): SqlSupportsConvert {
  switch (object) {
    case 0:
    case "SQL_CONVERT_BIGINT":
      return SqlSupportsConvert.SQL_CONVERT_BIGINT;
    case 1:
    case "SQL_CONVERT_BINARY":
      return SqlSupportsConvert.SQL_CONVERT_BINARY;
    case 2:
    case "SQL_CONVERT_BIT":
      return SqlSupportsConvert.SQL_CONVERT_BIT;
    case 3:
    case "SQL_CONVERT_CHAR":
      return SqlSupportsConvert.SQL_CONVERT_CHAR;
    case 4:
    case "SQL_CONVERT_DATE":
      return SqlSupportsConvert.SQL_CONVERT_DATE;
    case 5:
    case "SQL_CONVERT_DECIMAL":
      return SqlSupportsConvert.SQL_CONVERT_DECIMAL;
    case 6:
    case "SQL_CONVERT_FLOAT":
      return SqlSupportsConvert.SQL_CONVERT_FLOAT;
    case 7:
    case "SQL_CONVERT_INTEGER":
      return SqlSupportsConvert.SQL_CONVERT_INTEGER;
    case 8:
    case "SQL_CONVERT_INTERVAL_DAY_TIME":
      return SqlSupportsConvert.SQL_CONVERT_INTERVAL_DAY_TIME;
    case 9:
    case "SQL_CONVERT_INTERVAL_YEAR_MONTH":
      return SqlSupportsConvert.SQL_CONVERT_INTERVAL_YEAR_MONTH;
    case 10:
    case "SQL_CONVERT_LONGVARBINARY":
      return SqlSupportsConvert.SQL_CONVERT_LONGVARBINARY;
    case 11:
    case "SQL_CONVERT_LONGVARCHAR":
      return SqlSupportsConvert.SQL_CONVERT_LONGVARCHAR;
    case 12:
    case "SQL_CONVERT_NUMERIC":
      return SqlSupportsConvert.SQL_CONVERT_NUMERIC;
    case 13:
    case "SQL_CONVERT_REAL":
      return SqlSupportsConvert.SQL_CONVERT_REAL;
    case 14:
    case "SQL_CONVERT_SMALLINT":
      return SqlSupportsConvert.SQL_CONVERT_SMALLINT;
    case 15:
    case "SQL_CONVERT_TIME":
      return SqlSupportsConvert.SQL_CONVERT_TIME;
    case 16:
    case "SQL_CONVERT_TIMESTAMP":
      return SqlSupportsConvert.SQL_CONVERT_TIMESTAMP;
    case 17:
    case "SQL_CONVERT_TINYINT":
      return SqlSupportsConvert.SQL_CONVERT_TINYINT;
    case 18:
    case "SQL_CONVERT_VARBINARY":
      return SqlSupportsConvert.SQL_CONVERT_VARBINARY;
    case 19:
    case "SQL_CONVERT_VARCHAR":
      return SqlSupportsConvert.SQL_CONVERT_VARCHAR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlSupportsConvert.UNRECOGNIZED;
  }
}

export function sqlSupportsConvertToJSON(object: SqlSupportsConvert): string {
  switch (object) {
    case SqlSupportsConvert.SQL_CONVERT_BIGINT:
      return "SQL_CONVERT_BIGINT";
    case SqlSupportsConvert.SQL_CONVERT_BINARY:
      return "SQL_CONVERT_BINARY";
    case SqlSupportsConvert.SQL_CONVERT_BIT:
      return "SQL_CONVERT_BIT";
    case SqlSupportsConvert.SQL_CONVERT_CHAR:
      return "SQL_CONVERT_CHAR";
    case SqlSupportsConvert.SQL_CONVERT_DATE:
      return "SQL_CONVERT_DATE";
    case SqlSupportsConvert.SQL_CONVERT_DECIMAL:
      return "SQL_CONVERT_DECIMAL";
    case SqlSupportsConvert.SQL_CONVERT_FLOAT:
      return "SQL_CONVERT_FLOAT";
    case SqlSupportsConvert.SQL_CONVERT_INTEGER:
      return "SQL_CONVERT_INTEGER";
    case SqlSupportsConvert.SQL_CONVERT_INTERVAL_DAY_TIME:
      return "SQL_CONVERT_INTERVAL_DAY_TIME";
    case SqlSupportsConvert.SQL_CONVERT_INTERVAL_YEAR_MONTH:
      return "SQL_CONVERT_INTERVAL_YEAR_MONTH";
    case SqlSupportsConvert.SQL_CONVERT_LONGVARBINARY:
      return "SQL_CONVERT_LONGVARBINARY";
    case SqlSupportsConvert.SQL_CONVERT_LONGVARCHAR:
      return "SQL_CONVERT_LONGVARCHAR";
    case SqlSupportsConvert.SQL_CONVERT_NUMERIC:
      return "SQL_CONVERT_NUMERIC";
    case SqlSupportsConvert.SQL_CONVERT_REAL:
      return "SQL_CONVERT_REAL";
    case SqlSupportsConvert.SQL_CONVERT_SMALLINT:
      return "SQL_CONVERT_SMALLINT";
    case SqlSupportsConvert.SQL_CONVERT_TIME:
      return "SQL_CONVERT_TIME";
    case SqlSupportsConvert.SQL_CONVERT_TIMESTAMP:
      return "SQL_CONVERT_TIMESTAMP";
    case SqlSupportsConvert.SQL_CONVERT_TINYINT:
      return "SQL_CONVERT_TINYINT";
    case SqlSupportsConvert.SQL_CONVERT_VARBINARY:
      return "SQL_CONVERT_VARBINARY";
    case SqlSupportsConvert.SQL_CONVERT_VARCHAR:
      return "SQL_CONVERT_VARCHAR";
    case SqlSupportsConvert.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * The JDBC/ODBC-defined type of any object.
 * All the values here are the same as in the JDBC and ODBC specs.
 */
export enum XdbcDataType {
  XDBC_UNKNOWN_TYPE = 0,
  XDBC_CHAR = 1,
  XDBC_NUMERIC = 2,
  XDBC_DECIMAL = 3,
  XDBC_INTEGER = 4,
  XDBC_SMALLINT = 5,
  XDBC_FLOAT = 6,
  XDBC_REAL = 7,
  XDBC_DOUBLE = 8,
  XDBC_DATETIME = 9,
  XDBC_INTERVAL = 10,
  XDBC_VARCHAR = 12,
  XDBC_DATE = 91,
  XDBC_TIME = 92,
  XDBC_TIMESTAMP = 93,
  XDBC_LONGVARCHAR = -1,
  XDBC_BINARY = -2,
  XDBC_VARBINARY = -3,
  XDBC_LONGVARBINARY = -4,
  XDBC_BIGINT = -5,
  XDBC_TINYINT = -6,
  XDBC_BIT = -7,
  XDBC_WCHAR = -8,
  XDBC_WVARCHAR = -9,
}

export function xdbcDataTypeFromJSON(object: any): XdbcDataType {
  switch (object) {
    case 0:
    case "XDBC_UNKNOWN_TYPE":
      return XdbcDataType.XDBC_UNKNOWN_TYPE;
    case 1:
    case "XDBC_CHAR":
      return XdbcDataType.XDBC_CHAR;
    case 2:
    case "XDBC_NUMERIC":
      return XdbcDataType.XDBC_NUMERIC;
    case 3:
    case "XDBC_DECIMAL":
      return XdbcDataType.XDBC_DECIMAL;
    case 4:
    case "XDBC_INTEGER":
      return XdbcDataType.XDBC_INTEGER;
    case 5:
    case "XDBC_SMALLINT":
      return XdbcDataType.XDBC_SMALLINT;
    case 6:
    case "XDBC_FLOAT":
      return XdbcDataType.XDBC_FLOAT;
    case 7:
    case "XDBC_REAL":
      return XdbcDataType.XDBC_REAL;
    case 8:
    case "XDBC_DOUBLE":
      return XdbcDataType.XDBC_DOUBLE;
    case 9:
    case "XDBC_DATETIME":
      return XdbcDataType.XDBC_DATETIME;
    case 10:
    case "XDBC_INTERVAL":
      return XdbcDataType.XDBC_INTERVAL;
    case 12:
    case "XDBC_VARCHAR":
      return XdbcDataType.XDBC_VARCHAR;
    case 91:
    case "XDBC_DATE":
      return XdbcDataType.XDBC_DATE;
    case 92:
    case "XDBC_TIME":
      return XdbcDataType.XDBC_TIME;
    case 93:
    case "XDBC_TIMESTAMP":
      return XdbcDataType.XDBC_TIMESTAMP;
    case -1:
    case "XDBC_LONGVARCHAR":
      return XdbcDataType.XDBC_LONGVARCHAR;
    case -2:
    case "XDBC_BINARY":
      return XdbcDataType.XDBC_BINARY;
    case -3:
    case "XDBC_VARBINARY":
      return XdbcDataType.XDBC_VARBINARY;
    case -4:
    case "XDBC_LONGVARBINARY":
      return XdbcDataType.XDBC_LONGVARBINARY;
    case -5:
    case "XDBC_BIGINT":
      return XdbcDataType.XDBC_BIGINT;
    case -6:
    case "XDBC_TINYINT":
      return XdbcDataType.XDBC_TINYINT;
    case -7:
    case "XDBC_BIT":
      return XdbcDataType.XDBC_BIT;
    case -8:
    case "XDBC_WCHAR":
      return XdbcDataType.XDBC_WCHAR;
    case -9:
    case "XDBC_WVARCHAR":
      return XdbcDataType.XDBC_WVARCHAR;
    default:
      return XdbcDataType.XDBC_LONGVARCHAR;
  }
}

export function xdbcDataTypeToJSON(object: XdbcDataType): string {
  switch (object) {
    case XdbcDataType.XDBC_UNKNOWN_TYPE:
      return "XDBC_UNKNOWN_TYPE";
    case XdbcDataType.XDBC_CHAR:
      return "XDBC_CHAR";
    case XdbcDataType.XDBC_NUMERIC:
      return "XDBC_NUMERIC";
    case XdbcDataType.XDBC_DECIMAL:
      return "XDBC_DECIMAL";
    case XdbcDataType.XDBC_INTEGER:
      return "XDBC_INTEGER";
    case XdbcDataType.XDBC_SMALLINT:
      return "XDBC_SMALLINT";
    case XdbcDataType.XDBC_FLOAT:
      return "XDBC_FLOAT";
    case XdbcDataType.XDBC_REAL:
      return "XDBC_REAL";
    case XdbcDataType.XDBC_DOUBLE:
      return "XDBC_DOUBLE";
    case XdbcDataType.XDBC_DATETIME:
      return "XDBC_DATETIME";
    case XdbcDataType.XDBC_INTERVAL:
      return "XDBC_INTERVAL";
    case XdbcDataType.XDBC_VARCHAR:
      return "XDBC_VARCHAR";
    case XdbcDataType.XDBC_DATE:
      return "XDBC_DATE";
    case XdbcDataType.XDBC_TIME:
      return "XDBC_TIME";
    case XdbcDataType.XDBC_TIMESTAMP:
      return "XDBC_TIMESTAMP";
    case XdbcDataType.XDBC_LONGVARCHAR:
      return "XDBC_LONGVARCHAR";
    case XdbcDataType.XDBC_BINARY:
      return "XDBC_BINARY";
    case XdbcDataType.XDBC_VARBINARY:
      return "XDBC_VARBINARY";
    case XdbcDataType.XDBC_LONGVARBINARY:
      return "XDBC_LONGVARBINARY";
    case XdbcDataType.XDBC_BIGINT:
      return "XDBC_BIGINT";
    case XdbcDataType.XDBC_TINYINT:
      return "XDBC_TINYINT";
    case XdbcDataType.XDBC_BIT:
      return "XDBC_BIT";
    case XdbcDataType.XDBC_WCHAR:
      return "XDBC_WCHAR";
    case XdbcDataType.XDBC_WVARCHAR:
      return "XDBC_WVARCHAR";
    default:
      return "XDBC_LONGVARCHAR";
  }
}

/** Detailed subtype information for XDBC_TYPE_DATETIME and XDBC_TYPE_INTERVAL. */
export enum XdbcDatetimeSubcode {
  XDBC_SUBCODE_UNKNOWN = 0,
  XDBC_SUBCODE_YEAR = 1,
  XDBC_SUBCODE_DATE = 1,
  XDBC_SUBCODE_TIME = 2,
  XDBC_SUBCODE_MONTH = 2,
  XDBC_SUBCODE_TIMESTAMP = 3,
  XDBC_SUBCODE_DAY = 3,
  XDBC_SUBCODE_TIME_WITH_TIMEZONE = 4,
  XDBC_SUBCODE_HOUR = 4,
  XDBC_SUBCODE_TIMESTAMP_WITH_TIMEZONE = 5,
  XDBC_SUBCODE_MINUTE = 5,
  XDBC_SUBCODE_SECOND = 6,
  XDBC_SUBCODE_YEAR_TO_MONTH = 7,
  XDBC_SUBCODE_DAY_TO_HOUR = 8,
  XDBC_SUBCODE_DAY_TO_MINUTE = 9,
  XDBC_SUBCODE_DAY_TO_SECOND = 10,
  XDBC_SUBCODE_HOUR_TO_MINUTE = 11,
  XDBC_SUBCODE_HOUR_TO_SECOND = 12,
  XDBC_SUBCODE_MINUTE_TO_SECOND = 13,
  XDBC_SUBCODE_INTERVAL_YEAR = 101,
  XDBC_SUBCODE_INTERVAL_MONTH = 102,
  XDBC_SUBCODE_INTERVAL_DAY = 103,
  XDBC_SUBCODE_INTERVAL_HOUR = 104,
  XDBC_SUBCODE_INTERVAL_MINUTE = 105,
  XDBC_SUBCODE_INTERVAL_SECOND = 106,
  XDBC_SUBCODE_INTERVAL_YEAR_TO_MONTH = 107,
  XDBC_SUBCODE_INTERVAL_DAY_TO_HOUR = 108,
  XDBC_SUBCODE_INTERVAL_DAY_TO_MINUTE = 109,
  XDBC_SUBCODE_INTERVAL_DAY_TO_SECOND = 110,
  XDBC_SUBCODE_INTERVAL_HOUR_TO_MINUTE = 111,
  XDBC_SUBCODE_INTERVAL_HOUR_TO_SECOND = 112,
  XDBC_SUBCODE_INTERVAL_MINUTE_TO_SECOND = 113,
  UNRECOGNIZED = -1,
}

export function xdbcDatetimeSubcodeFromJSON(object: any): XdbcDatetimeSubcode {
  switch (object) {
    case 0:
    case "XDBC_SUBCODE_UNKNOWN":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_UNKNOWN;
    case 1:
    case "XDBC_SUBCODE_YEAR":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_YEAR;
    case 1:
    case "XDBC_SUBCODE_DATE":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_DATE;
    case 2:
    case "XDBC_SUBCODE_TIME":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_TIME;
    case 2:
    case "XDBC_SUBCODE_MONTH":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_MONTH;
    case 3:
    case "XDBC_SUBCODE_TIMESTAMP":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_TIMESTAMP;
    case 3:
    case "XDBC_SUBCODE_DAY":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_DAY;
    case 4:
    case "XDBC_SUBCODE_TIME_WITH_TIMEZONE":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_TIME_WITH_TIMEZONE;
    case 4:
    case "XDBC_SUBCODE_HOUR":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_HOUR;
    case 5:
    case "XDBC_SUBCODE_TIMESTAMP_WITH_TIMEZONE":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_TIMESTAMP_WITH_TIMEZONE;
    case 5:
    case "XDBC_SUBCODE_MINUTE":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_MINUTE;
    case 6:
    case "XDBC_SUBCODE_SECOND":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_SECOND;
    case 7:
    case "XDBC_SUBCODE_YEAR_TO_MONTH":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_YEAR_TO_MONTH;
    case 8:
    case "XDBC_SUBCODE_DAY_TO_HOUR":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_DAY_TO_HOUR;
    case 9:
    case "XDBC_SUBCODE_DAY_TO_MINUTE":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_DAY_TO_MINUTE;
    case 10:
    case "XDBC_SUBCODE_DAY_TO_SECOND":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_DAY_TO_SECOND;
    case 11:
    case "XDBC_SUBCODE_HOUR_TO_MINUTE":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_HOUR_TO_MINUTE;
    case 12:
    case "XDBC_SUBCODE_HOUR_TO_SECOND":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_HOUR_TO_SECOND;
    case 13:
    case "XDBC_SUBCODE_MINUTE_TO_SECOND":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_MINUTE_TO_SECOND;
    case 101:
    case "XDBC_SUBCODE_INTERVAL_YEAR":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_YEAR;
    case 102:
    case "XDBC_SUBCODE_INTERVAL_MONTH":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_MONTH;
    case 103:
    case "XDBC_SUBCODE_INTERVAL_DAY":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_DAY;
    case 104:
    case "XDBC_SUBCODE_INTERVAL_HOUR":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_HOUR;
    case 105:
    case "XDBC_SUBCODE_INTERVAL_MINUTE":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_MINUTE;
    case 106:
    case "XDBC_SUBCODE_INTERVAL_SECOND":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_SECOND;
    case 107:
    case "XDBC_SUBCODE_INTERVAL_YEAR_TO_MONTH":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_YEAR_TO_MONTH;
    case 108:
    case "XDBC_SUBCODE_INTERVAL_DAY_TO_HOUR":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_DAY_TO_HOUR;
    case 109:
    case "XDBC_SUBCODE_INTERVAL_DAY_TO_MINUTE":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_DAY_TO_MINUTE;
    case 110:
    case "XDBC_SUBCODE_INTERVAL_DAY_TO_SECOND":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_DAY_TO_SECOND;
    case 111:
    case "XDBC_SUBCODE_INTERVAL_HOUR_TO_MINUTE":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_HOUR_TO_MINUTE;
    case 112:
    case "XDBC_SUBCODE_INTERVAL_HOUR_TO_SECOND":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_HOUR_TO_SECOND;
    case 113:
    case "XDBC_SUBCODE_INTERVAL_MINUTE_TO_SECOND":
      return XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_MINUTE_TO_SECOND;
    case -1:
    case "UNRECOGNIZED":
    default:
      return XdbcDatetimeSubcode.UNRECOGNIZED;
  }
}

export function xdbcDatetimeSubcodeToJSON(object: XdbcDatetimeSubcode): string {
  switch (object) {
    case XdbcDatetimeSubcode.XDBC_SUBCODE_UNKNOWN:
      return "XDBC_SUBCODE_UNKNOWN";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_YEAR:
      return "XDBC_SUBCODE_YEAR";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_DATE:
      return "XDBC_SUBCODE_DATE";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_TIME:
      return "XDBC_SUBCODE_TIME";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_MONTH:
      return "XDBC_SUBCODE_MONTH";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_TIMESTAMP:
      return "XDBC_SUBCODE_TIMESTAMP";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_DAY:
      return "XDBC_SUBCODE_DAY";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_TIME_WITH_TIMEZONE:
      return "XDBC_SUBCODE_TIME_WITH_TIMEZONE";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_HOUR:
      return "XDBC_SUBCODE_HOUR";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_TIMESTAMP_WITH_TIMEZONE:
      return "XDBC_SUBCODE_TIMESTAMP_WITH_TIMEZONE";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_MINUTE:
      return "XDBC_SUBCODE_MINUTE";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_SECOND:
      return "XDBC_SUBCODE_SECOND";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_YEAR_TO_MONTH:
      return "XDBC_SUBCODE_YEAR_TO_MONTH";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_DAY_TO_HOUR:
      return "XDBC_SUBCODE_DAY_TO_HOUR";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_DAY_TO_MINUTE:
      return "XDBC_SUBCODE_DAY_TO_MINUTE";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_DAY_TO_SECOND:
      return "XDBC_SUBCODE_DAY_TO_SECOND";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_HOUR_TO_MINUTE:
      return "XDBC_SUBCODE_HOUR_TO_MINUTE";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_HOUR_TO_SECOND:
      return "XDBC_SUBCODE_HOUR_TO_SECOND";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_MINUTE_TO_SECOND:
      return "XDBC_SUBCODE_MINUTE_TO_SECOND";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_YEAR:
      return "XDBC_SUBCODE_INTERVAL_YEAR";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_MONTH:
      return "XDBC_SUBCODE_INTERVAL_MONTH";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_DAY:
      return "XDBC_SUBCODE_INTERVAL_DAY";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_HOUR:
      return "XDBC_SUBCODE_INTERVAL_HOUR";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_MINUTE:
      return "XDBC_SUBCODE_INTERVAL_MINUTE";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_SECOND:
      return "XDBC_SUBCODE_INTERVAL_SECOND";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_YEAR_TO_MONTH:
      return "XDBC_SUBCODE_INTERVAL_YEAR_TO_MONTH";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_DAY_TO_HOUR:
      return "XDBC_SUBCODE_INTERVAL_DAY_TO_HOUR";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_DAY_TO_MINUTE:
      return "XDBC_SUBCODE_INTERVAL_DAY_TO_MINUTE";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_DAY_TO_SECOND:
      return "XDBC_SUBCODE_INTERVAL_DAY_TO_SECOND";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_HOUR_TO_MINUTE:
      return "XDBC_SUBCODE_INTERVAL_HOUR_TO_MINUTE";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_HOUR_TO_SECOND:
      return "XDBC_SUBCODE_INTERVAL_HOUR_TO_SECOND";
    case XdbcDatetimeSubcode.XDBC_SUBCODE_INTERVAL_MINUTE_TO_SECOND:
      return "XDBC_SUBCODE_INTERVAL_MINUTE_TO_SECOND";
    case XdbcDatetimeSubcode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum Nullable {
  /** NULLABILITY_NO_NULLS - Indicates that the fields does not allow the use of null values. */
  NULLABILITY_NO_NULLS = 0,
  /** NULLABILITY_NULLABLE - Indicates that the fields allow the use of null values. */
  NULLABILITY_NULLABLE = 1,
  /** NULLABILITY_UNKNOWN - Indicates that nullability of the fields cannot be determined. */
  NULLABILITY_UNKNOWN = 2,
  UNRECOGNIZED = -1,
}

export function nullableFromJSON(object: any): Nullable {
  switch (object) {
    case 0:
    case "NULLABILITY_NO_NULLS":
      return Nullable.NULLABILITY_NO_NULLS;
    case 1:
    case "NULLABILITY_NULLABLE":
      return Nullable.NULLABILITY_NULLABLE;
    case 2:
    case "NULLABILITY_UNKNOWN":
      return Nullable.NULLABILITY_UNKNOWN;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Nullable.UNRECOGNIZED;
  }
}

export function nullableToJSON(object: Nullable): string {
  switch (object) {
    case Nullable.NULLABILITY_NO_NULLS:
      return "NULLABILITY_NO_NULLS";
    case Nullable.NULLABILITY_NULLABLE:
      return "NULLABILITY_NULLABLE";
    case Nullable.NULLABILITY_UNKNOWN:
      return "NULLABILITY_UNKNOWN";
    case Nullable.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum Searchable {
  /** NONE - Indicates that column cannot be used in a WHERE clause. */
  NONE = 0,
  /**
   * CHAR - Indicates that the column can be used in a WHERE clause if it is using a
   * LIKE operator.
   */
  CHAR = 1,
  /**
   * BASIC - Indicates that the column can be used In a WHERE clause with any
   * operator other than LIKE.
   *
   * - Allowed operators: comparison, quantified comparison, BETWEEN,
   *                      DISTINCT, IN, MATCH, and UNIQUE.
   */
  BASIC = 2,
  /** FULL - Indicates that the column can be used in a WHERE clause using any operator. */
  FULL = 3,
  UNRECOGNIZED = -1,
}

export function searchableFromJSON(object: any): Searchable {
  switch (object) {
    case 0:
    case "SEARCHABLE_NONE":
      return Searchable.NONE;
    case 1:
    case "SEARCHABLE_CHAR":
      return Searchable.CHAR;
    case 2:
    case "SEARCHABLE_BASIC":
      return Searchable.BASIC;
    case 3:
    case "SEARCHABLE_FULL":
      return Searchable.FULL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Searchable.UNRECOGNIZED;
  }
}

export function searchableToJSON(object: Searchable): string {
  switch (object) {
    case Searchable.NONE:
      return "SEARCHABLE_NONE";
    case Searchable.CHAR:
      return "SEARCHABLE_CHAR";
    case Searchable.BASIC:
      return "SEARCHABLE_BASIC";
    case Searchable.FULL:
      return "SEARCHABLE_FULL";
    case Searchable.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum UpdateDeleteRules {
  CASCADE = 0,
  RESTRICT = 1,
  SET_NULL = 2,
  NO_ACTION = 3,
  SET_DEFAULT = 4,
  UNRECOGNIZED = -1,
}

export function updateDeleteRulesFromJSON(object: any): UpdateDeleteRules {
  switch (object) {
    case 0:
    case "CASCADE":
      return UpdateDeleteRules.CASCADE;
    case 1:
    case "RESTRICT":
      return UpdateDeleteRules.RESTRICT;
    case 2:
    case "SET_NULL":
      return UpdateDeleteRules.SET_NULL;
    case 3:
    case "NO_ACTION":
      return UpdateDeleteRules.NO_ACTION;
    case 4:
    case "SET_DEFAULT":
      return UpdateDeleteRules.SET_DEFAULT;
    case -1:
    case "UNRECOGNIZED":
    default:
      return UpdateDeleteRules.UNRECOGNIZED;
  }
}

export function updateDeleteRulesToJSON(object: UpdateDeleteRules): string {
  switch (object) {
    case UpdateDeleteRules.CASCADE:
      return "CASCADE";
    case UpdateDeleteRules.RESTRICT:
      return "RESTRICT";
    case UpdateDeleteRules.SET_NULL:
      return "SET_NULL";
    case UpdateDeleteRules.NO_ACTION:
      return "NO_ACTION";
    case UpdateDeleteRules.SET_DEFAULT:
      return "SET_DEFAULT";
    case UpdateDeleteRules.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Represents a metadata request. Used in the command member of FlightDescriptor
 * for the following RPC calls:
 *  - GetSchema: return the Arrow schema of the query.
 *  - GetFlightInfo: execute the metadata request.
 *
 * The returned Arrow schema will be:
 * <
 *  info_name: uint32 not null,
 *  value: dense_union<
 *              string_value: utf8,
 *              bool_value: bool,
 *              bigint_value: int64,
 *              int32_bitmask: int32,
 *              string_list: list<string_data: utf8>
 *              int32_to_int32_list_map: map<key: int32, value: list<$data$: int32>>
 * >
 * where there is one row per requested piece of metadata information.
 */
export interface CommandGetSqlInfo {
  $type: "arrow.flight.protocol.sql.CommandGetSqlInfo";
  /**
   * Values are modelled after ODBC's SQLGetInfo() function. This information is intended to provide
   * Flight SQL clients with basic, SQL syntax and SQL functions related information.
   * More information types can be added in future releases.
   * E.g. more SQL syntax support types, scalar functions support, type conversion support etc.
   *
   * Note that the set of metadata may expand.
   *
   * Initially, Flight SQL will support the following information types:
   * - Server Information - Range [0-500)
   * - Syntax Information - Range [500-1000)
   * Range [0-10,000) is reserved for defaults (see SqlInfo enum for default options).
   * Custom options should start at 10,000.
   *
   * If omitted, then all metadata will be retrieved.
   * Flight SQL Servers may choose to include additional metadata above and beyond the specified set, however they must
   * at least return the specified set. IDs ranging from 0 to 10,000 (exclusive) are reserved for future use.
   * If additional metadata is included, the metadata IDs should start from 10,000.
   */
  readonly info: readonly number[];
}

/**
 * Represents a request to retrieve information about data type supported on a Flight SQL enabled backend.
 * Used in the command member of FlightDescriptor for the following RPC calls:
 *  - GetSchema: return the schema of the query.
 *  - GetFlightInfo: execute the catalog metadata request.
 *
 * The returned schema will be:
 * <
 *   type_name: utf8 not null (The name of the data type, for example: VARCHAR, INTEGER, etc),
 *   data_type: int32 not null (The SQL data type),
 *   column_size: int32 (The maximum size supported by that column.
 *                       In case of exact numeric types, this represents the maximum precision.
 *                       In case of string types, this represents the character length.
 *                       In case of datetime data types, this represents the length in characters of the string representation.
 *                       NULL is returned for data types where column size is not applicable.),
 *   literal_prefix: utf8 (Character or characters used to prefix a literal, NULL is returned for
 *                         data types where a literal prefix is not applicable.),
 *   literal_suffix: utf8 (Character or characters used to terminate a literal,
 *                         NULL is returned for data types where a literal suffix is not applicable.),
 *   create_params: list<utf8 not null>
 *                        (A list of keywords corresponding to which parameters can be used when creating
 *                         a column for that specific type.
 *                         NULL is returned if there are no parameters for the data type definition.),
 *   nullable: int32 not null (Shows if the data type accepts a NULL value. The possible values can be seen in the
 *                             Nullable enum.),
 *   case_sensitive: bool not null (Shows if a character data type is case-sensitive in collations and comparisons),
 *   searchable: int32 not null (Shows how the data type is used in a WHERE clause. The possible values can be seen in the
 *                               Searchable enum.),
 *   unsigned_attribute: bool (Shows if the data type is unsigned. NULL is returned if the attribute is
 *                             not applicable to the data type or the data type is not numeric.),
 *   fixed_prec_scale: bool not null (Shows if the data type has predefined fixed precision and scale.),
 *   auto_increment: bool (Shows if the data type is auto incremental. NULL is returned if the attribute
 *                         is not applicable to the data type or the data type is not numeric.),
 *   local_type_name: utf8 (Localized version of the data source-dependent name of the data type. NULL
 *                          is returned if a localized name is not supported by the data source),
 *   minimum_scale: int32 (The minimum scale of the data type on the data source.
 *                         If a data type has a fixed scale, the MINIMUM_SCALE and MAXIMUM_SCALE
 *                         columns both contain this value. NULL is returned if scale is not applicable.),
 *   maximum_scale: int32 (The maximum scale of the data type on the data source.
 *                         NULL is returned if scale is not applicable.),
 *   sql_data_type: int32 not null (The value of the SQL DATA TYPE which has the same values
 *                                  as data_type value. Except for interval and datetime, which
 *                                  uses generic values. More info about those types can be
 *                                  obtained through datetime_subcode. The possible values can be seen
 *                                  in the XdbcDataType enum.),
 *   datetime_subcode: int32 (Only used when the SQL DATA TYPE is interval or datetime. It contains
 *                            its sub types. For type different from interval and datetime, this value
 *                            is NULL. The possible values can be seen in the XdbcDatetimeSubcode enum.),
 *   num_prec_radix: int32 (If the data type is an approximate numeric type, this column contains
 *                          the value 2 to indicate that COLUMN_SIZE specifies a number of bits. For
 *                          exact numeric types, this column contains the value 10 to indicate that
 *                          column size specifies a number of decimal digits. Otherwise, this column is NULL.),
 *   interval_precision: int32 (If the data type is an interval data type, then this column contains the value
 *                              of the interval leading precision. Otherwise, this column is NULL. This fields
 *                              is only relevant to be used by ODBC).
 * >
 * The returned data should be ordered by data_type and then by type_name.
 */
export interface CommandGetXdbcTypeInfo {
  $type: "arrow.flight.protocol.sql.CommandGetXdbcTypeInfo";
  /** Specifies the data type to search for the info. */
  readonly dataType?: number | undefined;
}

/**
 * Represents a request to retrieve the list of catalogs on a Flight SQL enabled backend.
 * The definition of a catalog depends on vendor/implementation. It is usually the database itself
 * Used in the command member of FlightDescriptor for the following RPC calls:
 *  - GetSchema: return the Arrow schema of the query.
 *  - GetFlightInfo: execute the catalog metadata request.
 *
 * The returned Arrow schema will be:
 * <
 *  catalog_name: utf8 not null
 * >
 * The returned data should be ordered by catalog_name.
 */
export interface CommandGetCatalogs {
  $type: "arrow.flight.protocol.sql.CommandGetCatalogs";
}

/**
 * Represents a request to retrieve the list of database schemas on a Flight SQL enabled backend.
 * The definition of a database schema depends on vendor/implementation. It is usually a collection of tables.
 * Used in the command member of FlightDescriptor for the following RPC calls:
 *  - GetSchema: return the Arrow schema of the query.
 *  - GetFlightInfo: execute the catalog metadata request.
 *
 * The returned Arrow schema will be:
 * <
 *  catalog_name: utf8,
 *  db_schema_name: utf8 not null
 * >
 * The returned data should be ordered by catalog_name, then db_schema_name.
 */
export interface CommandGetDbSchemas {
  $type: "arrow.flight.protocol.sql.CommandGetDbSchemas";
  /**
   * Specifies the Catalog to search for the tables.
   * An empty string retrieves those without a catalog.
   * If omitted the catalog name should not be used to narrow the search.
   */
  readonly catalog?:
    | string
    | undefined;
  /**
   * Specifies a filter pattern for schemas to search for.
   * When no db_schema_filter_pattern is provided, the pattern will not be used to narrow the search.
   * In the pattern string, two special characters can be used to denote matching rules:
   *    - "%" means to match any substring with 0 or more characters.
   *    - "_" means to match any one character.
   */
  readonly dbSchemaFilterPattern?: string | undefined;
}

/**
 * Represents a request to retrieve the list of tables, and optionally their schemas, on a Flight SQL enabled backend.
 * Used in the command member of FlightDescriptor for the following RPC calls:
 *  - GetSchema: return the Arrow schema of the query.
 *  - GetFlightInfo: execute the catalog metadata request.
 *
 * The returned Arrow schema will be:
 * <
 *  catalog_name: utf8,
 *  db_schema_name: utf8,
 *  table_name: utf8 not null,
 *  table_type: utf8 not null,
 *  [optional] table_schema: bytes not null (schema of the table as described in Schema.fbs::Schema,
 *                                           it is serialized as an IPC message.)
 * >
 * Fields on table_schema may contain the following metadata:
 *  - ARROW:FLIGHT:SQL:CATALOG_NAME      - Table's catalog name
 *  - ARROW:FLIGHT:SQL:DB_SCHEMA_NAME    - Database schema name
 *  - ARROW:FLIGHT:SQL:TABLE_NAME        - Table name
 *  - ARROW:FLIGHT:SQL:TYPE_NAME         - The data source-specific name for the data type of the column.
 *  - ARROW:FLIGHT:SQL:PRECISION         - Column precision/size
 *  - ARROW:FLIGHT:SQL:SCALE             - Column scale/decimal digits if applicable
 *  - ARROW:FLIGHT:SQL:IS_AUTO_INCREMENT - "1" indicates if the column is auto incremented, "0" otherwise.
 *  - ARROW:FLIGHT:SQL:IS_CASE_SENSITIVE - "1" indicates if the column is case-sensitive, "0" otherwise.
 *  - ARROW:FLIGHT:SQL:IS_READ_ONLY      - "1" indicates if the column is read only, "0" otherwise.
 *  - ARROW:FLIGHT:SQL:IS_SEARCHABLE     - "1" indicates if the column is searchable via WHERE clause, "0" otherwise.
 * The returned data should be ordered by catalog_name, db_schema_name, table_name, then table_type, followed by table_schema if requested.
 */
export interface CommandGetTables {
  $type: "arrow.flight.protocol.sql.CommandGetTables";
  /**
   * Specifies the Catalog to search for the tables.
   * An empty string retrieves those without a catalog.
   * If omitted the catalog name should not be used to narrow the search.
   */
  readonly catalog?:
    | string
    | undefined;
  /**
   * Specifies a filter pattern for schemas to search for.
   * When no db_schema_filter_pattern is provided, all schemas matching other filters are searched.
   * In the pattern string, two special characters can be used to denote matching rules:
   *    - "%" means to match any substring with 0 or more characters.
   *    - "_" means to match any one character.
   */
  readonly dbSchemaFilterPattern?:
    | string
    | undefined;
  /**
   * Specifies a filter pattern for tables to search for.
   * When no table_name_filter_pattern is provided, all tables matching other filters are searched.
   * In the pattern string, two special characters can be used to denote matching rules:
   *    - "%" means to match any substring with 0 or more characters.
   *    - "_" means to match any one character.
   */
  readonly tableNameFilterPattern?:
    | string
    | undefined;
  /**
   * Specifies a filter of table types which must match.
   * The table types depend on vendor/implementation. It is usually used to separate tables from views or system tables.
   * TABLE, VIEW, and SYSTEM TABLE are commonly supported.
   */
  readonly tableTypes: readonly string[];
  /** Specifies if the Arrow schema should be returned for found tables. */
  readonly includeSchema: boolean;
}

/**
 * Represents a request to retrieve the list of table types on a Flight SQL enabled backend.
 * The table types depend on vendor/implementation. It is usually used to separate tables from views or system tables.
 * TABLE, VIEW, and SYSTEM TABLE are commonly supported.
 * Used in the command member of FlightDescriptor for the following RPC calls:
 *  - GetSchema: return the Arrow schema of the query.
 *  - GetFlightInfo: execute the catalog metadata request.
 *
 * The returned Arrow schema will be:
 * <
 *  table_type: utf8 not null
 * >
 * The returned data should be ordered by table_type.
 */
export interface CommandGetTableTypes {
  $type: "arrow.flight.protocol.sql.CommandGetTableTypes";
}

/**
 * Represents a request to retrieve the primary keys of a table on a Flight SQL enabled backend.
 * Used in the command member of FlightDescriptor for the following RPC calls:
 *  - GetSchema: return the Arrow schema of the query.
 *  - GetFlightInfo: execute the catalog metadata request.
 *
 * The returned Arrow schema will be:
 * <
 *  catalog_name: utf8,
 *  db_schema_name: utf8,
 *  table_name: utf8 not null,
 *  column_name: utf8 not null,
 *  key_name: utf8,
 *  key_sequence: int32 not null
 * >
 * The returned data should be ordered by catalog_name, db_schema_name, table_name, key_name, then key_sequence.
 */
export interface CommandGetPrimaryKeys {
  $type: "arrow.flight.protocol.sql.CommandGetPrimaryKeys";
  /**
   * Specifies the catalog to search for the table.
   * An empty string retrieves those without a catalog.
   * If omitted the catalog name should not be used to narrow the search.
   */
  readonly catalog?:
    | string
    | undefined;
  /**
   * Specifies the schema to search for the table.
   * An empty string retrieves those without a schema.
   * If omitted the schema name should not be used to narrow the search.
   */
  readonly dbSchema?:
    | string
    | undefined;
  /** Specifies the table to get the primary keys for. */
  readonly table: string;
}

/**
 * Represents a request to retrieve a description of the foreign key columns that reference the given table's
 * primary key columns (the foreign keys exported by a table) of a table on a Flight SQL enabled backend.
 * Used in the command member of FlightDescriptor for the following RPC calls:
 *  - GetSchema: return the Arrow schema of the query.
 *  - GetFlightInfo: execute the catalog metadata request.
 *
 * The returned Arrow schema will be:
 * <
 *  pk_catalog_name: utf8,
 *  pk_db_schema_name: utf8,
 *  pk_table_name: utf8 not null,
 *  pk_column_name: utf8 not null,
 *  fk_catalog_name: utf8,
 *  fk_db_schema_name: utf8,
 *  fk_table_name: utf8 not null,
 *  fk_column_name: utf8 not null,
 *  key_sequence: int32 not null,
 *  fk_key_name: utf8,
 *  pk_key_name: utf8,
 *  update_rule: uint8 not null,
 *  delete_rule: uint8 not null
 * >
 * The returned data should be ordered by fk_catalog_name, fk_db_schema_name, fk_table_name, fk_key_name, then key_sequence.
 * update_rule and delete_rule returns a byte that is equivalent to actions declared on UpdateDeleteRules enum.
 */
export interface CommandGetExportedKeys {
  $type: "arrow.flight.protocol.sql.CommandGetExportedKeys";
  /**
   * Specifies the catalog to search for the foreign key table.
   * An empty string retrieves those without a catalog.
   * If omitted the catalog name should not be used to narrow the search.
   */
  readonly catalog?:
    | string
    | undefined;
  /**
   * Specifies the schema to search for the foreign key table.
   * An empty string retrieves those without a schema.
   * If omitted the schema name should not be used to narrow the search.
   */
  readonly dbSchema?:
    | string
    | undefined;
  /** Specifies the foreign key table to get the foreign keys for. */
  readonly table: string;
}

/**
 * Represents a request to retrieve the foreign keys of a table on a Flight SQL enabled backend.
 * Used in the command member of FlightDescriptor for the following RPC calls:
 *  - GetSchema: return the Arrow schema of the query.
 *  - GetFlightInfo: execute the catalog metadata request.
 *
 * The returned Arrow schema will be:
 * <
 *  pk_catalog_name: utf8,
 *  pk_db_schema_name: utf8,
 *  pk_table_name: utf8 not null,
 *  pk_column_name: utf8 not null,
 *  fk_catalog_name: utf8,
 *  fk_db_schema_name: utf8,
 *  fk_table_name: utf8 not null,
 *  fk_column_name: utf8 not null,
 *  key_sequence: int32 not null,
 *  fk_key_name: utf8,
 *  pk_key_name: utf8,
 *  update_rule: uint8 not null,
 *  delete_rule: uint8 not null
 * >
 * The returned data should be ordered by pk_catalog_name, pk_db_schema_name, pk_table_name, pk_key_name, then key_sequence.
 * update_rule and delete_rule returns a byte that is equivalent to actions:
 *    - 0 = CASCADE
 *    - 1 = RESTRICT
 *    - 2 = SET NULL
 *    - 3 = NO ACTION
 *    - 4 = SET DEFAULT
 */
export interface CommandGetImportedKeys {
  $type: "arrow.flight.protocol.sql.CommandGetImportedKeys";
  /**
   * Specifies the catalog to search for the primary key table.
   * An empty string retrieves those without a catalog.
   * If omitted the catalog name should not be used to narrow the search.
   */
  readonly catalog?:
    | string
    | undefined;
  /**
   * Specifies the schema to search for the primary key table.
   * An empty string retrieves those without a schema.
   * If omitted the schema name should not be used to narrow the search.
   */
  readonly dbSchema?:
    | string
    | undefined;
  /** Specifies the primary key table to get the foreign keys for. */
  readonly table: string;
}

/**
 * Represents a request to retrieve a description of the foreign key columns in the given foreign key table that
 * reference the primary key or the columns representing a unique constraint of the parent table (could be the same
 * or a different table) on a Flight SQL enabled backend.
 * Used in the command member of FlightDescriptor for the following RPC calls:
 *  - GetSchema: return the Arrow schema of the query.
 *  - GetFlightInfo: execute the catalog metadata request.
 *
 * The returned Arrow schema will be:
 * <
 *  pk_catalog_name: utf8,
 *  pk_db_schema_name: utf8,
 *  pk_table_name: utf8 not null,
 *  pk_column_name: utf8 not null,
 *  fk_catalog_name: utf8,
 *  fk_db_schema_name: utf8,
 *  fk_table_name: utf8 not null,
 *  fk_column_name: utf8 not null,
 *  key_sequence: int32 not null,
 *  fk_key_name: utf8,
 *  pk_key_name: utf8,
 *  update_rule: uint8 not null,
 *  delete_rule: uint8 not null
 * >
 * The returned data should be ordered by pk_catalog_name, pk_db_schema_name, pk_table_name, pk_key_name, then key_sequence.
 * update_rule and delete_rule returns a byte that is equivalent to actions:
 *    - 0 = CASCADE
 *    - 1 = RESTRICT
 *    - 2 = SET NULL
 *    - 3 = NO ACTION
 *    - 4 = SET DEFAULT
 */
export interface CommandGetCrossReference {
  $type: "arrow.flight.protocol.sql.CommandGetCrossReference";
  /**
   * The catalog name where the parent table is.
   * An empty string retrieves those without a catalog.
   * If omitted the catalog name should not be used to narrow the search.
   */
  readonly pkCatalog?:
    | string
    | undefined;
  /**
   * The Schema name where the parent table is.
   * An empty string retrieves those without a schema.
   * If omitted the schema name should not be used to narrow the search.
   */
  readonly pkDbSchema?:
    | string
    | undefined;
  /** The parent table name. It cannot be null. */
  readonly pkTable: string;
  /**
   * The catalog name where the foreign table is.
   * An empty string retrieves those without a catalog.
   * If omitted the catalog name should not be used to narrow the search.
   */
  readonly fkCatalog?:
    | string
    | undefined;
  /**
   * The schema name where the foreign table is.
   * An empty string retrieves those without a schema.
   * If omitted the schema name should not be used to narrow the search.
   */
  readonly fkDbSchema?:
    | string
    | undefined;
  /** The foreign table name. It cannot be null. */
  readonly fkTable: string;
}

/** Request message for the "CreatePreparedStatement" action on a Flight SQL enabled backend. */
export interface ActionCreatePreparedStatementRequest {
  $type: "arrow.flight.protocol.sql.ActionCreatePreparedStatementRequest";
  /** The valid SQL string to create a prepared statement for. */
  readonly query: string;
  /**
   * Create/execute the prepared statement as part of this transaction (if
   * unset, executions of the prepared statement will be auto-committed).
   */
  readonly transactionId?: Uint8Array | undefined;
}

/** An embedded message describing a Substrait plan to execute. */
export interface SubstraitPlan {
  $type: "arrow.flight.protocol.sql.SubstraitPlan";
  /**
   * The serialized substrait.Plan to create a prepared statement for.
   * XXX(ARROW-16902): this is bytes instead of an embedded message
   * because Protobuf does not really support one DLL using Protobuf
   * definitions from another DLL.
   */
  readonly plan: Uint8Array;
  /**
   * The Substrait release, e.g. "0.12.0". This information is not
   * tracked in the plan itself, so this is the only way for consumers
   * to potentially know if they can handle the plan.
   */
  readonly version: string;
}

/** Request message for the "CreatePreparedSubstraitPlan" action on a Flight SQL enabled backend. */
export interface ActionCreatePreparedSubstraitPlanRequest {
  $type: "arrow.flight.protocol.sql.ActionCreatePreparedSubstraitPlanRequest";
  /** The serialized substrait.Plan to create a prepared statement for. */
  readonly plan:
    | SubstraitPlan
    | undefined;
  /**
   * Create/execute the prepared statement as part of this transaction (if
   * unset, executions of the prepared statement will be auto-committed).
   */
  readonly transactionId?: Uint8Array | undefined;
}

/**
 * Wrap the result of a "CreatePreparedStatement" or "CreatePreparedSubstraitPlan" action.
 *
 * The resultant PreparedStatement can be closed either:
 * - Manually, through the "ClosePreparedStatement" action;
 * - Automatically, by a server timeout.
 *
 * The result should be wrapped in a google.protobuf.Any message.
 */
export interface ActionCreatePreparedStatementResult {
  $type: "arrow.flight.protocol.sql.ActionCreatePreparedStatementResult";
  /** Opaque handle for the prepared statement on the server. */
  readonly preparedStatementHandle: Uint8Array;
  /**
   * If a result set generating query was provided, dataset_schema contains the
   * schema of the result set.  It should be an IPC-encapsulated Schema, as described in Schema.fbs.
   * For some queries, the schema of the results may depend on the schema of the parameters.  The server
   * should provide its best guess as to the schema at this point.  Clients must not assume that this
   * schema, if provided, will be accurate.
   */
  readonly datasetSchema: Uint8Array;
  /**
   * If the query provided contained parameters, parameter_schema contains the
   * schema of the expected parameters.  It should be an IPC-encapsulated Schema, as described in Schema.fbs.
   */
  readonly parameterSchema: Uint8Array;
}

/**
 * Request message for the "ClosePreparedStatement" action on a Flight SQL enabled backend.
 * Closes server resources associated with the prepared statement handle.
 */
export interface ActionClosePreparedStatementRequest {
  $type: "arrow.flight.protocol.sql.ActionClosePreparedStatementRequest";
  /** Opaque handle for the prepared statement on the server. */
  readonly preparedStatementHandle: Uint8Array;
}

/**
 * Request message for the "BeginTransaction" action.
 * Begins a transaction.
 */
export interface ActionBeginTransactionRequest {
  $type: "arrow.flight.protocol.sql.ActionBeginTransactionRequest";
}

/**
 * Request message for the "BeginSavepoint" action.
 * Creates a savepoint within a transaction.
 *
 * Only supported if FLIGHT_SQL_TRANSACTION is
 * FLIGHT_SQL_TRANSACTION_SUPPORT_SAVEPOINT.
 */
export interface ActionBeginSavepointRequest {
  $type: "arrow.flight.protocol.sql.ActionBeginSavepointRequest";
  /** The transaction to which a savepoint belongs. */
  readonly transactionId: Uint8Array;
  /** Name for the savepoint. */
  readonly name: string;
}

/**
 * The result of a "BeginTransaction" action.
 *
 * The transaction can be manipulated with the "EndTransaction" action, or
 * automatically via server timeout. If the transaction times out, then it is
 * automatically rolled back.
 *
 * The result should be wrapped in a google.protobuf.Any message.
 */
export interface ActionBeginTransactionResult {
  $type: "arrow.flight.protocol.sql.ActionBeginTransactionResult";
  /** Opaque handle for the transaction on the server. */
  readonly transactionId: Uint8Array;
}

/**
 * The result of a "BeginSavepoint" action.
 *
 * The transaction can be manipulated with the "EndSavepoint" action.
 * If the associated transaction is committed, rolled back, or times
 * out, then the savepoint is also invalidated.
 *
 * The result should be wrapped in a google.protobuf.Any message.
 */
export interface ActionBeginSavepointResult {
  $type: "arrow.flight.protocol.sql.ActionBeginSavepointResult";
  /** Opaque handle for the savepoint on the server. */
  readonly savepointId: Uint8Array;
}

/**
 * Request message for the "EndTransaction" action.
 *
 * Commit (COMMIT) or rollback (ROLLBACK) the transaction.
 *
 * If the action completes successfully, the transaction handle is
 * invalidated, as are all associated savepoints.
 */
export interface ActionEndTransactionRequest {
  $type: "arrow.flight.protocol.sql.ActionEndTransactionRequest";
  /** Opaque handle for the transaction on the server. */
  readonly transactionId: Uint8Array;
  /** Whether to commit/rollback the given transaction. */
  readonly action: ActionEndTransactionRequest_EndTransaction;
}

export enum ActionEndTransactionRequest_EndTransaction {
  UNSPECIFIED = 0,
  /** COMMIT - Commit the transaction. */
  COMMIT = 1,
  /** ROLLBACK - Roll back the transaction. */
  ROLLBACK = 2,
  UNRECOGNIZED = -1,
}

export function actionEndTransactionRequest_EndTransactionFromJSON(
  object: any,
): ActionEndTransactionRequest_EndTransaction {
  switch (object) {
    case 0:
    case "END_TRANSACTION_UNSPECIFIED":
      return ActionEndTransactionRequest_EndTransaction.UNSPECIFIED;
    case 1:
    case "END_TRANSACTION_COMMIT":
      return ActionEndTransactionRequest_EndTransaction.COMMIT;
    case 2:
    case "END_TRANSACTION_ROLLBACK":
      return ActionEndTransactionRequest_EndTransaction.ROLLBACK;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ActionEndTransactionRequest_EndTransaction.UNRECOGNIZED;
  }
}

export function actionEndTransactionRequest_EndTransactionToJSON(
  object: ActionEndTransactionRequest_EndTransaction,
): string {
  switch (object) {
    case ActionEndTransactionRequest_EndTransaction.UNSPECIFIED:
      return "END_TRANSACTION_UNSPECIFIED";
    case ActionEndTransactionRequest_EndTransaction.COMMIT:
      return "END_TRANSACTION_COMMIT";
    case ActionEndTransactionRequest_EndTransaction.ROLLBACK:
      return "END_TRANSACTION_ROLLBACK";
    case ActionEndTransactionRequest_EndTransaction.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Request message for the "EndSavepoint" action.
 *
 * Release (RELEASE) the savepoint or rollback (ROLLBACK) to the
 * savepoint.
 *
 * Releasing a savepoint invalidates that savepoint.  Rolling back to
 * a savepoint does not invalidate the savepoint, but invalidates all
 * savepoints created after the current savepoint.
 */
export interface ActionEndSavepointRequest {
  $type: "arrow.flight.protocol.sql.ActionEndSavepointRequest";
  /** Opaque handle for the savepoint on the server. */
  readonly savepointId: Uint8Array;
  /** Whether to rollback/release the given savepoint. */
  readonly action: ActionEndSavepointRequest_EndSavepoint;
}

export enum ActionEndSavepointRequest_EndSavepoint {
  UNSPECIFIED = 0,
  /** RELEASE - Release the savepoint. */
  RELEASE = 1,
  /** ROLLBACK - Roll back to a savepoint. */
  ROLLBACK = 2,
  UNRECOGNIZED = -1,
}

export function actionEndSavepointRequest_EndSavepointFromJSON(object: any): ActionEndSavepointRequest_EndSavepoint {
  switch (object) {
    case 0:
    case "END_SAVEPOINT_UNSPECIFIED":
      return ActionEndSavepointRequest_EndSavepoint.UNSPECIFIED;
    case 1:
    case "END_SAVEPOINT_RELEASE":
      return ActionEndSavepointRequest_EndSavepoint.RELEASE;
    case 2:
    case "END_SAVEPOINT_ROLLBACK":
      return ActionEndSavepointRequest_EndSavepoint.ROLLBACK;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ActionEndSavepointRequest_EndSavepoint.UNRECOGNIZED;
  }
}

export function actionEndSavepointRequest_EndSavepointToJSON(object: ActionEndSavepointRequest_EndSavepoint): string {
  switch (object) {
    case ActionEndSavepointRequest_EndSavepoint.UNSPECIFIED:
      return "END_SAVEPOINT_UNSPECIFIED";
    case ActionEndSavepointRequest_EndSavepoint.RELEASE:
      return "END_SAVEPOINT_RELEASE";
    case ActionEndSavepointRequest_EndSavepoint.ROLLBACK:
      return "END_SAVEPOINT_ROLLBACK";
    case ActionEndSavepointRequest_EndSavepoint.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Represents a SQL query. Used in the command member of FlightDescriptor
 * for the following RPC calls:
 *  - GetSchema: return the Arrow schema of the query.
 *    Fields on this schema may contain the following metadata:
 *    - ARROW:FLIGHT:SQL:CATALOG_NAME      - Table's catalog name
 *    - ARROW:FLIGHT:SQL:DB_SCHEMA_NAME    - Database schema name
 *    - ARROW:FLIGHT:SQL:TABLE_NAME        - Table name
 *    - ARROW:FLIGHT:SQL:TYPE_NAME         - The data source-specific name for the data type of the column.
 *    - ARROW:FLIGHT:SQL:PRECISION         - Column precision/size
 *    - ARROW:FLIGHT:SQL:SCALE             - Column scale/decimal digits if applicable
 *    - ARROW:FLIGHT:SQL:IS_AUTO_INCREMENT - "1" indicates if the column is auto incremented, "0" otherwise.
 *    - ARROW:FLIGHT:SQL:IS_CASE_SENSITIVE - "1" indicates if the column is case-sensitive, "0" otherwise.
 *    - ARROW:FLIGHT:SQL:IS_READ_ONLY      - "1" indicates if the column is read only, "0" otherwise.
 *    - ARROW:FLIGHT:SQL:IS_SEARCHABLE     - "1" indicates if the column is searchable via WHERE clause, "0" otherwise.
 *  - GetFlightInfo: execute the query.
 */
export interface CommandStatementQuery {
  $type: "arrow.flight.protocol.sql.CommandStatementQuery";
  /** The SQL syntax. */
  readonly query: string;
  /** Include the query as part of this transaction (if unset, the query is auto-committed). */
  readonly transactionId?: Uint8Array | undefined;
}

/**
 * Represents a Substrait plan. Used in the command member of FlightDescriptor
 * for the following RPC calls:
 *  - GetSchema: return the Arrow schema of the query.
 *    Fields on this schema may contain the following metadata:
 *    - ARROW:FLIGHT:SQL:CATALOG_NAME      - Table's catalog name
 *    - ARROW:FLIGHT:SQL:DB_SCHEMA_NAME    - Database schema name
 *    - ARROW:FLIGHT:SQL:TABLE_NAME        - Table name
 *    - ARROW:FLIGHT:SQL:TYPE_NAME         - The data source-specific name for the data type of the column.
 *    - ARROW:FLIGHT:SQL:PRECISION         - Column precision/size
 *    - ARROW:FLIGHT:SQL:SCALE             - Column scale/decimal digits if applicable
 *    - ARROW:FLIGHT:SQL:IS_AUTO_INCREMENT - "1" indicates if the column is auto incremented, "0" otherwise.
 *    - ARROW:FLIGHT:SQL:IS_CASE_SENSITIVE - "1" indicates if the column is case-sensitive, "0" otherwise.
 *    - ARROW:FLIGHT:SQL:IS_READ_ONLY      - "1" indicates if the column is read only, "0" otherwise.
 *    - ARROW:FLIGHT:SQL:IS_SEARCHABLE     - "1" indicates if the column is searchable via WHERE clause, "0" otherwise.
 *  - GetFlightInfo: execute the query.
 *  - DoPut: execute the query.
 */
export interface CommandStatementSubstraitPlan {
  $type: "arrow.flight.protocol.sql.CommandStatementSubstraitPlan";
  /** A serialized substrait.Plan */
  readonly plan:
    | SubstraitPlan
    | undefined;
  /** Include the query as part of this transaction (if unset, the query is auto-committed). */
  readonly transactionId?: Uint8Array | undefined;
}

/**
 * Represents a ticket resulting from GetFlightInfo with a CommandStatementQuery.
 * This should be used only once and treated as an opaque value, that is, clients should not attempt to parse this.
 */
export interface TicketStatementQuery {
  $type: "arrow.flight.protocol.sql.TicketStatementQuery";
  /** Unique identifier for the instance of the statement to execute. */
  readonly statementHandle: Uint8Array;
}

/**
 * Represents an instance of executing a prepared statement. Used in the command member of FlightDescriptor for
 * the following RPC calls:
 *  - GetSchema: return the Arrow schema of the query.
 *    Fields on this schema may contain the following metadata:
 *    - ARROW:FLIGHT:SQL:CATALOG_NAME      - Table's catalog name
 *    - ARROW:FLIGHT:SQL:DB_SCHEMA_NAME    - Database schema name
 *    - ARROW:FLIGHT:SQL:TABLE_NAME        - Table name
 *    - ARROW:FLIGHT:SQL:TYPE_NAME         - The data source-specific name for the data type of the column.
 *    - ARROW:FLIGHT:SQL:PRECISION         - Column precision/size
 *    - ARROW:FLIGHT:SQL:SCALE             - Column scale/decimal digits if applicable
 *    - ARROW:FLIGHT:SQL:IS_AUTO_INCREMENT - "1" indicates if the column is auto incremented, "0" otherwise.
 *    - ARROW:FLIGHT:SQL:IS_CASE_SENSITIVE - "1" indicates if the column is case-sensitive, "0" otherwise.
 *    - ARROW:FLIGHT:SQL:IS_READ_ONLY      - "1" indicates if the column is read only, "0" otherwise.
 *    - ARROW:FLIGHT:SQL:IS_SEARCHABLE     - "1" indicates if the column is searchable via WHERE clause, "0" otherwise.
 *
 *    If the schema is retrieved after parameter values have been bound with DoPut, then the server should account
 *    for the parameters when determining the schema.
 *  - DoPut: bind parameter values. All of the bound parameter sets will be executed as a single atomic execution.
 *  - GetFlightInfo: execute the prepared statement instance.
 */
export interface CommandPreparedStatementQuery {
  $type: "arrow.flight.protocol.sql.CommandPreparedStatementQuery";
  /** Opaque handle for the prepared statement on the server. */
  readonly preparedStatementHandle: Uint8Array;
}

/**
 * Represents a SQL update query. Used in the command member of FlightDescriptor
 * for the RPC call DoPut to cause the server to execute the included SQL update.
 */
export interface CommandStatementUpdate {
  $type: "arrow.flight.protocol.sql.CommandStatementUpdate";
  /** The SQL syntax. */
  readonly query: string;
  /** Include the query as part of this transaction (if unset, the query is auto-committed). */
  readonly transactionId?: Uint8Array | undefined;
}

/**
 * Represents a SQL update query. Used in the command member of FlightDescriptor
 * for the RPC call DoPut to cause the server to execute the included
 * prepared statement handle as an update.
 */
export interface CommandPreparedStatementUpdate {
  $type: "arrow.flight.protocol.sql.CommandPreparedStatementUpdate";
  /** Opaque handle for the prepared statement on the server. */
  readonly preparedStatementHandle: Uint8Array;
}

/**
 * Represents a bulk ingestion request. Used in the command member of FlightDescriptor
 * for the the RPC call DoPut to cause the server load the contents of the stream's
 * FlightData into the target destination.
 */
export interface CommandStatementIngest {
  $type: "arrow.flight.protocol.sql.CommandStatementIngest";
  /** The behavior for handling the table definition. */
  readonly tableDefinitionOptions:
    | CommandStatementIngest_TableDefinitionOptions
    | undefined;
  /** The table to load data into. */
  readonly table: string;
  /** The db_schema of the destination table to load data into. If unset, a backend-specific default may be used. */
  readonly schema?:
    | string
    | undefined;
  /** The catalog of the destination table to load data into. If unset, a backend-specific default may be used. */
  readonly catalog?:
    | string
    | undefined;
  /**
   * Store ingested data in a temporary table.
   * The effect of setting temporary is to place the table in a backend-defined namespace, and to drop the table at the end of the session.
   * The namespacing may make use of a backend-specific schema and/or catalog.
   * The server should return an error if an explicit choice of schema or catalog is incompatible with the server's namespacing decision.
   */
  readonly temporary: boolean;
  /** Perform the ingestion as part of this transaction. If specified, results should not be committed in the event of an error/cancellation. */
  readonly transactionId?:
    | Uint8Array
    | undefined;
  /** Backend-specific options. */
  readonly options: { [key: string]: string };
}

/** Options for table definition behavior */
export interface CommandStatementIngest_TableDefinitionOptions {
  $type: "arrow.flight.protocol.sql.CommandStatementIngest.TableDefinitionOptions";
  readonly ifNotExist: CommandStatementIngest_TableDefinitionOptions_TableNotExistOption;
  readonly ifExists: CommandStatementIngest_TableDefinitionOptions_TableExistsOption;
}

/** The action to take if the target table does not exist */
export enum CommandStatementIngest_TableDefinitionOptions_TableNotExistOption {
  /** UNSPECIFIED - Do not use. Servers should error if this is specified by a client. */
  UNSPECIFIED = 0,
  /** CREATE - Create the table if it does not exist */
  CREATE = 1,
  /** FAIL - Fail if the table does not exist */
  FAIL = 2,
  UNRECOGNIZED = -1,
}

export function commandStatementIngest_TableDefinitionOptions_TableNotExistOptionFromJSON(
  object: any,
): CommandStatementIngest_TableDefinitionOptions_TableNotExistOption {
  switch (object) {
    case 0:
    case "TABLE_NOT_EXIST_OPTION_UNSPECIFIED":
      return CommandStatementIngest_TableDefinitionOptions_TableNotExistOption.UNSPECIFIED;
    case 1:
    case "TABLE_NOT_EXIST_OPTION_CREATE":
      return CommandStatementIngest_TableDefinitionOptions_TableNotExistOption.CREATE;
    case 2:
    case "TABLE_NOT_EXIST_OPTION_FAIL":
      return CommandStatementIngest_TableDefinitionOptions_TableNotExistOption.FAIL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CommandStatementIngest_TableDefinitionOptions_TableNotExistOption.UNRECOGNIZED;
  }
}

export function commandStatementIngest_TableDefinitionOptions_TableNotExistOptionToJSON(
  object: CommandStatementIngest_TableDefinitionOptions_TableNotExistOption,
): string {
  switch (object) {
    case CommandStatementIngest_TableDefinitionOptions_TableNotExistOption.UNSPECIFIED:
      return "TABLE_NOT_EXIST_OPTION_UNSPECIFIED";
    case CommandStatementIngest_TableDefinitionOptions_TableNotExistOption.CREATE:
      return "TABLE_NOT_EXIST_OPTION_CREATE";
    case CommandStatementIngest_TableDefinitionOptions_TableNotExistOption.FAIL:
      return "TABLE_NOT_EXIST_OPTION_FAIL";
    case CommandStatementIngest_TableDefinitionOptions_TableNotExistOption.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The action to take if the target table already exists */
export enum CommandStatementIngest_TableDefinitionOptions_TableExistsOption {
  /** UNSPECIFIED - Do not use. Servers should error if this is specified by a client. */
  UNSPECIFIED = 0,
  /** FAIL - Fail if the table already exists */
  FAIL = 1,
  /** APPEND - Append to the table if it already exists */
  APPEND = 2,
  /** REPLACE - Drop and recreate the table if it already exists */
  REPLACE = 3,
  UNRECOGNIZED = -1,
}

export function commandStatementIngest_TableDefinitionOptions_TableExistsOptionFromJSON(
  object: any,
): CommandStatementIngest_TableDefinitionOptions_TableExistsOption {
  switch (object) {
    case 0:
    case "TABLE_EXISTS_OPTION_UNSPECIFIED":
      return CommandStatementIngest_TableDefinitionOptions_TableExistsOption.UNSPECIFIED;
    case 1:
    case "TABLE_EXISTS_OPTION_FAIL":
      return CommandStatementIngest_TableDefinitionOptions_TableExistsOption.FAIL;
    case 2:
    case "TABLE_EXISTS_OPTION_APPEND":
      return CommandStatementIngest_TableDefinitionOptions_TableExistsOption.APPEND;
    case 3:
    case "TABLE_EXISTS_OPTION_REPLACE":
      return CommandStatementIngest_TableDefinitionOptions_TableExistsOption.REPLACE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CommandStatementIngest_TableDefinitionOptions_TableExistsOption.UNRECOGNIZED;
  }
}

export function commandStatementIngest_TableDefinitionOptions_TableExistsOptionToJSON(
  object: CommandStatementIngest_TableDefinitionOptions_TableExistsOption,
): string {
  switch (object) {
    case CommandStatementIngest_TableDefinitionOptions_TableExistsOption.UNSPECIFIED:
      return "TABLE_EXISTS_OPTION_UNSPECIFIED";
    case CommandStatementIngest_TableDefinitionOptions_TableExistsOption.FAIL:
      return "TABLE_EXISTS_OPTION_FAIL";
    case CommandStatementIngest_TableDefinitionOptions_TableExistsOption.APPEND:
      return "TABLE_EXISTS_OPTION_APPEND";
    case CommandStatementIngest_TableDefinitionOptions_TableExistsOption.REPLACE:
      return "TABLE_EXISTS_OPTION_REPLACE";
    case CommandStatementIngest_TableDefinitionOptions_TableExistsOption.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface CommandStatementIngest_OptionsEntry {
  $type: "arrow.flight.protocol.sql.CommandStatementIngest.OptionsEntry";
  readonly key: string;
  readonly value: string;
}

/**
 * Returned from the RPC call DoPut when a CommandStatementUpdate,
 * CommandPreparedStatementUpdate, or CommandStatementIngest was
 * in the request, containing results from the update.
 */
export interface DoPutUpdateResult {
  $type: "arrow.flight.protocol.sql.DoPutUpdateResult";
  /**
   * The number of records updated. A return value of -1 represents
   * an unknown updated record count.
   */
  readonly recordCount: bigint;
}

/**
 * An *optional* response returned when `DoPut` is called with `CommandPreparedStatementQuery`.
 *
 * *Note on legacy behavior*: previous versions of the protocol did not return any result for
 * this command, and that behavior should still be supported by clients. In that case, the client
 * can continue as though the fields in this message were not provided or set to sensible default values.
 */
export interface DoPutPreparedStatementResult {
  $type: "arrow.flight.protocol.sql.DoPutPreparedStatementResult";
  /**
   * Represents a (potentially updated) opaque handle for the prepared statement on the server.
   * Because the handle could potentially be updated, any previous handles for this prepared
   * statement should be considered invalid, and all subsequent requests for this prepared
   * statement must use this new handle.
   * The updated handle allows implementing query parameters with stateless services.
   *
   * When an updated handle is not provided by the server, clients should contiue
   * using the previous handle provided by `ActionCreatePreparedStatementResonse`.
   */
  readonly preparedStatementHandle?: Uint8Array | undefined;
}

/**
 * Request message for the "CancelQuery" action.
 *
 * Explicitly cancel a running query.
 *
 * This lets a single client explicitly cancel work, no matter how many clients
 * are involved/whether the query is distributed or not, given server support.
 * The transaction/statement is not rolled back; it is the application's job to
 * commit or rollback as appropriate. This only indicates the client no longer
 * wishes to read the remainder of the query results or continue submitting
 * data.
 *
 * This command is idempotent.
 *
 * This command is deprecated since 13.0.0. Use the "CancelFlightInfo"
 * action with DoAction instead.
 *
 * @deprecated
 */
export interface ActionCancelQueryRequest {
  $type: "arrow.flight.protocol.sql.ActionCancelQueryRequest";
  /**
   * The result of the GetFlightInfo RPC that initiated the query.
   * XXX(ARROW-16902): this must be a serialized FlightInfo, but is
   * rendered as bytes because Protobuf does not really support one
   * DLL using Protobuf definitions from another DLL.
   */
  readonly info: Uint8Array;
}

/**
 * The result of cancelling a query.
 *
 * The result should be wrapped in a google.protobuf.Any message.
 *
 * This command is deprecated since 13.0.0. Use the "CancelFlightInfo"
 * action with DoAction instead.
 *
 * @deprecated
 */
export interface ActionCancelQueryResult {
  $type: "arrow.flight.protocol.sql.ActionCancelQueryResult";
  readonly result: ActionCancelQueryResult_CancelResult;
}

export enum ActionCancelQueryResult_CancelResult {
  /**
   * UNSPECIFIED - The cancellation status is unknown. Servers should avoid using
   * this value (send a NOT_FOUND error if the requested query is
   * not known). Clients can retry the request.
   */
  UNSPECIFIED = 0,
  /**
   * CANCELLED - The cancellation request is complete. Subsequent requests with
   * the same payload may return CANCELLED or a NOT_FOUND error.
   */
  CANCELLED = 1,
  /**
   * CANCELLING - The cancellation request is in progress. The client may retry
   * the cancellation request.
   */
  CANCELLING = 2,
  /**
   * NOT_CANCELLABLE - The query is not cancellable. The client should not retry the
   * cancellation request.
   */
  NOT_CANCELLABLE = 3,
  UNRECOGNIZED = -1,
}

export function actionCancelQueryResult_CancelResultFromJSON(object: any): ActionCancelQueryResult_CancelResult {
  switch (object) {
    case 0:
    case "CANCEL_RESULT_UNSPECIFIED":
      return ActionCancelQueryResult_CancelResult.UNSPECIFIED;
    case 1:
    case "CANCEL_RESULT_CANCELLED":
      return ActionCancelQueryResult_CancelResult.CANCELLED;
    case 2:
    case "CANCEL_RESULT_CANCELLING":
      return ActionCancelQueryResult_CancelResult.CANCELLING;
    case 3:
    case "CANCEL_RESULT_NOT_CANCELLABLE":
      return ActionCancelQueryResult_CancelResult.NOT_CANCELLABLE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ActionCancelQueryResult_CancelResult.UNRECOGNIZED;
  }
}

export function actionCancelQueryResult_CancelResultToJSON(object: ActionCancelQueryResult_CancelResult): string {
  switch (object) {
    case ActionCancelQueryResult_CancelResult.UNSPECIFIED:
      return "CANCEL_RESULT_UNSPECIFIED";
    case ActionCancelQueryResult_CancelResult.CANCELLED:
      return "CANCEL_RESULT_CANCELLED";
    case ActionCancelQueryResult_CancelResult.CANCELLING:
      return "CANCEL_RESULT_CANCELLING";
    case ActionCancelQueryResult_CancelResult.NOT_CANCELLABLE:
      return "CANCEL_RESULT_NOT_CANCELLABLE";
    case ActionCancelQueryResult_CancelResult.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

function createBaseCommandGetSqlInfo(): CommandGetSqlInfo {
  return { $type: "arrow.flight.protocol.sql.CommandGetSqlInfo", info: [] };
}

export const CommandGetSqlInfo: MessageFns<CommandGetSqlInfo, "arrow.flight.protocol.sql.CommandGetSqlInfo"> = {
  $type: "arrow.flight.protocol.sql.CommandGetSqlInfo" as const,

  encode(message: CommandGetSqlInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    writer.uint32(10).fork();
    for (const v of message.info) {
      writer.uint32(v);
    }
    writer.join();
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommandGetSqlInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommandGetSqlInfo() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag === 8) {
            message.info.push(reader.uint32());

            continue;
          }

          if (tag === 10) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.info.push(reader.uint32());
            }

            continue;
          }

          break;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommandGetSqlInfo {
    return {
      $type: CommandGetSqlInfo.$type,
      info: globalThis.Array.isArray(object?.info) ? object.info.map((e: any) => globalThis.Number(e)) : [],
    };
  },

  toJSON(message: CommandGetSqlInfo): unknown {
    const obj: any = {};
    if (message.info?.length) {
      obj.info = message.info.map((e) => Math.round(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CommandGetSqlInfo>, I>>(base?: I): CommandGetSqlInfo {
    return CommandGetSqlInfo.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CommandGetSqlInfo>, I>>(object: I): CommandGetSqlInfo {
    const message = createBaseCommandGetSqlInfo() as any;
    message.info = object.info?.map((e) => e) || [];
    return message;
  },
};

messageTypeRegistry.set(CommandGetSqlInfo.$type, CommandGetSqlInfo);

function createBaseCommandGetXdbcTypeInfo(): CommandGetXdbcTypeInfo {
  return { $type: "arrow.flight.protocol.sql.CommandGetXdbcTypeInfo", dataType: undefined };
}

export const CommandGetXdbcTypeInfo: MessageFns<
  CommandGetXdbcTypeInfo,
  "arrow.flight.protocol.sql.CommandGetXdbcTypeInfo"
> = {
  $type: "arrow.flight.protocol.sql.CommandGetXdbcTypeInfo" as const,

  encode(message: CommandGetXdbcTypeInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dataType !== undefined) {
      writer.uint32(8).int32(message.dataType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommandGetXdbcTypeInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommandGetXdbcTypeInfo() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.dataType = reader.int32();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommandGetXdbcTypeInfo {
    return {
      $type: CommandGetXdbcTypeInfo.$type,
      dataType: isSet(object.dataType) ? globalThis.Number(object.dataType) : undefined,
    };
  },

  toJSON(message: CommandGetXdbcTypeInfo): unknown {
    const obj: any = {};
    if (message.dataType !== undefined) {
      obj.dataType = Math.round(message.dataType);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CommandGetXdbcTypeInfo>, I>>(base?: I): CommandGetXdbcTypeInfo {
    return CommandGetXdbcTypeInfo.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CommandGetXdbcTypeInfo>, I>>(object: I): CommandGetXdbcTypeInfo {
    const message = createBaseCommandGetXdbcTypeInfo() as any;
    message.dataType = object.dataType ?? undefined;
    return message;
  },
};

messageTypeRegistry.set(CommandGetXdbcTypeInfo.$type, CommandGetXdbcTypeInfo);

function createBaseCommandGetCatalogs(): CommandGetCatalogs {
  return { $type: "arrow.flight.protocol.sql.CommandGetCatalogs" };
}

export const CommandGetCatalogs: MessageFns<CommandGetCatalogs, "arrow.flight.protocol.sql.CommandGetCatalogs"> = {
  $type: "arrow.flight.protocol.sql.CommandGetCatalogs" as const,

  encode(_: CommandGetCatalogs, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommandGetCatalogs {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommandGetCatalogs() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): CommandGetCatalogs {
    return { $type: CommandGetCatalogs.$type };
  },

  toJSON(_: CommandGetCatalogs): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<CommandGetCatalogs>, I>>(base?: I): CommandGetCatalogs {
    return CommandGetCatalogs.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CommandGetCatalogs>, I>>(_: I): CommandGetCatalogs {
    const message = createBaseCommandGetCatalogs() as any;
    return message;
  },
};

messageTypeRegistry.set(CommandGetCatalogs.$type, CommandGetCatalogs);

function createBaseCommandGetDbSchemas(): CommandGetDbSchemas {
  return {
    $type: "arrow.flight.protocol.sql.CommandGetDbSchemas",
    catalog: undefined,
    dbSchemaFilterPattern: undefined,
  };
}

export const CommandGetDbSchemas: MessageFns<CommandGetDbSchemas, "arrow.flight.protocol.sql.CommandGetDbSchemas"> = {
  $type: "arrow.flight.protocol.sql.CommandGetDbSchemas" as const,

  encode(message: CommandGetDbSchemas, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.catalog !== undefined) {
      writer.uint32(10).string(message.catalog);
    }
    if (message.dbSchemaFilterPattern !== undefined) {
      writer.uint32(18).string(message.dbSchemaFilterPattern);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommandGetDbSchemas {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommandGetDbSchemas() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.catalog = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.dbSchemaFilterPattern = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommandGetDbSchemas {
    return {
      $type: CommandGetDbSchemas.$type,
      catalog: isSet(object.catalog) ? globalThis.String(object.catalog) : undefined,
      dbSchemaFilterPattern: isSet(object.dbSchemaFilterPattern)
        ? globalThis.String(object.dbSchemaFilterPattern)
        : undefined,
    };
  },

  toJSON(message: CommandGetDbSchemas): unknown {
    const obj: any = {};
    if (message.catalog !== undefined) {
      obj.catalog = message.catalog;
    }
    if (message.dbSchemaFilterPattern !== undefined) {
      obj.dbSchemaFilterPattern = message.dbSchemaFilterPattern;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CommandGetDbSchemas>, I>>(base?: I): CommandGetDbSchemas {
    return CommandGetDbSchemas.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CommandGetDbSchemas>, I>>(object: I): CommandGetDbSchemas {
    const message = createBaseCommandGetDbSchemas() as any;
    message.catalog = object.catalog ?? undefined;
    message.dbSchemaFilterPattern = object.dbSchemaFilterPattern ?? undefined;
    return message;
  },
};

messageTypeRegistry.set(CommandGetDbSchemas.$type, CommandGetDbSchemas);

function createBaseCommandGetTables(): CommandGetTables {
  return {
    $type: "arrow.flight.protocol.sql.CommandGetTables",
    catalog: undefined,
    dbSchemaFilterPattern: undefined,
    tableNameFilterPattern: undefined,
    tableTypes: [],
    includeSchema: false,
  };
}

export const CommandGetTables: MessageFns<CommandGetTables, "arrow.flight.protocol.sql.CommandGetTables"> = {
  $type: "arrow.flight.protocol.sql.CommandGetTables" as const,

  encode(message: CommandGetTables, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.catalog !== undefined) {
      writer.uint32(10).string(message.catalog);
    }
    if (message.dbSchemaFilterPattern !== undefined) {
      writer.uint32(18).string(message.dbSchemaFilterPattern);
    }
    if (message.tableNameFilterPattern !== undefined) {
      writer.uint32(26).string(message.tableNameFilterPattern);
    }
    for (const v of message.tableTypes) {
      writer.uint32(34).string(v!);
    }
    if (message.includeSchema !== false) {
      writer.uint32(40).bool(message.includeSchema);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommandGetTables {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommandGetTables() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.catalog = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.dbSchemaFilterPattern = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.tableNameFilterPattern = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.tableTypes.push(reader.string());
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.includeSchema = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommandGetTables {
    return {
      $type: CommandGetTables.$type,
      catalog: isSet(object.catalog) ? globalThis.String(object.catalog) : undefined,
      dbSchemaFilterPattern: isSet(object.dbSchemaFilterPattern)
        ? globalThis.String(object.dbSchemaFilterPattern)
        : undefined,
      tableNameFilterPattern: isSet(object.tableNameFilterPattern)
        ? globalThis.String(object.tableNameFilterPattern)
        : undefined,
      tableTypes: globalThis.Array.isArray(object?.tableTypes)
        ? object.tableTypes.map((e: any) => globalThis.String(e))
        : [],
      includeSchema: isSet(object.includeSchema) ? globalThis.Boolean(object.includeSchema) : false,
    };
  },

  toJSON(message: CommandGetTables): unknown {
    const obj: any = {};
    if (message.catalog !== undefined) {
      obj.catalog = message.catalog;
    }
    if (message.dbSchemaFilterPattern !== undefined) {
      obj.dbSchemaFilterPattern = message.dbSchemaFilterPattern;
    }
    if (message.tableNameFilterPattern !== undefined) {
      obj.tableNameFilterPattern = message.tableNameFilterPattern;
    }
    if (message.tableTypes?.length) {
      obj.tableTypes = message.tableTypes;
    }
    if (message.includeSchema !== false) {
      obj.includeSchema = message.includeSchema;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CommandGetTables>, I>>(base?: I): CommandGetTables {
    return CommandGetTables.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CommandGetTables>, I>>(object: I): CommandGetTables {
    const message = createBaseCommandGetTables() as any;
    message.catalog = object.catalog ?? undefined;
    message.dbSchemaFilterPattern = object.dbSchemaFilterPattern ?? undefined;
    message.tableNameFilterPattern = object.tableNameFilterPattern ?? undefined;
    message.tableTypes = object.tableTypes?.map((e) => e) || [];
    message.includeSchema = object.includeSchema ?? false;
    return message;
  },
};

messageTypeRegistry.set(CommandGetTables.$type, CommandGetTables);

function createBaseCommandGetTableTypes(): CommandGetTableTypes {
  return { $type: "arrow.flight.protocol.sql.CommandGetTableTypes" };
}

export const CommandGetTableTypes: MessageFns<CommandGetTableTypes, "arrow.flight.protocol.sql.CommandGetTableTypes"> =
  {
    $type: "arrow.flight.protocol.sql.CommandGetTableTypes" as const,

    encode(_: CommandGetTableTypes, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): CommandGetTableTypes {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseCommandGetTableTypes() as any;
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(_: any): CommandGetTableTypes {
      return { $type: CommandGetTableTypes.$type };
    },

    toJSON(_: CommandGetTableTypes): unknown {
      const obj: any = {};
      return obj;
    },

    create<I extends Exact<DeepPartial<CommandGetTableTypes>, I>>(base?: I): CommandGetTableTypes {
      return CommandGetTableTypes.fromPartial(base ?? ({} as any));
    },
    fromPartial<I extends Exact<DeepPartial<CommandGetTableTypes>, I>>(_: I): CommandGetTableTypes {
      const message = createBaseCommandGetTableTypes() as any;
      return message;
    },
  };

messageTypeRegistry.set(CommandGetTableTypes.$type, CommandGetTableTypes);

function createBaseCommandGetPrimaryKeys(): CommandGetPrimaryKeys {
  return {
    $type: "arrow.flight.protocol.sql.CommandGetPrimaryKeys",
    catalog: undefined,
    dbSchema: undefined,
    table: "",
  };
}

export const CommandGetPrimaryKeys: MessageFns<
  CommandGetPrimaryKeys,
  "arrow.flight.protocol.sql.CommandGetPrimaryKeys"
> = {
  $type: "arrow.flight.protocol.sql.CommandGetPrimaryKeys" as const,

  encode(message: CommandGetPrimaryKeys, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.catalog !== undefined) {
      writer.uint32(10).string(message.catalog);
    }
    if (message.dbSchema !== undefined) {
      writer.uint32(18).string(message.dbSchema);
    }
    if (message.table !== "") {
      writer.uint32(26).string(message.table);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommandGetPrimaryKeys {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommandGetPrimaryKeys() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.catalog = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.dbSchema = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.table = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommandGetPrimaryKeys {
    return {
      $type: CommandGetPrimaryKeys.$type,
      catalog: isSet(object.catalog) ? globalThis.String(object.catalog) : undefined,
      dbSchema: isSet(object.dbSchema) ? globalThis.String(object.dbSchema) : undefined,
      table: isSet(object.table) ? globalThis.String(object.table) : "",
    };
  },

  toJSON(message: CommandGetPrimaryKeys): unknown {
    const obj: any = {};
    if (message.catalog !== undefined) {
      obj.catalog = message.catalog;
    }
    if (message.dbSchema !== undefined) {
      obj.dbSchema = message.dbSchema;
    }
    if (message.table !== "") {
      obj.table = message.table;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CommandGetPrimaryKeys>, I>>(base?: I): CommandGetPrimaryKeys {
    return CommandGetPrimaryKeys.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CommandGetPrimaryKeys>, I>>(object: I): CommandGetPrimaryKeys {
    const message = createBaseCommandGetPrimaryKeys() as any;
    message.catalog = object.catalog ?? undefined;
    message.dbSchema = object.dbSchema ?? undefined;
    message.table = object.table ?? "";
    return message;
  },
};

messageTypeRegistry.set(CommandGetPrimaryKeys.$type, CommandGetPrimaryKeys);

function createBaseCommandGetExportedKeys(): CommandGetExportedKeys {
  return {
    $type: "arrow.flight.protocol.sql.CommandGetExportedKeys",
    catalog: undefined,
    dbSchema: undefined,
    table: "",
  };
}

export const CommandGetExportedKeys: MessageFns<
  CommandGetExportedKeys,
  "arrow.flight.protocol.sql.CommandGetExportedKeys"
> = {
  $type: "arrow.flight.protocol.sql.CommandGetExportedKeys" as const,

  encode(message: CommandGetExportedKeys, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.catalog !== undefined) {
      writer.uint32(10).string(message.catalog);
    }
    if (message.dbSchema !== undefined) {
      writer.uint32(18).string(message.dbSchema);
    }
    if (message.table !== "") {
      writer.uint32(26).string(message.table);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommandGetExportedKeys {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommandGetExportedKeys() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.catalog = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.dbSchema = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.table = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommandGetExportedKeys {
    return {
      $type: CommandGetExportedKeys.$type,
      catalog: isSet(object.catalog) ? globalThis.String(object.catalog) : undefined,
      dbSchema: isSet(object.dbSchema) ? globalThis.String(object.dbSchema) : undefined,
      table: isSet(object.table) ? globalThis.String(object.table) : "",
    };
  },

  toJSON(message: CommandGetExportedKeys): unknown {
    const obj: any = {};
    if (message.catalog !== undefined) {
      obj.catalog = message.catalog;
    }
    if (message.dbSchema !== undefined) {
      obj.dbSchema = message.dbSchema;
    }
    if (message.table !== "") {
      obj.table = message.table;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CommandGetExportedKeys>, I>>(base?: I): CommandGetExportedKeys {
    return CommandGetExportedKeys.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CommandGetExportedKeys>, I>>(object: I): CommandGetExportedKeys {
    const message = createBaseCommandGetExportedKeys() as any;
    message.catalog = object.catalog ?? undefined;
    message.dbSchema = object.dbSchema ?? undefined;
    message.table = object.table ?? "";
    return message;
  },
};

messageTypeRegistry.set(CommandGetExportedKeys.$type, CommandGetExportedKeys);

function createBaseCommandGetImportedKeys(): CommandGetImportedKeys {
  return {
    $type: "arrow.flight.protocol.sql.CommandGetImportedKeys",
    catalog: undefined,
    dbSchema: undefined,
    table: "",
  };
}

export const CommandGetImportedKeys: MessageFns<
  CommandGetImportedKeys,
  "arrow.flight.protocol.sql.CommandGetImportedKeys"
> = {
  $type: "arrow.flight.protocol.sql.CommandGetImportedKeys" as const,

  encode(message: CommandGetImportedKeys, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.catalog !== undefined) {
      writer.uint32(10).string(message.catalog);
    }
    if (message.dbSchema !== undefined) {
      writer.uint32(18).string(message.dbSchema);
    }
    if (message.table !== "") {
      writer.uint32(26).string(message.table);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommandGetImportedKeys {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommandGetImportedKeys() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.catalog = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.dbSchema = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.table = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommandGetImportedKeys {
    return {
      $type: CommandGetImportedKeys.$type,
      catalog: isSet(object.catalog) ? globalThis.String(object.catalog) : undefined,
      dbSchema: isSet(object.dbSchema) ? globalThis.String(object.dbSchema) : undefined,
      table: isSet(object.table) ? globalThis.String(object.table) : "",
    };
  },

  toJSON(message: CommandGetImportedKeys): unknown {
    const obj: any = {};
    if (message.catalog !== undefined) {
      obj.catalog = message.catalog;
    }
    if (message.dbSchema !== undefined) {
      obj.dbSchema = message.dbSchema;
    }
    if (message.table !== "") {
      obj.table = message.table;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CommandGetImportedKeys>, I>>(base?: I): CommandGetImportedKeys {
    return CommandGetImportedKeys.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CommandGetImportedKeys>, I>>(object: I): CommandGetImportedKeys {
    const message = createBaseCommandGetImportedKeys() as any;
    message.catalog = object.catalog ?? undefined;
    message.dbSchema = object.dbSchema ?? undefined;
    message.table = object.table ?? "";
    return message;
  },
};

messageTypeRegistry.set(CommandGetImportedKeys.$type, CommandGetImportedKeys);

function createBaseCommandGetCrossReference(): CommandGetCrossReference {
  return {
    $type: "arrow.flight.protocol.sql.CommandGetCrossReference",
    pkCatalog: undefined,
    pkDbSchema: undefined,
    pkTable: "",
    fkCatalog: undefined,
    fkDbSchema: undefined,
    fkTable: "",
  };
}

export const CommandGetCrossReference: MessageFns<
  CommandGetCrossReference,
  "arrow.flight.protocol.sql.CommandGetCrossReference"
> = {
  $type: "arrow.flight.protocol.sql.CommandGetCrossReference" as const,

  encode(message: CommandGetCrossReference, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.pkCatalog !== undefined) {
      writer.uint32(10).string(message.pkCatalog);
    }
    if (message.pkDbSchema !== undefined) {
      writer.uint32(18).string(message.pkDbSchema);
    }
    if (message.pkTable !== "") {
      writer.uint32(26).string(message.pkTable);
    }
    if (message.fkCatalog !== undefined) {
      writer.uint32(34).string(message.fkCatalog);
    }
    if (message.fkDbSchema !== undefined) {
      writer.uint32(42).string(message.fkDbSchema);
    }
    if (message.fkTable !== "") {
      writer.uint32(50).string(message.fkTable);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommandGetCrossReference {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommandGetCrossReference() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.pkCatalog = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.pkDbSchema = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.pkTable = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.fkCatalog = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.fkDbSchema = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.fkTable = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommandGetCrossReference {
    return {
      $type: CommandGetCrossReference.$type,
      pkCatalog: isSet(object.pkCatalog) ? globalThis.String(object.pkCatalog) : undefined,
      pkDbSchema: isSet(object.pkDbSchema) ? globalThis.String(object.pkDbSchema) : undefined,
      pkTable: isSet(object.pkTable) ? globalThis.String(object.pkTable) : "",
      fkCatalog: isSet(object.fkCatalog) ? globalThis.String(object.fkCatalog) : undefined,
      fkDbSchema: isSet(object.fkDbSchema) ? globalThis.String(object.fkDbSchema) : undefined,
      fkTable: isSet(object.fkTable) ? globalThis.String(object.fkTable) : "",
    };
  },

  toJSON(message: CommandGetCrossReference): unknown {
    const obj: any = {};
    if (message.pkCatalog !== undefined) {
      obj.pkCatalog = message.pkCatalog;
    }
    if (message.pkDbSchema !== undefined) {
      obj.pkDbSchema = message.pkDbSchema;
    }
    if (message.pkTable !== "") {
      obj.pkTable = message.pkTable;
    }
    if (message.fkCatalog !== undefined) {
      obj.fkCatalog = message.fkCatalog;
    }
    if (message.fkDbSchema !== undefined) {
      obj.fkDbSchema = message.fkDbSchema;
    }
    if (message.fkTable !== "") {
      obj.fkTable = message.fkTable;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CommandGetCrossReference>, I>>(base?: I): CommandGetCrossReference {
    return CommandGetCrossReference.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CommandGetCrossReference>, I>>(object: I): CommandGetCrossReference {
    const message = createBaseCommandGetCrossReference() as any;
    message.pkCatalog = object.pkCatalog ?? undefined;
    message.pkDbSchema = object.pkDbSchema ?? undefined;
    message.pkTable = object.pkTable ?? "";
    message.fkCatalog = object.fkCatalog ?? undefined;
    message.fkDbSchema = object.fkDbSchema ?? undefined;
    message.fkTable = object.fkTable ?? "";
    return message;
  },
};

messageTypeRegistry.set(CommandGetCrossReference.$type, CommandGetCrossReference);

function createBaseActionCreatePreparedStatementRequest(): ActionCreatePreparedStatementRequest {
  return {
    $type: "arrow.flight.protocol.sql.ActionCreatePreparedStatementRequest",
    query: "",
    transactionId: undefined,
  };
}

export const ActionCreatePreparedStatementRequest: MessageFns<
  ActionCreatePreparedStatementRequest,
  "arrow.flight.protocol.sql.ActionCreatePreparedStatementRequest"
> = {
  $type: "arrow.flight.protocol.sql.ActionCreatePreparedStatementRequest" as const,

  encode(message: ActionCreatePreparedStatementRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.query !== "") {
      writer.uint32(10).string(message.query);
    }
    if (message.transactionId !== undefined) {
      writer.uint32(18).bytes(message.transactionId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ActionCreatePreparedStatementRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseActionCreatePreparedStatementRequest() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.query = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.transactionId = reader.bytes();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ActionCreatePreparedStatementRequest {
    return {
      $type: ActionCreatePreparedStatementRequest.$type,
      query: isSet(object.query) ? globalThis.String(object.query) : "",
      transactionId: isSet(object.transactionId) ? bytesFromBase64(object.transactionId) : undefined,
    };
  },

  toJSON(message: ActionCreatePreparedStatementRequest): unknown {
    const obj: any = {};
    if (message.query !== "") {
      obj.query = message.query;
    }
    if (message.transactionId !== undefined) {
      obj.transactionId = base64FromBytes(message.transactionId);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ActionCreatePreparedStatementRequest>, I>>(
    base?: I,
  ): ActionCreatePreparedStatementRequest {
    return ActionCreatePreparedStatementRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ActionCreatePreparedStatementRequest>, I>>(
    object: I,
  ): ActionCreatePreparedStatementRequest {
    const message = createBaseActionCreatePreparedStatementRequest() as any;
    message.query = object.query ?? "";
    message.transactionId = object.transactionId ?? undefined;
    return message;
  },
};

messageTypeRegistry.set(ActionCreatePreparedStatementRequest.$type, ActionCreatePreparedStatementRequest);

function createBaseSubstraitPlan(): SubstraitPlan {
  return { $type: "arrow.flight.protocol.sql.SubstraitPlan", plan: new Uint8Array(0), version: "" };
}

export const SubstraitPlan: MessageFns<SubstraitPlan, "arrow.flight.protocol.sql.SubstraitPlan"> = {
  $type: "arrow.flight.protocol.sql.SubstraitPlan" as const,

  encode(message: SubstraitPlan, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.plan.length !== 0) {
      writer.uint32(10).bytes(message.plan);
    }
    if (message.version !== "") {
      writer.uint32(18).string(message.version);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SubstraitPlan {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSubstraitPlan() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.plan = reader.bytes();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.version = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SubstraitPlan {
    return {
      $type: SubstraitPlan.$type,
      plan: isSet(object.plan) ? bytesFromBase64(object.plan) : new Uint8Array(0),
      version: isSet(object.version) ? globalThis.String(object.version) : "",
    };
  },

  toJSON(message: SubstraitPlan): unknown {
    const obj: any = {};
    if (message.plan.length !== 0) {
      obj.plan = base64FromBytes(message.plan);
    }
    if (message.version !== "") {
      obj.version = message.version;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<SubstraitPlan>, I>>(base?: I): SubstraitPlan {
    return SubstraitPlan.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<SubstraitPlan>, I>>(object: I): SubstraitPlan {
    const message = createBaseSubstraitPlan() as any;
    message.plan = object.plan ?? new Uint8Array(0);
    message.version = object.version ?? "";
    return message;
  },
};

messageTypeRegistry.set(SubstraitPlan.$type, SubstraitPlan);

function createBaseActionCreatePreparedSubstraitPlanRequest(): ActionCreatePreparedSubstraitPlanRequest {
  return {
    $type: "arrow.flight.protocol.sql.ActionCreatePreparedSubstraitPlanRequest",
    plan: undefined,
    transactionId: undefined,
  };
}

export const ActionCreatePreparedSubstraitPlanRequest: MessageFns<
  ActionCreatePreparedSubstraitPlanRequest,
  "arrow.flight.protocol.sql.ActionCreatePreparedSubstraitPlanRequest"
> = {
  $type: "arrow.flight.protocol.sql.ActionCreatePreparedSubstraitPlanRequest" as const,

  encode(message: ActionCreatePreparedSubstraitPlanRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.plan !== undefined) {
      SubstraitPlan.encode(message.plan, writer.uint32(10).fork()).join();
    }
    if (message.transactionId !== undefined) {
      writer.uint32(18).bytes(message.transactionId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ActionCreatePreparedSubstraitPlanRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseActionCreatePreparedSubstraitPlanRequest() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.plan = SubstraitPlan.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.transactionId = reader.bytes();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ActionCreatePreparedSubstraitPlanRequest {
    return {
      $type: ActionCreatePreparedSubstraitPlanRequest.$type,
      plan: isSet(object.plan) ? SubstraitPlan.fromJSON(object.plan) : undefined,
      transactionId: isSet(object.transactionId) ? bytesFromBase64(object.transactionId) : undefined,
    };
  },

  toJSON(message: ActionCreatePreparedSubstraitPlanRequest): unknown {
    const obj: any = {};
    if (message.plan !== undefined) {
      obj.plan = SubstraitPlan.toJSON(message.plan);
    }
    if (message.transactionId !== undefined) {
      obj.transactionId = base64FromBytes(message.transactionId);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ActionCreatePreparedSubstraitPlanRequest>, I>>(
    base?: I,
  ): ActionCreatePreparedSubstraitPlanRequest {
    return ActionCreatePreparedSubstraitPlanRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ActionCreatePreparedSubstraitPlanRequest>, I>>(
    object: I,
  ): ActionCreatePreparedSubstraitPlanRequest {
    const message = createBaseActionCreatePreparedSubstraitPlanRequest() as any;
    message.plan = (object.plan !== undefined && object.plan !== null)
      ? SubstraitPlan.fromPartial(object.plan)
      : undefined;
    message.transactionId = object.transactionId ?? undefined;
    return message;
  },
};

messageTypeRegistry.set(ActionCreatePreparedSubstraitPlanRequest.$type, ActionCreatePreparedSubstraitPlanRequest);

function createBaseActionCreatePreparedStatementResult(): ActionCreatePreparedStatementResult {
  return {
    $type: "arrow.flight.protocol.sql.ActionCreatePreparedStatementResult",
    preparedStatementHandle: new Uint8Array(0),
    datasetSchema: new Uint8Array(0),
    parameterSchema: new Uint8Array(0),
  };
}

export const ActionCreatePreparedStatementResult: MessageFns<
  ActionCreatePreparedStatementResult,
  "arrow.flight.protocol.sql.ActionCreatePreparedStatementResult"
> = {
  $type: "arrow.flight.protocol.sql.ActionCreatePreparedStatementResult" as const,

  encode(message: ActionCreatePreparedStatementResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.preparedStatementHandle.length !== 0) {
      writer.uint32(10).bytes(message.preparedStatementHandle);
    }
    if (message.datasetSchema.length !== 0) {
      writer.uint32(18).bytes(message.datasetSchema);
    }
    if (message.parameterSchema.length !== 0) {
      writer.uint32(26).bytes(message.parameterSchema);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ActionCreatePreparedStatementResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseActionCreatePreparedStatementResult() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.preparedStatementHandle = reader.bytes();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.datasetSchema = reader.bytes();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.parameterSchema = reader.bytes();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ActionCreatePreparedStatementResult {
    return {
      $type: ActionCreatePreparedStatementResult.$type,
      preparedStatementHandle: isSet(object.preparedStatementHandle)
        ? bytesFromBase64(object.preparedStatementHandle)
        : new Uint8Array(0),
      datasetSchema: isSet(object.datasetSchema) ? bytesFromBase64(object.datasetSchema) : new Uint8Array(0),
      parameterSchema: isSet(object.parameterSchema) ? bytesFromBase64(object.parameterSchema) : new Uint8Array(0),
    };
  },

  toJSON(message: ActionCreatePreparedStatementResult): unknown {
    const obj: any = {};
    if (message.preparedStatementHandle.length !== 0) {
      obj.preparedStatementHandle = base64FromBytes(message.preparedStatementHandle);
    }
    if (message.datasetSchema.length !== 0) {
      obj.datasetSchema = base64FromBytes(message.datasetSchema);
    }
    if (message.parameterSchema.length !== 0) {
      obj.parameterSchema = base64FromBytes(message.parameterSchema);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ActionCreatePreparedStatementResult>, I>>(
    base?: I,
  ): ActionCreatePreparedStatementResult {
    return ActionCreatePreparedStatementResult.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ActionCreatePreparedStatementResult>, I>>(
    object: I,
  ): ActionCreatePreparedStatementResult {
    const message = createBaseActionCreatePreparedStatementResult() as any;
    message.preparedStatementHandle = object.preparedStatementHandle ?? new Uint8Array(0);
    message.datasetSchema = object.datasetSchema ?? new Uint8Array(0);
    message.parameterSchema = object.parameterSchema ?? new Uint8Array(0);
    return message;
  },
};

messageTypeRegistry.set(ActionCreatePreparedStatementResult.$type, ActionCreatePreparedStatementResult);

function createBaseActionClosePreparedStatementRequest(): ActionClosePreparedStatementRequest {
  return {
    $type: "arrow.flight.protocol.sql.ActionClosePreparedStatementRequest",
    preparedStatementHandle: new Uint8Array(0),
  };
}

export const ActionClosePreparedStatementRequest: MessageFns<
  ActionClosePreparedStatementRequest,
  "arrow.flight.protocol.sql.ActionClosePreparedStatementRequest"
> = {
  $type: "arrow.flight.protocol.sql.ActionClosePreparedStatementRequest" as const,

  encode(message: ActionClosePreparedStatementRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.preparedStatementHandle.length !== 0) {
      writer.uint32(10).bytes(message.preparedStatementHandle);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ActionClosePreparedStatementRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseActionClosePreparedStatementRequest() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.preparedStatementHandle = reader.bytes();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ActionClosePreparedStatementRequest {
    return {
      $type: ActionClosePreparedStatementRequest.$type,
      preparedStatementHandle: isSet(object.preparedStatementHandle)
        ? bytesFromBase64(object.preparedStatementHandle)
        : new Uint8Array(0),
    };
  },

  toJSON(message: ActionClosePreparedStatementRequest): unknown {
    const obj: any = {};
    if (message.preparedStatementHandle.length !== 0) {
      obj.preparedStatementHandle = base64FromBytes(message.preparedStatementHandle);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ActionClosePreparedStatementRequest>, I>>(
    base?: I,
  ): ActionClosePreparedStatementRequest {
    return ActionClosePreparedStatementRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ActionClosePreparedStatementRequest>, I>>(
    object: I,
  ): ActionClosePreparedStatementRequest {
    const message = createBaseActionClosePreparedStatementRequest() as any;
    message.preparedStatementHandle = object.preparedStatementHandle ?? new Uint8Array(0);
    return message;
  },
};

messageTypeRegistry.set(ActionClosePreparedStatementRequest.$type, ActionClosePreparedStatementRequest);

function createBaseActionBeginTransactionRequest(): ActionBeginTransactionRequest {
  return { $type: "arrow.flight.protocol.sql.ActionBeginTransactionRequest" };
}

export const ActionBeginTransactionRequest: MessageFns<
  ActionBeginTransactionRequest,
  "arrow.flight.protocol.sql.ActionBeginTransactionRequest"
> = {
  $type: "arrow.flight.protocol.sql.ActionBeginTransactionRequest" as const,

  encode(_: ActionBeginTransactionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ActionBeginTransactionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseActionBeginTransactionRequest() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): ActionBeginTransactionRequest {
    return { $type: ActionBeginTransactionRequest.$type };
  },

  toJSON(_: ActionBeginTransactionRequest): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<ActionBeginTransactionRequest>, I>>(base?: I): ActionBeginTransactionRequest {
    return ActionBeginTransactionRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ActionBeginTransactionRequest>, I>>(_: I): ActionBeginTransactionRequest {
    const message = createBaseActionBeginTransactionRequest() as any;
    return message;
  },
};

messageTypeRegistry.set(ActionBeginTransactionRequest.$type, ActionBeginTransactionRequest);

function createBaseActionBeginSavepointRequest(): ActionBeginSavepointRequest {
  return { $type: "arrow.flight.protocol.sql.ActionBeginSavepointRequest", transactionId: new Uint8Array(0), name: "" };
}

export const ActionBeginSavepointRequest: MessageFns<
  ActionBeginSavepointRequest,
  "arrow.flight.protocol.sql.ActionBeginSavepointRequest"
> = {
  $type: "arrow.flight.protocol.sql.ActionBeginSavepointRequest" as const,

  encode(message: ActionBeginSavepointRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.transactionId.length !== 0) {
      writer.uint32(10).bytes(message.transactionId);
    }
    if (message.name !== "") {
      writer.uint32(18).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ActionBeginSavepointRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseActionBeginSavepointRequest() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.transactionId = reader.bytes();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.name = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ActionBeginSavepointRequest {
    return {
      $type: ActionBeginSavepointRequest.$type,
      transactionId: isSet(object.transactionId) ? bytesFromBase64(object.transactionId) : new Uint8Array(0),
      name: isSet(object.name) ? globalThis.String(object.name) : "",
    };
  },

  toJSON(message: ActionBeginSavepointRequest): unknown {
    const obj: any = {};
    if (message.transactionId.length !== 0) {
      obj.transactionId = base64FromBytes(message.transactionId);
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ActionBeginSavepointRequest>, I>>(base?: I): ActionBeginSavepointRequest {
    return ActionBeginSavepointRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ActionBeginSavepointRequest>, I>>(object: I): ActionBeginSavepointRequest {
    const message = createBaseActionBeginSavepointRequest() as any;
    message.transactionId = object.transactionId ?? new Uint8Array(0);
    message.name = object.name ?? "";
    return message;
  },
};

messageTypeRegistry.set(ActionBeginSavepointRequest.$type, ActionBeginSavepointRequest);

function createBaseActionBeginTransactionResult(): ActionBeginTransactionResult {
  return { $type: "arrow.flight.protocol.sql.ActionBeginTransactionResult", transactionId: new Uint8Array(0) };
}

export const ActionBeginTransactionResult: MessageFns<
  ActionBeginTransactionResult,
  "arrow.flight.protocol.sql.ActionBeginTransactionResult"
> = {
  $type: "arrow.flight.protocol.sql.ActionBeginTransactionResult" as const,

  encode(message: ActionBeginTransactionResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.transactionId.length !== 0) {
      writer.uint32(10).bytes(message.transactionId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ActionBeginTransactionResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseActionBeginTransactionResult() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.transactionId = reader.bytes();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ActionBeginTransactionResult {
    return {
      $type: ActionBeginTransactionResult.$type,
      transactionId: isSet(object.transactionId) ? bytesFromBase64(object.transactionId) : new Uint8Array(0),
    };
  },

  toJSON(message: ActionBeginTransactionResult): unknown {
    const obj: any = {};
    if (message.transactionId.length !== 0) {
      obj.transactionId = base64FromBytes(message.transactionId);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ActionBeginTransactionResult>, I>>(base?: I): ActionBeginTransactionResult {
    return ActionBeginTransactionResult.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ActionBeginTransactionResult>, I>>(object: I): ActionBeginTransactionResult {
    const message = createBaseActionBeginTransactionResult() as any;
    message.transactionId = object.transactionId ?? new Uint8Array(0);
    return message;
  },
};

messageTypeRegistry.set(ActionBeginTransactionResult.$type, ActionBeginTransactionResult);

function createBaseActionBeginSavepointResult(): ActionBeginSavepointResult {
  return { $type: "arrow.flight.protocol.sql.ActionBeginSavepointResult", savepointId: new Uint8Array(0) };
}

export const ActionBeginSavepointResult: MessageFns<
  ActionBeginSavepointResult,
  "arrow.flight.protocol.sql.ActionBeginSavepointResult"
> = {
  $type: "arrow.flight.protocol.sql.ActionBeginSavepointResult" as const,

  encode(message: ActionBeginSavepointResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.savepointId.length !== 0) {
      writer.uint32(10).bytes(message.savepointId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ActionBeginSavepointResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseActionBeginSavepointResult() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.savepointId = reader.bytes();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ActionBeginSavepointResult {
    return {
      $type: ActionBeginSavepointResult.$type,
      savepointId: isSet(object.savepointId) ? bytesFromBase64(object.savepointId) : new Uint8Array(0),
    };
  },

  toJSON(message: ActionBeginSavepointResult): unknown {
    const obj: any = {};
    if (message.savepointId.length !== 0) {
      obj.savepointId = base64FromBytes(message.savepointId);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ActionBeginSavepointResult>, I>>(base?: I): ActionBeginSavepointResult {
    return ActionBeginSavepointResult.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ActionBeginSavepointResult>, I>>(object: I): ActionBeginSavepointResult {
    const message = createBaseActionBeginSavepointResult() as any;
    message.savepointId = object.savepointId ?? new Uint8Array(0);
    return message;
  },
};

messageTypeRegistry.set(ActionBeginSavepointResult.$type, ActionBeginSavepointResult);

function createBaseActionEndTransactionRequest(): ActionEndTransactionRequest {
  return {
    $type: "arrow.flight.protocol.sql.ActionEndTransactionRequest",
    transactionId: new Uint8Array(0),
    action: 0,
  };
}

export const ActionEndTransactionRequest: MessageFns<
  ActionEndTransactionRequest,
  "arrow.flight.protocol.sql.ActionEndTransactionRequest"
> = {
  $type: "arrow.flight.protocol.sql.ActionEndTransactionRequest" as const,

  encode(message: ActionEndTransactionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.transactionId.length !== 0) {
      writer.uint32(10).bytes(message.transactionId);
    }
    if (message.action !== 0) {
      writer.uint32(16).int32(message.action);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ActionEndTransactionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseActionEndTransactionRequest() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.transactionId = reader.bytes();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.action = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ActionEndTransactionRequest {
    return {
      $type: ActionEndTransactionRequest.$type,
      transactionId: isSet(object.transactionId) ? bytesFromBase64(object.transactionId) : new Uint8Array(0),
      action: isSet(object.action) ? actionEndTransactionRequest_EndTransactionFromJSON(object.action) : 0,
    };
  },

  toJSON(message: ActionEndTransactionRequest): unknown {
    const obj: any = {};
    if (message.transactionId.length !== 0) {
      obj.transactionId = base64FromBytes(message.transactionId);
    }
    if (message.action !== 0) {
      obj.action = actionEndTransactionRequest_EndTransactionToJSON(message.action);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ActionEndTransactionRequest>, I>>(base?: I): ActionEndTransactionRequest {
    return ActionEndTransactionRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ActionEndTransactionRequest>, I>>(object: I): ActionEndTransactionRequest {
    const message = createBaseActionEndTransactionRequest() as any;
    message.transactionId = object.transactionId ?? new Uint8Array(0);
    message.action = object.action ?? 0;
    return message;
  },
};

messageTypeRegistry.set(ActionEndTransactionRequest.$type, ActionEndTransactionRequest);

function createBaseActionEndSavepointRequest(): ActionEndSavepointRequest {
  return { $type: "arrow.flight.protocol.sql.ActionEndSavepointRequest", savepointId: new Uint8Array(0), action: 0 };
}

export const ActionEndSavepointRequest: MessageFns<
  ActionEndSavepointRequest,
  "arrow.flight.protocol.sql.ActionEndSavepointRequest"
> = {
  $type: "arrow.flight.protocol.sql.ActionEndSavepointRequest" as const,

  encode(message: ActionEndSavepointRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.savepointId.length !== 0) {
      writer.uint32(10).bytes(message.savepointId);
    }
    if (message.action !== 0) {
      writer.uint32(16).int32(message.action);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ActionEndSavepointRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseActionEndSavepointRequest() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.savepointId = reader.bytes();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.action = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ActionEndSavepointRequest {
    return {
      $type: ActionEndSavepointRequest.$type,
      savepointId: isSet(object.savepointId) ? bytesFromBase64(object.savepointId) : new Uint8Array(0),
      action: isSet(object.action) ? actionEndSavepointRequest_EndSavepointFromJSON(object.action) : 0,
    };
  },

  toJSON(message: ActionEndSavepointRequest): unknown {
    const obj: any = {};
    if (message.savepointId.length !== 0) {
      obj.savepointId = base64FromBytes(message.savepointId);
    }
    if (message.action !== 0) {
      obj.action = actionEndSavepointRequest_EndSavepointToJSON(message.action);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ActionEndSavepointRequest>, I>>(base?: I): ActionEndSavepointRequest {
    return ActionEndSavepointRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ActionEndSavepointRequest>, I>>(object: I): ActionEndSavepointRequest {
    const message = createBaseActionEndSavepointRequest() as any;
    message.savepointId = object.savepointId ?? new Uint8Array(0);
    message.action = object.action ?? 0;
    return message;
  },
};

messageTypeRegistry.set(ActionEndSavepointRequest.$type, ActionEndSavepointRequest);

function createBaseCommandStatementQuery(): CommandStatementQuery {
  return { $type: "arrow.flight.protocol.sql.CommandStatementQuery", query: "", transactionId: undefined };
}

export const CommandStatementQuery: MessageFns<
  CommandStatementQuery,
  "arrow.flight.protocol.sql.CommandStatementQuery"
> = {
  $type: "arrow.flight.protocol.sql.CommandStatementQuery" as const,

  encode(message: CommandStatementQuery, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.query !== "") {
      writer.uint32(10).string(message.query);
    }
    if (message.transactionId !== undefined) {
      writer.uint32(18).bytes(message.transactionId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommandStatementQuery {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommandStatementQuery() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.query = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.transactionId = reader.bytes();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommandStatementQuery {
    return {
      $type: CommandStatementQuery.$type,
      query: isSet(object.query) ? globalThis.String(object.query) : "",
      transactionId: isSet(object.transactionId) ? bytesFromBase64(object.transactionId) : undefined,
    };
  },

  toJSON(message: CommandStatementQuery): unknown {
    const obj: any = {};
    if (message.query !== "") {
      obj.query = message.query;
    }
    if (message.transactionId !== undefined) {
      obj.transactionId = base64FromBytes(message.transactionId);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CommandStatementQuery>, I>>(base?: I): CommandStatementQuery {
    return CommandStatementQuery.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CommandStatementQuery>, I>>(object: I): CommandStatementQuery {
    const message = createBaseCommandStatementQuery() as any;
    message.query = object.query ?? "";
    message.transactionId = object.transactionId ?? undefined;
    return message;
  },
};

messageTypeRegistry.set(CommandStatementQuery.$type, CommandStatementQuery);

function createBaseCommandStatementSubstraitPlan(): CommandStatementSubstraitPlan {
  return {
    $type: "arrow.flight.protocol.sql.CommandStatementSubstraitPlan",
    plan: undefined,
    transactionId: undefined,
  };
}

export const CommandStatementSubstraitPlan: MessageFns<
  CommandStatementSubstraitPlan,
  "arrow.flight.protocol.sql.CommandStatementSubstraitPlan"
> = {
  $type: "arrow.flight.protocol.sql.CommandStatementSubstraitPlan" as const,

  encode(message: CommandStatementSubstraitPlan, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.plan !== undefined) {
      SubstraitPlan.encode(message.plan, writer.uint32(10).fork()).join();
    }
    if (message.transactionId !== undefined) {
      writer.uint32(18).bytes(message.transactionId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommandStatementSubstraitPlan {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommandStatementSubstraitPlan() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.plan = SubstraitPlan.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.transactionId = reader.bytes();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommandStatementSubstraitPlan {
    return {
      $type: CommandStatementSubstraitPlan.$type,
      plan: isSet(object.plan) ? SubstraitPlan.fromJSON(object.plan) : undefined,
      transactionId: isSet(object.transactionId) ? bytesFromBase64(object.transactionId) : undefined,
    };
  },

  toJSON(message: CommandStatementSubstraitPlan): unknown {
    const obj: any = {};
    if (message.plan !== undefined) {
      obj.plan = SubstraitPlan.toJSON(message.plan);
    }
    if (message.transactionId !== undefined) {
      obj.transactionId = base64FromBytes(message.transactionId);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CommandStatementSubstraitPlan>, I>>(base?: I): CommandStatementSubstraitPlan {
    return CommandStatementSubstraitPlan.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CommandStatementSubstraitPlan>, I>>(
    object: I,
  ): CommandStatementSubstraitPlan {
    const message = createBaseCommandStatementSubstraitPlan() as any;
    message.plan = (object.plan !== undefined && object.plan !== null)
      ? SubstraitPlan.fromPartial(object.plan)
      : undefined;
    message.transactionId = object.transactionId ?? undefined;
    return message;
  },
};

messageTypeRegistry.set(CommandStatementSubstraitPlan.$type, CommandStatementSubstraitPlan);

function createBaseTicketStatementQuery(): TicketStatementQuery {
  return { $type: "arrow.flight.protocol.sql.TicketStatementQuery", statementHandle: new Uint8Array(0) };
}

export const TicketStatementQuery: MessageFns<TicketStatementQuery, "arrow.flight.protocol.sql.TicketStatementQuery"> =
  {
    $type: "arrow.flight.protocol.sql.TicketStatementQuery" as const,

    encode(message: TicketStatementQuery, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
      if (message.statementHandle.length !== 0) {
        writer.uint32(10).bytes(message.statementHandle);
      }
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): TicketStatementQuery {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseTicketStatementQuery() as any;
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.statementHandle = reader.bytes();
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): TicketStatementQuery {
      return {
        $type: TicketStatementQuery.$type,
        statementHandle: isSet(object.statementHandle) ? bytesFromBase64(object.statementHandle) : new Uint8Array(0),
      };
    },

    toJSON(message: TicketStatementQuery): unknown {
      const obj: any = {};
      if (message.statementHandle.length !== 0) {
        obj.statementHandle = base64FromBytes(message.statementHandle);
      }
      return obj;
    },

    create<I extends Exact<DeepPartial<TicketStatementQuery>, I>>(base?: I): TicketStatementQuery {
      return TicketStatementQuery.fromPartial(base ?? ({} as any));
    },
    fromPartial<I extends Exact<DeepPartial<TicketStatementQuery>, I>>(object: I): TicketStatementQuery {
      const message = createBaseTicketStatementQuery() as any;
      message.statementHandle = object.statementHandle ?? new Uint8Array(0);
      return message;
    },
  };

messageTypeRegistry.set(TicketStatementQuery.$type, TicketStatementQuery);

function createBaseCommandPreparedStatementQuery(): CommandPreparedStatementQuery {
  return {
    $type: "arrow.flight.protocol.sql.CommandPreparedStatementQuery",
    preparedStatementHandle: new Uint8Array(0),
  };
}

export const CommandPreparedStatementQuery: MessageFns<
  CommandPreparedStatementQuery,
  "arrow.flight.protocol.sql.CommandPreparedStatementQuery"
> = {
  $type: "arrow.flight.protocol.sql.CommandPreparedStatementQuery" as const,

  encode(message: CommandPreparedStatementQuery, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.preparedStatementHandle.length !== 0) {
      writer.uint32(10).bytes(message.preparedStatementHandle);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommandPreparedStatementQuery {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommandPreparedStatementQuery() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.preparedStatementHandle = reader.bytes();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommandPreparedStatementQuery {
    return {
      $type: CommandPreparedStatementQuery.$type,
      preparedStatementHandle: isSet(object.preparedStatementHandle)
        ? bytesFromBase64(object.preparedStatementHandle)
        : new Uint8Array(0),
    };
  },

  toJSON(message: CommandPreparedStatementQuery): unknown {
    const obj: any = {};
    if (message.preparedStatementHandle.length !== 0) {
      obj.preparedStatementHandle = base64FromBytes(message.preparedStatementHandle);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CommandPreparedStatementQuery>, I>>(base?: I): CommandPreparedStatementQuery {
    return CommandPreparedStatementQuery.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CommandPreparedStatementQuery>, I>>(
    object: I,
  ): CommandPreparedStatementQuery {
    const message = createBaseCommandPreparedStatementQuery() as any;
    message.preparedStatementHandle = object.preparedStatementHandle ?? new Uint8Array(0);
    return message;
  },
};

messageTypeRegistry.set(CommandPreparedStatementQuery.$type, CommandPreparedStatementQuery);

function createBaseCommandStatementUpdate(): CommandStatementUpdate {
  return { $type: "arrow.flight.protocol.sql.CommandStatementUpdate", query: "", transactionId: undefined };
}

export const CommandStatementUpdate: MessageFns<
  CommandStatementUpdate,
  "arrow.flight.protocol.sql.CommandStatementUpdate"
> = {
  $type: "arrow.flight.protocol.sql.CommandStatementUpdate" as const,

  encode(message: CommandStatementUpdate, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.query !== "") {
      writer.uint32(10).string(message.query);
    }
    if (message.transactionId !== undefined) {
      writer.uint32(18).bytes(message.transactionId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommandStatementUpdate {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommandStatementUpdate() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.query = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.transactionId = reader.bytes();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommandStatementUpdate {
    return {
      $type: CommandStatementUpdate.$type,
      query: isSet(object.query) ? globalThis.String(object.query) : "",
      transactionId: isSet(object.transactionId) ? bytesFromBase64(object.transactionId) : undefined,
    };
  },

  toJSON(message: CommandStatementUpdate): unknown {
    const obj: any = {};
    if (message.query !== "") {
      obj.query = message.query;
    }
    if (message.transactionId !== undefined) {
      obj.transactionId = base64FromBytes(message.transactionId);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CommandStatementUpdate>, I>>(base?: I): CommandStatementUpdate {
    return CommandStatementUpdate.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CommandStatementUpdate>, I>>(object: I): CommandStatementUpdate {
    const message = createBaseCommandStatementUpdate() as any;
    message.query = object.query ?? "";
    message.transactionId = object.transactionId ?? undefined;
    return message;
  },
};

messageTypeRegistry.set(CommandStatementUpdate.$type, CommandStatementUpdate);

function createBaseCommandPreparedStatementUpdate(): CommandPreparedStatementUpdate {
  return {
    $type: "arrow.flight.protocol.sql.CommandPreparedStatementUpdate",
    preparedStatementHandle: new Uint8Array(0),
  };
}

export const CommandPreparedStatementUpdate: MessageFns<
  CommandPreparedStatementUpdate,
  "arrow.flight.protocol.sql.CommandPreparedStatementUpdate"
> = {
  $type: "arrow.flight.protocol.sql.CommandPreparedStatementUpdate" as const,

  encode(message: CommandPreparedStatementUpdate, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.preparedStatementHandle.length !== 0) {
      writer.uint32(10).bytes(message.preparedStatementHandle);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommandPreparedStatementUpdate {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommandPreparedStatementUpdate() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.preparedStatementHandle = reader.bytes();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommandPreparedStatementUpdate {
    return {
      $type: CommandPreparedStatementUpdate.$type,
      preparedStatementHandle: isSet(object.preparedStatementHandle)
        ? bytesFromBase64(object.preparedStatementHandle)
        : new Uint8Array(0),
    };
  },

  toJSON(message: CommandPreparedStatementUpdate): unknown {
    const obj: any = {};
    if (message.preparedStatementHandle.length !== 0) {
      obj.preparedStatementHandle = base64FromBytes(message.preparedStatementHandle);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CommandPreparedStatementUpdate>, I>>(base?: I): CommandPreparedStatementUpdate {
    return CommandPreparedStatementUpdate.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CommandPreparedStatementUpdate>, I>>(
    object: I,
  ): CommandPreparedStatementUpdate {
    const message = createBaseCommandPreparedStatementUpdate() as any;
    message.preparedStatementHandle = object.preparedStatementHandle ?? new Uint8Array(0);
    return message;
  },
};

messageTypeRegistry.set(CommandPreparedStatementUpdate.$type, CommandPreparedStatementUpdate);

function createBaseCommandStatementIngest(): CommandStatementIngest {
  return {
    $type: "arrow.flight.protocol.sql.CommandStatementIngest",
    tableDefinitionOptions: undefined,
    table: "",
    schema: undefined,
    catalog: undefined,
    temporary: false,
    transactionId: undefined,
    options: {},
  };
}

export const CommandStatementIngest: MessageFns<
  CommandStatementIngest,
  "arrow.flight.protocol.sql.CommandStatementIngest"
> = {
  $type: "arrow.flight.protocol.sql.CommandStatementIngest" as const,

  encode(message: CommandStatementIngest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tableDefinitionOptions !== undefined) {
      CommandStatementIngest_TableDefinitionOptions.encode(message.tableDefinitionOptions, writer.uint32(10).fork())
        .join();
    }
    if (message.table !== "") {
      writer.uint32(18).string(message.table);
    }
    if (message.schema !== undefined) {
      writer.uint32(26).string(message.schema);
    }
    if (message.catalog !== undefined) {
      writer.uint32(34).string(message.catalog);
    }
    if (message.temporary !== false) {
      writer.uint32(40).bool(message.temporary);
    }
    if (message.transactionId !== undefined) {
      writer.uint32(50).bytes(message.transactionId);
    }
    Object.entries(message.options).forEach(([key, value]) => {
      CommandStatementIngest_OptionsEntry.encode({
        $type: "arrow.flight.protocol.sql.CommandStatementIngest.OptionsEntry",
        key: key as any,
        value,
      }, writer.uint32(8002).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommandStatementIngest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommandStatementIngest() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.tableDefinitionOptions = CommandStatementIngest_TableDefinitionOptions.decode(
            reader,
            reader.uint32(),
          );
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.table = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.schema = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.catalog = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.temporary = reader.bool();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.transactionId = reader.bytes();
          continue;
        }
        case 1000: {
          if (tag !== 8002) {
            break;
          }

          const entry1000 = CommandStatementIngest_OptionsEntry.decode(reader, reader.uint32());
          if (entry1000.value !== undefined) {
            message.options[entry1000.key] = entry1000.value;
          }
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommandStatementIngest {
    return {
      $type: CommandStatementIngest.$type,
      tableDefinitionOptions: isSet(object.tableDefinitionOptions)
        ? CommandStatementIngest_TableDefinitionOptions.fromJSON(object.tableDefinitionOptions)
        : undefined,
      table: isSet(object.table) ? globalThis.String(object.table) : "",
      schema: isSet(object.schema) ? globalThis.String(object.schema) : undefined,
      catalog: isSet(object.catalog) ? globalThis.String(object.catalog) : undefined,
      temporary: isSet(object.temporary) ? globalThis.Boolean(object.temporary) : false,
      transactionId: isSet(object.transactionId) ? bytesFromBase64(object.transactionId) : undefined,
      options: isObject(object.options)
        ? Object.entries(object.options).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: CommandStatementIngest): unknown {
    const obj: any = {};
    if (message.tableDefinitionOptions !== undefined) {
      obj.tableDefinitionOptions = CommandStatementIngest_TableDefinitionOptions.toJSON(message.tableDefinitionOptions);
    }
    if (message.table !== "") {
      obj.table = message.table;
    }
    if (message.schema !== undefined) {
      obj.schema = message.schema;
    }
    if (message.catalog !== undefined) {
      obj.catalog = message.catalog;
    }
    if (message.temporary !== false) {
      obj.temporary = message.temporary;
    }
    if (message.transactionId !== undefined) {
      obj.transactionId = base64FromBytes(message.transactionId);
    }
    if (message.options) {
      const entries = Object.entries(message.options);
      if (entries.length > 0) {
        obj.options = {};
        entries.forEach(([k, v]) => {
          obj.options[k] = v;
        });
      }
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CommandStatementIngest>, I>>(base?: I): CommandStatementIngest {
    return CommandStatementIngest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CommandStatementIngest>, I>>(object: I): CommandStatementIngest {
    const message = createBaseCommandStatementIngest() as any;
    message.tableDefinitionOptions =
      (object.tableDefinitionOptions !== undefined && object.tableDefinitionOptions !== null)
        ? CommandStatementIngest_TableDefinitionOptions.fromPartial(object.tableDefinitionOptions)
        : undefined;
    message.table = object.table ?? "";
    message.schema = object.schema ?? undefined;
    message.catalog = object.catalog ?? undefined;
    message.temporary = object.temporary ?? false;
    message.transactionId = object.transactionId ?? undefined;
    message.options = Object.entries(object.options ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

messageTypeRegistry.set(CommandStatementIngest.$type, CommandStatementIngest);

function createBaseCommandStatementIngest_TableDefinitionOptions(): CommandStatementIngest_TableDefinitionOptions {
  return {
    $type: "arrow.flight.protocol.sql.CommandStatementIngest.TableDefinitionOptions",
    ifNotExist: 0,
    ifExists: 0,
  };
}

export const CommandStatementIngest_TableDefinitionOptions: MessageFns<
  CommandStatementIngest_TableDefinitionOptions,
  "arrow.flight.protocol.sql.CommandStatementIngest.TableDefinitionOptions"
> = {
  $type: "arrow.flight.protocol.sql.CommandStatementIngest.TableDefinitionOptions" as const,

  encode(
    message: CommandStatementIngest_TableDefinitionOptions,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.ifNotExist !== 0) {
      writer.uint32(8).int32(message.ifNotExist);
    }
    if (message.ifExists !== 0) {
      writer.uint32(16).int32(message.ifExists);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommandStatementIngest_TableDefinitionOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommandStatementIngest_TableDefinitionOptions() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.ifNotExist = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.ifExists = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommandStatementIngest_TableDefinitionOptions {
    return {
      $type: CommandStatementIngest_TableDefinitionOptions.$type,
      ifNotExist: isSet(object.ifNotExist)
        ? commandStatementIngest_TableDefinitionOptions_TableNotExistOptionFromJSON(object.ifNotExist)
        : 0,
      ifExists: isSet(object.ifExists)
        ? commandStatementIngest_TableDefinitionOptions_TableExistsOptionFromJSON(object.ifExists)
        : 0,
    };
  },

  toJSON(message: CommandStatementIngest_TableDefinitionOptions): unknown {
    const obj: any = {};
    if (message.ifNotExist !== 0) {
      obj.ifNotExist = commandStatementIngest_TableDefinitionOptions_TableNotExistOptionToJSON(message.ifNotExist);
    }
    if (message.ifExists !== 0) {
      obj.ifExists = commandStatementIngest_TableDefinitionOptions_TableExistsOptionToJSON(message.ifExists);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CommandStatementIngest_TableDefinitionOptions>, I>>(
    base?: I,
  ): CommandStatementIngest_TableDefinitionOptions {
    return CommandStatementIngest_TableDefinitionOptions.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CommandStatementIngest_TableDefinitionOptions>, I>>(
    object: I,
  ): CommandStatementIngest_TableDefinitionOptions {
    const message = createBaseCommandStatementIngest_TableDefinitionOptions() as any;
    message.ifNotExist = object.ifNotExist ?? 0;
    message.ifExists = object.ifExists ?? 0;
    return message;
  },
};

messageTypeRegistry.set(
  CommandStatementIngest_TableDefinitionOptions.$type,
  CommandStatementIngest_TableDefinitionOptions,
);

function createBaseCommandStatementIngest_OptionsEntry(): CommandStatementIngest_OptionsEntry {
  return { $type: "arrow.flight.protocol.sql.CommandStatementIngest.OptionsEntry", key: "", value: "" };
}

export const CommandStatementIngest_OptionsEntry: MessageFns<
  CommandStatementIngest_OptionsEntry,
  "arrow.flight.protocol.sql.CommandStatementIngest.OptionsEntry"
> = {
  $type: "arrow.flight.protocol.sql.CommandStatementIngest.OptionsEntry" as const,

  encode(message: CommandStatementIngest_OptionsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CommandStatementIngest_OptionsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCommandStatementIngest_OptionsEntry() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CommandStatementIngest_OptionsEntry {
    return {
      $type: CommandStatementIngest_OptionsEntry.$type,
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: CommandStatementIngest_OptionsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CommandStatementIngest_OptionsEntry>, I>>(
    base?: I,
  ): CommandStatementIngest_OptionsEntry {
    return CommandStatementIngest_OptionsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CommandStatementIngest_OptionsEntry>, I>>(
    object: I,
  ): CommandStatementIngest_OptionsEntry {
    const message = createBaseCommandStatementIngest_OptionsEntry() as any;
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

messageTypeRegistry.set(CommandStatementIngest_OptionsEntry.$type, CommandStatementIngest_OptionsEntry);

function createBaseDoPutUpdateResult(): DoPutUpdateResult {
  return { $type: "arrow.flight.protocol.sql.DoPutUpdateResult", recordCount: 0n };
}

export const DoPutUpdateResult: MessageFns<DoPutUpdateResult, "arrow.flight.protocol.sql.DoPutUpdateResult"> = {
  $type: "arrow.flight.protocol.sql.DoPutUpdateResult" as const,

  encode(message: DoPutUpdateResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.recordCount !== 0n) {
      if (BigInt.asIntN(64, message.recordCount) !== message.recordCount) {
        throw new globalThis.Error("value provided for field message.recordCount of type int64 too large");
      }
      writer.uint32(8).int64(message.recordCount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DoPutUpdateResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDoPutUpdateResult() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.recordCount = reader.int64() as bigint;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DoPutUpdateResult {
    return { $type: DoPutUpdateResult.$type, recordCount: isSet(object.recordCount) ? BigInt(object.recordCount) : 0n };
  },

  toJSON(message: DoPutUpdateResult): unknown {
    const obj: any = {};
    if (message.recordCount !== 0n) {
      obj.recordCount = message.recordCount.toString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DoPutUpdateResult>, I>>(base?: I): DoPutUpdateResult {
    return DoPutUpdateResult.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DoPutUpdateResult>, I>>(object: I): DoPutUpdateResult {
    const message = createBaseDoPutUpdateResult() as any;
    message.recordCount = object.recordCount ?? 0n;
    return message;
  },
};

messageTypeRegistry.set(DoPutUpdateResult.$type, DoPutUpdateResult);

function createBaseDoPutPreparedStatementResult(): DoPutPreparedStatementResult {
  return { $type: "arrow.flight.protocol.sql.DoPutPreparedStatementResult", preparedStatementHandle: undefined };
}

export const DoPutPreparedStatementResult: MessageFns<
  DoPutPreparedStatementResult,
  "arrow.flight.protocol.sql.DoPutPreparedStatementResult"
> = {
  $type: "arrow.flight.protocol.sql.DoPutPreparedStatementResult" as const,

  encode(message: DoPutPreparedStatementResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.preparedStatementHandle !== undefined) {
      writer.uint32(10).bytes(message.preparedStatementHandle);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DoPutPreparedStatementResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDoPutPreparedStatementResult() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.preparedStatementHandle = reader.bytes();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DoPutPreparedStatementResult {
    return {
      $type: DoPutPreparedStatementResult.$type,
      preparedStatementHandle: isSet(object.preparedStatementHandle)
        ? bytesFromBase64(object.preparedStatementHandle)
        : undefined,
    };
  },

  toJSON(message: DoPutPreparedStatementResult): unknown {
    const obj: any = {};
    if (message.preparedStatementHandle !== undefined) {
      obj.preparedStatementHandle = base64FromBytes(message.preparedStatementHandle);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DoPutPreparedStatementResult>, I>>(base?: I): DoPutPreparedStatementResult {
    return DoPutPreparedStatementResult.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DoPutPreparedStatementResult>, I>>(object: I): DoPutPreparedStatementResult {
    const message = createBaseDoPutPreparedStatementResult() as any;
    message.preparedStatementHandle = object.preparedStatementHandle ?? undefined;
    return message;
  },
};

messageTypeRegistry.set(DoPutPreparedStatementResult.$type, DoPutPreparedStatementResult);

function createBaseActionCancelQueryRequest(): ActionCancelQueryRequest {
  return { $type: "arrow.flight.protocol.sql.ActionCancelQueryRequest", info: new Uint8Array(0) };
}

export const ActionCancelQueryRequest: MessageFns<
  ActionCancelQueryRequest,
  "arrow.flight.protocol.sql.ActionCancelQueryRequest"
> = {
  $type: "arrow.flight.protocol.sql.ActionCancelQueryRequest" as const,

  encode(message: ActionCancelQueryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.info.length !== 0) {
      writer.uint32(10).bytes(message.info);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ActionCancelQueryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseActionCancelQueryRequest() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.info = reader.bytes();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ActionCancelQueryRequest {
    return {
      $type: ActionCancelQueryRequest.$type,
      info: isSet(object.info) ? bytesFromBase64(object.info) : new Uint8Array(0),
    };
  },

  toJSON(message: ActionCancelQueryRequest): unknown {
    const obj: any = {};
    if (message.info.length !== 0) {
      obj.info = base64FromBytes(message.info);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ActionCancelQueryRequest>, I>>(base?: I): ActionCancelQueryRequest {
    return ActionCancelQueryRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ActionCancelQueryRequest>, I>>(object: I): ActionCancelQueryRequest {
    const message = createBaseActionCancelQueryRequest() as any;
    message.info = object.info ?? new Uint8Array(0);
    return message;
  },
};

messageTypeRegistry.set(ActionCancelQueryRequest.$type, ActionCancelQueryRequest);

function createBaseActionCancelQueryResult(): ActionCancelQueryResult {
  return { $type: "arrow.flight.protocol.sql.ActionCancelQueryResult", result: 0 };
}

export const ActionCancelQueryResult: MessageFns<
  ActionCancelQueryResult,
  "arrow.flight.protocol.sql.ActionCancelQueryResult"
> = {
  $type: "arrow.flight.protocol.sql.ActionCancelQueryResult" as const,

  encode(message: ActionCancelQueryResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.result !== 0) {
      writer.uint32(8).int32(message.result);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ActionCancelQueryResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseActionCancelQueryResult() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.result = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ActionCancelQueryResult {
    return {
      $type: ActionCancelQueryResult.$type,
      result: isSet(object.result) ? actionCancelQueryResult_CancelResultFromJSON(object.result) : 0,
    };
  },

  toJSON(message: ActionCancelQueryResult): unknown {
    const obj: any = {};
    if (message.result !== 0) {
      obj.result = actionCancelQueryResult_CancelResultToJSON(message.result);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ActionCancelQueryResult>, I>>(base?: I): ActionCancelQueryResult {
    return ActionCancelQueryResult.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ActionCancelQueryResult>, I>>(object: I): ActionCancelQueryResult {
    const message = createBaseActionCancelQueryResult() as any;
    message.result = object.result ?? 0;
    return message;
  },
};

messageTypeRegistry.set(ActionCancelQueryResult.$type, ActionCancelQueryResult);

function bytesFromBase64(b64: string): Uint8Array {
  if ((globalThis as any).Buffer) {
    return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
  } else {
    const bin = globalThis.atob(b64);
    const arr = new Uint8Array(bin.length);
    for (let i = 0; i < bin.length; ++i) {
      arr[i] = bin.charCodeAt(i);
    }
    return arr;
  }
}

function base64FromBytes(arr: Uint8Array): string {
  if ((globalThis as any).Buffer) {
    return globalThis.Buffer.from(arr).toString("base64");
  } else {
    const bin: string[] = [];
    arr.forEach((byte) => {
      bin.push(globalThis.String.fromCharCode(byte));
    });
    return globalThis.btoa(bin.join(""));
  }
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | bigint | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends { readonly $case: string }
    ? { [K in keyof Omit<T, "$case">]?: DeepPartial<T[K]> } & { readonly $case: T["$case"] }
  : T extends {} ? { [K in Exclude<keyof T, "$type">]?: DeepPartial<T[K]> }
  : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
export type Exact<P, I extends P> = P extends Builtin ? P
  : P & { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P> | "$type">]: never };

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T, V extends string> {
  readonly $type: V;
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create<I extends Exact<DeepPartial<T>, I>>(base?: I): T;
  fromPartial<I extends Exact<DeepPartial<T>, I>>(object: I): T;
}
